Amortized analysis is a powerful technique for data structure analysis, involving the total runtime of a sequence of operations. This lecture covers different techniques of amortized analysis (aggregate method, accounting method, charging method, potential method) and examples of amortized analysis (table doubling, binary counter, 2-3 tree and 2-5 tree).
To store n elements in a table of size m = O(n), double m whenever n becomes larger than m (due to insertions). The cost to double a table of size m is clearly Ѳ(m) = Θ(n), which is also the worse case cost of an insertion. The total cost of n insertions is at most:

2º + 21 + 22 + ··· + 2[lgn] = Θ(n).

Each insertion has O(n)/n = Θ(1) amortized cost.
The aggregate method is: add up the cost of all the operations and then divide by the number of operations.
amortized cost per operation = total cost of k operations / k.
It is the simplest method but may not be able to analyze more complicated algorithms.
Amortized cost can be, but does not have to be, average cost. We can assign any amortized cost to each operation, as long as they“preserve the total cost", i.e., for any sequence of operations,

☑ amortized cost ≥ ☑ actual cost

where the sum is taken over all operations. A 2-3 tree achieves O(1) amortized cost per create, O(lg n*) amortized cost per insert, and 0 amortized cost per delete, where n* is the maximum size of the 2-3 tree during the entire sequence of operations. For any sequence of operations, suppose there are c creations, i insertions and d ≤ i deletions (cannot delete from an empty tree), the total amortized cost is asymptotically the same as the total actual cost:

O(c + ilgn* + 0d) = O(c + ilgn* + dlgn*)

The amortized cost per insert to O(lgn) where n is the current size.
This method allows an operation to store credit into a bank for future use, if its assigned amortized cost > its actual cost; it also allows an operation to pay for its extra actual cost using existing credit, if its assigned amortized cost < its actual cost. For table doubling, if an insertion does not trigger table doubling, store a coin representing c = O(1) work for future use. If an insertion does trigger table doubling, there must be n/2 elements that are inserted after the previous table doubling, whose coins have not been consumed. Use up these n/2 coins to pay for the O(n) table doubling. amortized cost for table doubling: O(n) – c . n/2 = 0 for large enough c. amortized cost per insertion: 1 + c = O(1).
The charging method allows operations to charge cost retroactively to past operations.
amortized cost of an operation = actual cost of this operation – total cost charged to past operations + total cost charged by future operations

For example, in table doubling, when the table doubles from m to 2m, we can charge (m) cost to the m/2 insert operations since the last doubling. Each insert is charged by (1), and will not be charged again. So the amortized cost per insert is Θ(1). Now let's extend the above example with table halving. The motivation is to save space when with deletes. If the table is down to 1/4 full, n = m/4, we shrink the table size from m to m/2 at Ө(m) cost. This way, the table is half full again after any resize (doubling or shrinking). Now each table doubling still has ≥ m/2 insert operations to charge to, and each table halving has ≥ m/4 delete operations to charge to. So the amortized cost per insert or delete is still Ө(1).
Insert has O(lgn) amortized cost, where n is the size of the tree when that insert happens, and delete has 0 amortized cost. Insert does not need to charge anything. Delete will charge an insert operation. But we will not charge the insert of the element to be deleted, because we will run into the same problem as the accounting method. Instead, each delete operation will charge the insert operation that brought the tree to its current size n. Each insert is still charged at most once, because for the tree size to reach n again, another insert must happen.
This method defines a potential function that maps a data structure (DS) configu- ration to a value. This function Þ is equivalent to the total unused credits stored up by all past operations (the bank account balance). Now

amortized cost of an operation = actual cost of this operation + ΔΦ

and

amortized cost = ∑ actual cost + Φ(final DS) – Ф(initial DS).

In order for the amortized bound to hold, I should never go below (initial DS) at any point. If (initial DS) = 0, which is usually the case, then I should never go negative (intuitively, we cannot "owe the bank”). In accounting method, we specify ΔΦ, while in potential method, we specify Ф. One determines the other, so the two methods are equivalent. But sometimes one is more intuitive than the other.
Cost of increment is Ѳ(1 + #1), where #1 represents the number of trailing 1 bits. So the intuition is that 1 bits are bad.
Define Φ = c . #1. Then for large enough c,

amortized cost = actual cost + ΔΦ =  Θ(1 + #1) + c(−#1 + 1) = Θ(1)

Φ(initial DS) = 0 if the counter starts at 0000. This is necessary for the above amortized analysis. Otherwise, I may become smaller than Φ(initial DS).
Insert can cause O(lg n) splits in the worst case, but we can show it causes only O(1) amortized splits. First consider what causes a split: insertion into a 3-node (a node with 3 children). In that case, the 3-node needs to split into two 2-nodes. So 3-nodes are bad. We define Ф = the number of 3-nodes. Then ΔΦ < 1 the number of splits. Amortized number of splits = actual number of splits + ΔΦ = 1. Φ(initial DS) = 0 if the tree is empty initially. The above analysis holds for any (a, b)-tree, if we define Þ to be the number of b-nodes. If we consider both insertion and deletion in 2-3 trees, can we claim both O(1) splits for insert, and O(1) merges for delete? The answer is no, because a split creates two 2-nodes, which are bad for merge. In the worse case, they may be merged by the next delete, and then need split again on the next insert, and so on. What do we solve this problem? We need to prevent split and merge from creating 'bad' nodes.
We can claim O(1) splits for insert, and O(1) merges for delete in 2-5 trees. In 2-5 trees, insertion into a 5-node (a node with 5 children) causes it to split into two 3-nodes. Deletion from a 2-node causes it to merge with another 2-node to form a 3-node. 5-nodes and 2-nodes are bad. We define Φ = # of 5-nodes + # of 2-nodes. Amortized splits and merges = 1. Φ(initial DS) = 0 if the tree is empty initially. The above analysis holds for any (a, b)-tree where b > 2a, because splits and merges do not produce bad nodes. We define Þ to be the number of b-nodes plus the number of a nodes. Note: The potential examples could also be done with the accounting method by placing coins on 1s (binary counter) or 2/5-nodes ((2,5)-trees).
Skip Lists, including data structure, randomized insertion, and with high probability (w.h.p.) bound.
Skip lists are simple randomized dynamic search structures invented by William Pugh in 1989, easy to implement, and maintain a dynamic set of n elements in O(lg n) time per operation in expectation and with high probability. They provide a strong guarantee on the tail of the distribution of T(n) and achieve O(lg n) 'almost always'.
Searches take O(n) time in the worst case.
By using two sorted linked lists. It is assumed that you have two sorted linked lists on subsets of the elements, and each element can appear in one or both lists.
Walk right in the top linked list (L₁) until going right would go too far, walk down to the bottom linked list (L₂), and walk right in L₂ until the element is found (or not).
Evenly space the nodes in L₁ to care about worst-case performance. In a subway, the "popular stations"
The search cost is roughly |L₁| + |L₂|/|L₁|, which is minimized (up to constant factors) when the terms are equal.  This leads to |L₁|² = |L₂| = n, implying |L₁| = \sqrt{n}. Therefore L₁ = \sqrt{n}, L₂ = n and search cost is roughly |L₁| + |L₂|/|L₁| = \sqrt{n} + n/\sqrt{n} = 2\sqrt{n}
If there are 2 sorted lists → 2\cdot \sqrt{n}, If there are 3 sorted lists → 3\cdot \sqrt[3]{n}, If there are k sorted lists → k\cdot \sqrt[k]{n}, If there are lg n sorted lists → lg n \cdot \sqrt[lgn]{n} = 2lgn
lg n sorted linked lists are like a binary tree (in fact, level-linked B+-tree).
An ideal skip list is a lg n linked list structure.
To insert an element x into a skip list:  SEARCH(x) to see where x fits in the bottom list, always insert into the bottom list, which contains all elements, and insert into some of the lists above. For the question, 'To which other lists should we add x?' flip a (fair) coin; if HEADS, promote x to the next level up and flip again.  The probability of promotion to the next level = p = 1/2. On average, 1/2 of the elements are promoted 0 levels, 1/4 of the elements are promoted 1 level, 1/8 of the elements are promoted 2 levels, etc.
Add a special -∞ value to every list, so you can search with the same algorithm.
A skip list is the result of insertions (and deletions) from an initially empty structure (containing just -∞). INSERT(x) uses random coin flips to decide the promotion level, and DELETE(x) removes x from all lists containing it.
Expected Time for Search: O(lg n)
Search for the target begins with the head element in the top list. Proceed horizontally until the current element is greater than or equal to the target. If the current element equals the target, it has been found. If the current element is greater than the target, go back to the previous element and drop down vertically to the next lower list and repeat the procedure. The expected number of steps in each linked list is seen to be 1/p, by tracing the search path backwards from the target until reaching an element that appears in the next higher list. The total expected cost of a search is O(log1/p n) (1/p), which is O(lg n) when p is a constant.
With high probability, every search in an n-element skip list costs O(lg n).
Informally: Event E occurs with high probability (w.h.p.) if, for any a ≥ 1, there is an appropriate choice of constants for which E occurs with probability at least 1 - O(1/na).  In fact, the constant in O(lg n) depends on a.
Formally: Parameterized event Eα occurs with high probability if, for any a ≥ 1, there is an appropriate choice of constants for which Eα occurs with probability at least 1 - cα/na.
For any random events E₁, E₂, ..., Eₖ, Pr{E₁ ∪ E₂ ∪ ... ∪ Eₖ} ≤ Pr{E₁} + Pr{E₂} + ... + Pr{Eₖ}.
An n-element skip list has O(lg n) expected number of levels. The probability that x has been promoted once is p. The probability that x has been promoted k times is pk f. The expected number of promotions is Sigma I = 0 \infty i. p^I = O(log Error probability for having at most c lg n levels = Pr{more than c lg n levels} ≤ n \cdot Pr{element x promoted at least c lg n times} = n\cdot (1/2^{c lgn}) = n\cdot (1/nc) = 1/nc-1 (by Boole's Inequality).
Error probability for having at most c lg n levels <= 1/n^{c-1}. We can make a arbitrarily large by choosing the constant c in the O(lg n) bound accordingly.
Search starts [ends] at leaf (node in the bottom level). At each node visited: If node wasn't promoted higher (got TAILS here), then we go [came from] left. If node was promoted higher (got HEADS here), then we go [came from] up.  Search stops [starts] at the root (or -∞).
The search makes "up" and "left" moves until it reaches the root (or -∞). The expected number of "up" moves < num. of levels <= O(lg n) (Lemma).
Let Y be a random variable representing the total number of heads (tails) in a series of m independent coin flips, where each flip has a probability p of coming up heads (tails). Then, for all r > 0, Pr[Y > E[Y] + r] < e^{-2r^2/m}.
For any c there is a constant d such that w.h.p. the number of heads in flipping d lgn fair coins is at least c lgn.
Pr[Y >= (d - c) lgn] = Pr[Y >= E[Y] + (1/2 d - c) lgn]. Choose d = 3c => r = 3clgn.  By Chernoff, the probability of <= c lgn heads is <= e^{-2r^2/m} = e^{-2(3clgn)^2/8clgn} = e^{-9/4clgn} <= e^{-clgn} <= 2^{-clgn} (e > 2) = 1/nc.
With high probability, every search in an n-element skip list costs O(lg n).
event A: number of levels <= c lgn w.h.p.
event B: number of moves until c lgn 'up' moves <= d lgn w.h.p.
A and B are not independent!
Want to show A & B occurs w.h.p. to prove theorem
Pr(A & B) = Pr(A + B) <= Pr(A) + Pr(B) (union bound)
<= 1/nc-1 + 1/nc = O(1/nc-1)
Search (binary, B-ary, cache-oblivious) and Sorting (mergesorts, cache-oblivious).
Proof: partition block access sequence into maximal phases of M/B distinct blocks, LRU spends < M/B memory transfers/phase, and OPT must spend ≥ M/B memory transfers per phase: at best, starts phase with entire M/2 cache with needed items. But there are M/B blocks during phase. So ≤ half free
Preprocess n elements in comparison model to support predecessor search for x. B-trees support predecessor (and insert and delete) in O(logB+1 N) memory transfers. Each node occupies Θ(1) blocks, height= O(logB N), and we need to know B.
Approximately, every iteration visits a different block until we are in x's block. Thus, MT(N) = Θ(log N – log B) = Θ(log(N/B)). SLOW
store N elements in complete BST, carve BST at middle level of edges, recursively layout the pieces and concatenate, like block matrix multiplication, order of pieces doesn't matter; just need each piece to be stored consecutively
Consider recursive level of refinement at which structure has < B nodes, the height of the vEB tree is between lg B and lg B => size is between √B and B => any root-to-node path (search path) visits < lg N = 2logB N trees that have size < B, each tree of size < B occupies ≤ 2 memory blocks => 4logB N = O(logB N) memory transfers
this generalizes to heights that are not powers of 2, B-trees of constant branching factor and dynamic B-trees: O(logB N) insert/delete. [Bender, Demaine, Farach-Colton 2000]
N inserts into (cache-oblivious) B-tree = MT(N) = Θ(NlogB N) NOT OPTIMAL. By contrast, BST sort is optimal O(N lg N)
Binary mergesort is cache-oblivious. The merge is 3 parallel scans => MT(N) = 2MT(N/2) + O(N/B + 1). MT(M) = O(M/B). The recursion tree has lg(N/M) levels, and each level contributes O(N/B) => MT(N) = lg(N/M) * (N/B) <= faster than the B-tree version discussed earlier!
Split array into M/B equal subarrays, recursively sort each, merge via M/B parallel scans (keeping one “current” block per list) => MT(N) = (M/B)*MT(N/(M/B)) + O(N/B + 1). MT(M) = O(M/B), height becomes logM/B (N/M) + 1 = logM/B (N/B)-logM/B (M/B)+1 = logM/B (N/B).
MT(N) = O((N/B)logM/B (N/B)). This is asymptotically optimal, in the comparison model. This requires the tall-cache assumption: M = Ω(B1+e) for some fixed e > 0, e.g., M = Ω(B2) or M/B = Ω(B). Then, ≈ N-way mergesort with recursive (“funnel”) merge works.
O(logM/B N) per insert or delete-min, generalizes sorting, external memory and cache-oblivious, and see 6.851
Vertex Cover, Fixed-Parameter Tractability, Kernelization, and Connection to Approximation
Fixed Parameter Algorithms are an alternative way to deal with NP-hard problems instead of approximation algorithms. There are three general desired features of an algorithm: Solve (NP-)hard problems, Run in polynomial time (fast), Get exact solutions. In general, unless P = NP, an algorithm can have two of these three features, but not all three. An algorithm that has Features 2 and 3 is an algorithm in P (poly-time exact). An approximation algorithm has Features 1 and 2. It solves hard problems, and it runs fast, but it does not give exact solutions. Fixed-parameter algorithms will have Features 1 and 3. They will solve hard problems and give exact solutions, but they will not run very fast.
The idea is to aim for an exact algorithm but isolate exponential terms to a specific parameter. When the value of this parameter is small, the algorithm gets fast instances. Hopefully, this parameter will be small in practice.
A parameter is a nonnegative integer k(x) where x is the problem input. Typically, the parameter is a natural property of the problem (some k in input). It may not necessarily be efficiently computable (e.g., OPT).
A parameterized problem is simply the problem plus the parameter or the problem as seen with respect to the parameter. There are potentially many interesting parameterizations for any given problem.
The goal of fixed-parameter algorithms is to have an algorithm that is polynomial in the problem size n but possibly exponential in the parameter k, and still get an exact solution.
Given a graph G = (V, E) and a nonnegative integer k, is there a set S⊆ V of vertices of size at most k, |S| ≤ k, that covers all edges. This is a decision problem for Vertex Cover and is also NP-hard. We will use k as the parameter to develop a fixed-parameter algorithm for k-Vertex Cover. Note that we can have k << |V|.
Try all $binom{n}{0} + binom{n}{1} + ... + binom{n}{k}$ sets of ≤ k vertices. Can skip all terms smaller than $binom{n}{k}$ because bigger sets have more coverage. Testing coverage takes O(m) time where m is the number of edges. Therefore, the total runtime is O(Vk|E|). It is polynomial for fixed k but not the same polynomial for all k's. It is inefficient in most cases. Hence we define nf(k) to be bad, where n = |V| + |E| is the input size.
The bounded search-tree algorithm works as follows: pick arbitrary edge e = (u, v), we know that either u ∈ S or v ∈ S (or both) but don't know which, guess which one: try both possibilities:
1. add u to S, delete u and incident edges from G, and recurse with k′ = k−1.
2. do the same but with v instead of u
3. return the OR of the two outcomes
Image Description:  A tree structure is displayed.  The root node is labeled u, v.  This node has two child nodes. The left child node is labeled u', v' and the right child node is labeled u", v".  The left child node has two children labeled u' and v' respectively.  The right child node has two children labeled u" and v" respectively.
At a leaf (k = 0), return YES if |E| = 0 (all edges covered). It takes O(V) time to delete u or v. Therefore this has a total runtime of (2k|V|).  \begin{itemize}
    \item O(V) for fixed k
    \item degree of polynomial is independent of k
    \item also polynomial for k = O(lg|V|)
    \item practical for e.g. k ≤ 32
    \item Hence we define $f(k) n^{O(1)}$ to be good
\end{itemize}
A parameterized problem is fixed-parameter tractable (FPT) if there is an algorithm with running time ≤ f(k) · no(1), such that f : N → N (non negative) and k is the parameter, and the O(1) degree of the polynomial is independent of k and n.
Question: Why f(k) · no(1) and not f(k) + no(1)?
Theorem: ∃f(k)·nalgorithm ∃f′(k) + nc
Proof:
(←)
Trivial (assuming f'(k) and n' are ≥ 1)
(⇒)
if n ≤ f(k), then f(k) · nº ≤ f(k)c+1
Kernelization is a simplifying self-reduction. It is a polynomial time algorithm that converts an input (x, k) into a small and equivalent input (x', k'). Here, small means |x'| ≤ f(k) and equivalent means the answer to x is the same as the answer to x'.
Theorem: a problem is FPT ⇔ a kernelization
Proof:
(←)
Kernelize ⇒ n' ≤ f(k)
Run any finite g(n') algorithm
Totals to no(1) + g(f(k)) time
(⇒)
let A be an f(k) · nº algorithm, then assuming k is known:
if n ≤ f(k), it's already kernelized.
if f(k) ≤ n, then
1. run A → f(k) · nº ≤ nc+1 time
2. output O(1)-sized YES/NO instance as appropriate (to kernelize)
if k is unknown: run A for nc+1 time and if it is still not done, we know it is already kernelized.
To create a kernel for k-Vertex Cover, the algorithm follows the following steps:
• Make graph simple by removing all self loops and multi-edges
• Any vertex of degree > k must be in the cover (else would need to add > k vertices to cover incident edges)
• Remove such vertices (and incident edges) one at a time, decreasing k accordingly
• Remaining graph has maximum degree ≤ k
• Each remaining vertex covers ≤ k edges
• If the number of remaining edges is > k, answer NO and output canonical NO instance.
• Else, |E'| ≤ k²
• Remove all isolated vertices (degree 0 vertices)
• Now |V'| ≤ 2k2
• The input has been reduced to instance (V', E') of size O(k²)
The runtime of the kernelization algorithm is naively O(VE). (O(V + E) with more work.) After this, we can apply either a brute-force algorithm on the kernel, which yields an overall runtime O(V + E + (2k²)*k²) = O(V + E + 2kk2k+2). Or we can apply a bounded search-tree solution, which yields a runtime of O(V + E + 2k*k²).
The best algorithm to date: O(kV + 1.274k) by [Chen, Kanj, Xia - TCS 2010].
Take an optimization problem, integral OPT and consider its associated decision problem: “OPT ≤ k ?” and parameterize by k.
Theorem: optimization problem has EPTAS
(EPTAS: efficient PTAS, f(1) · no(1) e.g. Approxpartition[L17])
⇒ decision problem is FPT
Proof: (like FPTAS, pseudopolynomial algorithm)
• Say maximization problem (and ≤ k decision)
• run EPTAS with e = 1/(2k) in f(2k) · nº(1) time.
• relative error ≤ k/(2k) = 1/2
• ⇒ absolute error < 1 if OPT ≤ k
• So if we find a solution with value < k, then OPT ≤ (1+1/2)· k ≤ k + 1/2
Integral ⇒ OPT < k ⇒ YES
• else OPT > k
Also: =, <, > decision problems are equivalent with respect to FPT.
Dynamic programming, Matrix multiplication, Floyd-Warshall algorithm, Johnson's algorithm, and Difference constraints.
Given a directed graph G = (V, E), a vertex s ∈ V, and edge weights w : E → R, find d(s, v), which equals the shortest-path weight s → v, ∀v ∈ V (or -∞ if there is a negative-weight cycle along the way, or ∞ if no path).
If the graph is unweighted (w = 1), use BFS with a time complexity of O(V + E). If the graph has non-negative edge weights, use Dijkstra with a time complexity of O(E + V lg V). For a general graph, use Bellman-Ford with a time complexity of O(VE). For an acyclic graph (DAG), use Topological sort + one pass of B-F with a time complexity of O(V + E).  We achieve a O(E + V lg V) bound on Dijkstra's algorithm using Fibonacci heaps.
Given an edge-weighted graph G = (V, E, w), find δ(u, v) for all u, v ∈ V.
|V| x BFS and the time complexity is O(VE) , E = Θ(V²), which is O(V³)
|V| x Dijkstra and the time complexity is O(VE + V² lg V), E = Θ(V²), which is O(V³)
|V| x Bellman-Ford and the time complexity is O(V²E) , E = Θ(V²), which is O(V⁴) or  Johnson's and the time complexity is O(VE + V² lg V), E = Θ(V²), which is O(V³)
Sub-problems: d(m) = weight of shortest path u → v using ≤ m edges. Guessing: What's the last edge (x, v)?
Recurrence: 
d(m) = min(d(m-1) + w(x, v) for x ∈ V)
0 if u = v
d(0) =  otherwise
Topological ordering: for m = 0,1,2, . . ., n − 1: for u and v in V.  If graph contains no negative-weight cycles (by Bellman-Ford analysis), then shortest path is simple ⇒ δ(u, v) = d(n-1) = d(n)
In this Dynamic Program, we have O(V3) total sub-problems. Each sub-problem takes O(V) time to solve, since we need to consider V possible choices. This gives a total runtime complexity of O(V4).
1 form = 1 to n by 1
2 for u in V
3 for v in V
4 for x in V
5 if duv > dux + dxv
6 duv = dux + dxv
In the above pseudocode, we omit superscripts because more relaxation can never hurt.
Note that we can change our relaxation step to d(m) = min(d[m/21+d[m/2] for x ∈ V). This change would produce an overall running time of O(n³ lgn) time. (student suggestion)
Given n × n matrices A and B, compute C = A. B, such that Cij = ∑k=1 aik.bkj
• O(n³) using standard algorithm
• O(n 2.807) using Strassen's algorithm
• O(n2.376) using Coppersmith-Winograd algorithm
• O(n2.3728) using Vassilevska Williams algorithm
Define ⊙ = min and + = -. Then, C = A ⊙ B produces Cij = mink(aik + bkj). Define D(m) = (d(m)), W = (w(i, j)), V = {1, 2, ..., n}. With the above definitions, we see that D(m) can be expressed as D(m-1) ⊙ W. In other words, D(m) can be expressed as the circle-multiplication of W with itself m times.
n 2 multiplications ⇒ O(n⁴) time (stil no better)
• Repeated squaring: ((W2)2)2... = W2lg n = Wn-1 = (δ(i, j)) if no negative-weight cycles. Time complexity of this algorithm is now O(n³ lgn).
We can't use Strassen, etc. since our new multiplication and addition operations don't support negation.
(k)
1. Sub-problems: c) = weight of shortest path u → v whose intermediate
vertices ∈ {1,2,..., k}
2. Guessing: Does shortest path use vertex k?
3. Recurrence:
c(k) = min(c(k-1), c(k-1) + C(k-1))
cuv              cuk      Ckv
c(0) = w(u, v)
cuv
4. Topological ordering: for k: for u and v in V:
5. Original problem: δ(u, v) = c(n). Negative weight cycle ⇒ negative c(n)
Time complexity
This Dynamic Program contains O(V³) problems as well. However, in this case, it takes only O(1) time to solve each sub-problem, which means that the total runtime of this algorithm is O(V³).
1 C = (w(u, v))
2 for k = 1 to n by 1
3 for u in V
4 for v in V
5 if Cuv > Cuk + Ckv
6 Cuv = Cuk + Ckv
As before, we choose to ignore subscripts.
1. Find function h : V → R such that wh(u, v) = w(u, v) + h(u) – h(v) ≥ 0 for all
u, v ∈ V or determine that a negative-weight cycle exists.
2. Run Dijkstra's algorithm on (V, E, wh) from every source vertex s ∈ V ⇒ get
δη(u, v) for all u, v ∈ V
3. Given δη(u, v), it is easy to compute δ(u, v)
Claim. δ(u, v) = δη(u, v) – h(u) + h(v)
Proof. Look at any u → v path p in the graph G
Say p is vo → U1 → U2 → …… → Uk, where v₁ = u and vk = v.
Wh(p) = ∑Wh(Vi-1, Vi) = ∑[W(Vi−1, Vi) + h(vi−1) - h(vi)] = ∑(Vi-1, Vi) + h(vo) – h(vk) = w(p) + h(u) – h(v)
Hence all u → v paths change in weight by the same offset h(u) – h(v),
which implies that the shortest path is preserved (but offset).
We know that
wn(u, v) = w(u, v) + h(u) – h(v) ≥ 0
This is equivalent to,
h(v) – h(u) ≤ w(u, v)
for all (u, v) ∈ V. This is called a system of difference constraints.
Theorem. If (V, E, w) has a negative-weight cycle, then there exists no solution to
the above system of difference constraints.
Say vo → V1 → … → Uk → vo is a negative weight cycle.
Let us assume to the contrary that the system of difference constraints has a
solution; let's call it h.
This gives us the following system of equations,
h(v₁) - h(vo) ≤ w(νο, υ1)
h(v2) - h(v1) ≤ w(v1, v2)
:
h(vk) – h(Uk-1) ≤ W(Uk−1, Uk)
h(vo) - h(vk) ≤ w(υκ, υο)
Summing all these equations gives us 0 < w(cycle) < 0 which is obviously not possible. From this, we can conclude that no solution to the above system of difference constraints exists if the graph (V, E, w) has a negative weight cycle.
Theorem. If (V, E,w) has no negative-weight cycle, then we can find a solution to the difference constraints.
Add a new vertex s to G, and add edges (s, v) of weight 0 for all v ∈ V.
Clearly, these new edges do not introduce any new negative weight cycles to the graph
Adding these new edges ensures that there now exists at least one path from s
to v. This implies that d(s, v) is finite for all v ∈ V
We now claim that h(v) = d(s, v). This is obvious from the triangle inequality:
δ(s, u) + w(u, v) ≥ δ(s, v) ⇔ δ(s, v) – δ(s, u) ≤ w(u, v) ⇔ h(v) – h(u) ≤ w(u, v)
1. The first step involves running Bellman-Ford from s, which takes O(VE) time.
We also pay a pre-processing cost to reweight all the edges (O(E))
2. We then run Dijkstra's algorithm from each of the V vertices in the graph; the
total time complexity of this step is O(VE + V2 lg V)
3. We then need to reweight the shortest paths for each pair; this takes O(V2) time.
The total running time of this algorithm is O(VE + V² lg V).
Bellman-Ford consult any system of difference constraints (or report that it is un-solvable) in O(VE) time where V = variables and E = constraints. An exercise is to prove the Bellman-Ford minimizes maxi Xi mini Xi.
This has applications to:
Real-time programming
Multimedia scheduling
Temporal reasoning
For example, you can bound the duration of an event via difference constraint LB < tend - tstart < UB, or bound a gap between events via 0 < tstart2 - tend1 ≤ ε, or synchronize events via |tstart1 - tstart2| ≤ ɛ or 0.
A polynomial \(A(x)\) can be written as:

\(A(x) = a_0 + a_1x + a_2x^2 + \cdots + a_{n-1}x^{n-1} = \sum_{k=0}^{n-1} a_kx^k = (a_0, a_1, a_2, \ldots, a_{n-1})\) (coefficient vector).
The three primary operations for polynomials are evaluation, addition, and multiplication.
Given a polynomial \(A(x)\) and a number \(x_0\), compute \(A(x_0)\). This can be done in \(O(n)\) time using \(O(n)\) arithmetic operations via Horner's rule: \(A(x) = a_0 + x(a_1 + x(a_2 + \cdots x(a_{n-1})\cdots))\). \(O(n)\) multiplications and \(O(n)\) additions are required.
Given two polynomials \(A(x)\) and \(B(x)\), compute \(C(x) = A(x) + B(x)\). This takes \(O(n)\) time using basic arithmetic, because \(c_k = a_k + b_k\).
Given two polynomials \(A(x)\) and \(B(x)\), compute \(C(x) = A(x) \cdot B(x)\). Then \(c_k = \sum_{j=0}^{k} a_j b_{k-j}\) for \(0 \leq k \leq 2(n-1)\), because the degree of the resulting polynomial is twice that of \(A\) or \(B\). The convolution is the inner product of all relative shifts, an operation also useful for smoothing etc. in digital signal processing.
Naive polynomial multiplication takes \(O(n^2)\).
\(O(n^{1.83})\) or even \(O(n^{1+\epsilon})\) (for \(\epsilon > 0\)) is possible via Strassen-like divide-and-conquer tricks.
Today, we will compute the product in \(O(n \lg n)\) time via Fast Fourier Transform!
The 3 main representations of polynomials to consider are:
1. Coefficient vector with a monomial basis
2. Roots and a scale term
3. Samples
A(x) = (x - r_0) \cdot (x - r_1) \cdot \ldots \cdot (x - r_{n-1}) \cdot c
It is impossible to find exact roots with only basic arithmetic operations and kth root operations. Furthermore, addition is extremely hard with this representation, or even impossible. Multiplication simply requires roots to be concatenated, and evaluation can be completed in O(n).
Samples: (x_0, y_0), (x_1, y_1), \ldots, (x_{n-1}, y_{n-1}) with \(A(x_i) = y_i\) (\(\forall i\)) and each \(x_i\) is distinct. These samples uniquely determine a degree \(n - 1\) polynomial \(A\), according to the Lagrange and Fundamental Theorem of Algebra. Addition and multiplication can be computed by adding and multiplying the \(y_i\) terms, assuming that the \(x_i\)'s match. However, evaluation requires interpolation.
Consider the polynomial in matrix form:

\[
\begin{bmatrix}
1 & x_0 & x_0^2 & \cdots & x_0^{n-1} \\
1 & x_1 & x_1^2 & \cdots & x_1^{n-1} \\
1 & x_2 & x_2^2 & \cdots & x_2^{n-1} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1 & x_{n-1} & x_{n-1}^2 & \cdots & x_{n-1}^{n-1}
\end{bmatrix}
\begin{bmatrix}
a_0 \\
a_1 \\
a_2 \\
\vdots \\
a_{n-1}
\end{bmatrix}
=
\begin{bmatrix}
y_0 \\
y_1 \\
y_2 \\
\vdots \\
y_{n-1}
\end{bmatrix}
\]

where V is the Vandermonde matrix with entries \(v_{jk} = x_k^j\).
Then we can convert between coefficients and samples using the matrix vector product \(V \cdot A\), which is equivalent to evaluation. This takes \(O(n^2)\).
Similarly, we can samples to coefficients by solving \(V\backslash Y\) (in MATLAB® notation). This takes \(O(n^3)\) via Gaussian elimination, or \(O(n^2)\) to compute \(A = V^{-1} \cdot Y\), if \(V^{-1}\) is precomputed.
Polynomial multiplication can be formulated as a divide and conquer algorithm with the following steps for a polynomial \(A(x)\) \(\forall x \in X\):

1. Divide the polynomial \(A\) into its even and odd coefficients:
\(A_{even}(x) = \sum_{k=0}^{\lfloor \frac{n}{2} - 1 \rfloor} a_{2k}x^k = (a_0, a_2, a_4, \ldots)\)
\(A_{odd}(x) = \sum_{k=0}^{\lfloor \frac{n}{2} - 1 \rfloor} a_{2k+1}x^k = (a_1, a_3, a_5, \ldots)\)

2. Recursively conquer \(A_{even}(y)\) for \(y \in X^2\) and \(A_{odd}(y)\) for \(y \in X^2\), where \(X^2 = \{ x^2 \mid x \in X \}\).

3. Combine the terms: \(A(x) = A_{even}(x^2) + x \cdot A_{odd}(x^2)\) for \(x \in X\).
Collapsing sets can be constructed via square roots. Each of the following collapsing sets is computing by taking all square roots of the previous set.
1. \(\{1\}\)
2. \(\{1,-1\}\)
3. \(\{1, -1, i, -i\}\)
4. \(\{1, -1, \pm \frac{\sqrt{2}}{2}(1 + i), \pm \frac{\sqrt{2}}{2}(-1 + i)\} \), which lie on a unit circle
The nth roots of unity are n x's such that \(x^n = 1\). These points are uniformly spaced around the unit circle in the complex plane (including 1). These points are of the form \((\cos \theta, \sin \theta) = \cos \theta + i \sin \theta = e^{i\theta}\) by Euler's Formula, for \(\theta = 0, \frac{\tau}{n}, \frac{2\tau}{n}, \ldots, \frac{n-1}{n}\tau\) (where \(\tau = 2\pi\)).
The nth roots of unity where \(n = 2^p\) form a collapsing set, because \((e^{i\theta})^2 = e^{i(2\theta)} = e^{i(2\theta \mod \tau)}\). Therefore the even nth roots of unity are equivalent to the \(\frac{n}{2}\)nd roots of unity.
The DFT allows the transformation between coefficients and samples, computing \(A^* = V \cdot A\) for \(x_k = e^{i\tau k/n}\) where \(n = 2^p\), where \(A\) is the set of coefficients and \(A^*\) is the resulting samples. The individual terms \(a_k^* = \sum_{j=0}^{n-1} e^{i\tau jk/n} \cdot a_j\).
The FFT algorithm is an \(O(n \lg n)\) divide and conquer algorithm for DFT, used by Gauss circa 1805, and popularized by Cooley and Turkey and 1965. Gauss used the algorithm to determine periodic asteroid orbits, while Cooley and Turkey used it to detect Soviet nuclear tests from offshore readings.
A practical implementation of FFT is FFTW, which was described by Frigo and Johnson at MIT. The algorithm is often implemented directly in hardware, for fixed \(n\).
The Inverse Discrete Fourier Transform is an algorithm to return the coefficients of a polynomial from the multiplied samples. The transformation is of the form \(A^* \rightarrow V^{-1} \cdot A^* = A\). In order to compute this, we need to find \(V^{-1}\), which in fact has a very nice structure.

Claim 1. \(V^{-1} = \frac{1}{n} \overline{V}\), where \(\overline{V}\) is the complex conjugate of \(V\).
In order to compute the product of two polynomials \(A\) and \(B\), we can perform the following steps:

1. Compute \(A^* = FFT(A)\) and \(B^* = FFT(B)\), which converts both \(A\) and \(B\) from coefficient vectors to a sample representation.
2. Compute \(C^* = A^* \cdot B^*\) in sample representation in linear time by calculating \(C_k^* = A_k^* \cdot B_k^*\) (\(\forall k\)).
3. Compute \(C = IFFT(C^*)\), which is a vector representation of our final solution.
Fourier (frequency) space many applications. The polynomial \(A^* = FFT(A)\) is complex, and the amplitude \(|a_k^*|\) represents the amplitude of the frequency-k signal, while \(\arg(a_k^*)\) (the angle of the 2D vector) represents the phase shift of that signal. For example, this perspective is particularly useful for audio processing, as used by Adobe Audition, Audacity, etc.:

*   High-pass filters zero out high frequencies
*   Low-pass filters zero out low frequencies
*   Pitch shifts shift the frequency vector
*   Used in MP3 compression, etc.
Series of Improved Data Structures, Insert, Successor, Delete, and Space
To perform Insert, Delete and Successor operations in O(log log u) time.
O(log log n)
Binary search over O(log u) elements. Recurrences: T(log u) = T(log u / 2) + O(1), T(u) = T(√u) + O(1)
By splitting up the range {0, 1, 2, ..., u – 1} into √u clusters of size √u. If x = i√u + j, then V[x] = V.Cluster[i][j]. The formulas are: low(x) = x mod √u = j, high(x) = floor(x / √u) = i, index(i, j) = i√u + j
Set V.cluster[high(x)][low(x)] = 1, the time complexity is O(1).
Mark cluster high(x) as non-empty with O(1) time complexity.
Look within cluster high(x) with complexity O(√u). Else, find next non-empty cluster i with O(√u). Find minimum entry j in that cluster with O(√u). Return index(i, j). Total time complexity: O(√u)
1 Insert(V.cluster[high(x)], low[x]). 2 Insert(V.summary, high(x)).
T(u) = 2T(√u) + O(1); T'(log u) = 2T'(log u / 2) + O(1) => T(u) = T'(log u) = O(log u)
1 i = high(x). 2 j = Successor(V.cluster[i], j). 3 if j = = ∞, 4 i = Successor(V.summary, i). 5 j = Successor(V.cluster[i], -∞). 6 return index(i, j)
We need to reduce the number of recursions to one.
We store the minimum and maximum entry in each structure. This gives an O(1) time overhead for each Insert operation.
1 i = high(x). 2 if low(x) < V.cluster[i].max, 3 j = Successor(V.cluster[i], low(x)). 4 else i = Successor(V.summary, high(x)). 5 j = V.cluster[i].min. 6 return index(i, j).
T(u) = T(√u) + O(1) => T(u) = O(log log u)
The Successor call now needs to check for the min separately.  if x < V.min : return V.min
1 if V.min == None, 2 V.min = V.max = x ▷ O(1) time, 3 return, 4 if x < V.min, 5 swap(x <-> V.min), 6 if x > V.max, 7 V.max = x), 8 if V.cluster[high(x) == None, 9 Insert(V.summary, high(x)) ▷ First Call, 10 Insert(V.cluster.high(x)], low(x)) ▷ Second Call
T(u) = T(√u) + O(1) => T(u) = O(log log u)
1 if x == V.min ▷ Find new min, 2 i = V.summary.min, 3 if i = None, 4 V.min = V.max = None ▷ O(1) time, 5 return, 6 V.min = index(i, V.cluster[i].min) ▷ Unstore new min, 7 Delete(V.cluster[high(x)], low(x)) ▷ First Call, 8 if V.cluster[high(x)].min == None, 9 Delete(V.summary, high(x)) ▷ Second Call, 10 ▷ Now we update V.max, 11 if x == V.max, 12 if V.summary.max = None, 13 else, 14 i = V.summary.max, 15 V.max = index(i, V.cluster[i].max)
T(u) = T(√u) + O(1) => T(u) = O(log log u)
Ω(log logu) time per query for u = n^(log n)^(o(1)). O(n poly(log n)) space
We can improve from Θ(u) to O(n log log u). Only create nonempty clusters If V.min becomes None, deallocate V. Store V.cluster as a hashtable of nonempty clusters. Each insert may create a new structure O(log log u) times (each empty insert)Can actually happen [Vladimir Čunát]. Charge pointer to structure (and associated hash table entry) to the structure. This gives us O(n log log u) space (but randomized).
Store vEB structure with n = O(log log u) using BST or even an array => O(log log n) time once in base case. We use O(n/ log log u) such structures (disjoint) => O(log logn * log logu) = O(n) space for small. Larger structures “store” pointers to them => O(log logn * log logu) = O(n) space for large. Details: Split/Merge small structures
Greedy Algorithms and Minimum Spanning Tree, including Optimal Substructure, Greedy Choice Property, Prim's algorithm and Kruskal's algorithm.
A greedy algorithm repeatedly makes a locally best choice or decision, but ignores the effects of the future.
A tree is a connected, acyclic graph. A spanning tree of a graph G is a subset of the edges of G that form a tree and include all vertices of G.
Given an undirected graph G = (V, E) and edge weights W : E → R, find a spanning tree T of minimum weight Σe∈T w(e).
The obvious MST algorithm is to compute the weight of every tree, and return the tree of minimum weight. Unfortunately, this can take exponential time in the worst case. In the worst case, there can be an exponential number of spanning trees.
Optimal Substructure: the optimal solution to a problem incorporates the optimal solution to subproblem(s). Greedy choice property: locally optimal choices lead to a globally optimal solution.
If T' is a minimum spanning tree of G/e, then T' ∪ {e} is an MST of G.
For any cut (S, V \ S) in a graph G = (V, E, w), any least-weight crossing edge e = {u, v} with u ∈ S and v ∉ S is in some MST of G.
1 Maintain priority queue Q on V \ S, where v.key = min{w(u, v) | u ∈ S}
2 Q=V
3 Choose arbitrary start vertex s ∈ V, s.key = Ø
4 for v in V \{s}
5  v.key = ∞
6 while Q is not empty
7  u = Extract-Min(Q), add u to S
8  for v ∈ Adj[u]
9   if v ∈ Q and v ∉ S and w(u, v) < v.key:
10    v.key = w(u, v) (via a Decrease-Key operation)
11    v.parent = u
12 return {{v, v.parent} | v ∈ V \ {s}}
1. v ¢ S = v.key = min{w(u, v) | u ∈ S}
2. Tree Ts within SC MST of G.
O(V)·TExtract-Min + O(E) ·TDecrease-Key
Kruskal's Algorithm is another algorithm to solve the MST problem. It constructs an MST by taking the globally lowest-weight edge and contracting it.
1 Maintain connected components that have been added to the
MST so far T, in a Union-Find structure
2 Initialize T = 0
3 for v in V
4  Make-Set(v)
5 Sort E by weight
6 For e = (u, v) ∈ E (in increasing-weight order):
7  if Find-Set(u) ≠ Find-Set(v):
8   Add e to T
9   Union(u, v)
The tree-so-far T ⊆ MST T*.
Tsort(E) + O(V) · TMake-Set + O(E)(TFind + TUnion) = O(Elg E + Ea(V))
Currently, the fastest MST algorithm is a randomized algorithm with an expected runtime of O(V + E). The algorithm was proposed by Karger, Klein, and Tarjan in 1993.
The lecture covers: Symmetric key encryption, Key exchange, Asymmetric key encryption, RSA, NP-complete problems and cryptography (graph coloring, knapsack).
Symmetric key encryption involves the following equations: \(c = e_k(m)\) and \(m = d_k(c)\), where \(c\) is the ciphertext, \(m\) is the plaintext, \(e\) is the encryption function, \(d\) is the decryption function, and \(k\) is the secret key. \(e\) and \(d\) permute and reverse-permute the space of all messages. Reversible operations include ⊕, +/-, and shift left/right. Examples of symmetric algorithms are AES, RC5, and DES.
The key management question is: How does the secret key \(k\) get exchanged/shared? Alice wants to send a message to Bob, but there are pirates who will take any keys or messages in unlocked boxes but won't touch locked boxes. The solution is: Alice puts message \(m\) in a box, locks it with key \(k_a\), and sends the box to Bob. Bob locks the box with key \(k_b\), and sends it to Alice. Alice unlocks the box with \(k_a\), and sends it to Bob. Bob unlocks the box with \(k_b\), and reads \(m\). This relies on the commutativity of the locks.
In Diffie-Hellman Key Exchange, \(G = F_p^*\), where \(F_p\) is a finite field (mod \(p\), a prime), and \(*\) means invertible elements only (\({1, 2, ..., p - 1}\)). Alice selects a and computes \(g^a\), while Bob selects b and computes \(g^b\). Alice can compute \((g^b)^a \mod p = k\), and Bob can compute \((g^a)^b \mod p = k\). This assumes the Discrete Log Problem is hard (given \(g^a\), compute a) and the Diffie-Hellman Problem is hard (given \(g^a, g^b\), compute \(g^{ab}\)). A potential attack is the Man-in-the-middle attack, where Alice and Bob unknowingly communicate with Eve instead.
Public key encryption involves: message + public key = ciphertext; ciphertext + private key = message. The two keys need to be linked in a mathematical way, and knowing the public key should not reveal the private key.
In RSA: Alice picks two large secret primes \(p\) and \(q\). Alice computes \(N = p \cdot q\). Alice chooses an encryption exponent \(e\) such that \(\gcd(e, (p - 1)(q - 1)) = 1\), with examples of \(e = 3, 17, 65537\). Alice's public key is \((N, e)\). The decryption exponent \(d\) is obtained using the Extended Euclidean Algorithm by Alice such that \(ed = 1 \mod (p - 1)(q - 1)\). Alice's private key is \((d, p, q)\). Encryption: \(c = m^e \mod N\). Decryption: \(m = c^d \mod N\).
The hardness of RSA relies on: Factoring, where given \(N\), it is hard to factor into \(p\) and \(q\). Also, the RSA Problem states that given \(e\) such that \(\gcd(e, (p - 1)(q - 1)) = 1\) and \(c\), it's hard to find \(m\) such that \(m^e = c \mod N\).
NP-completeness covers problems like determining if \(N\) is composite with a factor within a range, if a graph is \(k\)-colorable, and given a pile of \(n\) items with different weights \(w_i\), if it is possible to put items in a knapsack such that we get a specific total weight \(S\). These problems are NP-complete.
NP-completeness is about worst-case complexity, while cryptography wants a problem instance, with suitably chosen parameters that is hard on average. Most knapsack cryptosystems have failed. Determining if a graph is 3-colorable is NP-complete but easy on average because an average graph, beyond a certain size, is not 3-colorable. A standard backtracking search involves ordering vertices, traversing the graph, and on visiting a vertex, choosing the smallest possible color that works.
General knapsack problem: NP-complete. Super-increasing knapsack: linear time solvable, where \(w_j \geq \sum_{i=1}^{j-1} w_i\).  Merkle Hellman Cryptosystem uses a Private transform, transforming private key (super-increasing knapsack problem) to a "hard" general knapsack problem, and produces a public key. Transform: two private integers \(N, M\) such that \(\gcd(N, M) = 1\). Multiply all values in the sequence by \(N\) and then take mod \(M\). Example: \(N = 31, M = 105\), private key = {2, 3, 6, 14, 27, 52}, public key={62, 93, 81, 88, 102, 37}.
Merkle Hellman Example: Let \(N = 31, M = 105\), the private key = {2, 3, 6, 14, 27, 52} and the public key={62, 93, 81, 88, 102, 37}. 
If Message = 011000, 110101, 101110 then
Ciphertext:011000 = 93+81 = 174
110101 = 62+93 +88 +37 = 280
101110 = 62+81+88 + 102 = 333
= 174, 280, 333
Recipient knows \(N = 31, M = 105\), {2, 3, 6, 14, 27, 52}. Multiplies each ciphertext block by \(N^{-1} \mod M\). In this case, \(N^{-1} = 61 \mod 105\).
174*61=9 = 3 + 6 = 011000
280*61=70 = 2 + 3 + 13 + 52 = 110101
333*61 = 48 = 2 + 6 + 13 + 27 = 101110
Density of knapsack \(d = \frac{n}{\max{\log_2 w_i:1 \leq i \leq n}}\). Lattice basis reduction can solve knapsacks of low density. Unfortunately, M-H scheme always produces knapsacks of low density.
Review: dictionaries, chaining, simple uniform, Universal hashing, Perfect hashing
A dictionary is an Abstract Data Type (ADT) that maintains a set of items. Each item has a key. The dictionary supports the following operations: insert(item): add item to set, delete(item): remove item from set, search(key): return item with key if it exists. We assume that items have distinct keys (or that inserting new ones clobbers old ones).
This problem is easier than predecessor/successor problems solved in previous lecture (by van Emde Boas trees, or by AVL/2-3 trees/skip lists).
O(1) time per operation and O(n) space complexity.
n = number of keys over all possible items,  m = number of keys/items currently in the table, m = number of slots in the table
Pr {h(k₁) = h(k₂)} = 1/m. We achieve (1 + a) time per operation, where a = n/m is called load factor. The downside of the algorithm is that it requires assuming input keys are random, and it only works in average case, like basic quicksort. Today we are going to remove the unreasonable simple uniform hashing assumption.
"cut into small pieces", which comes from the French ‘hacher‘which means “chop up”, which comes from the Old French ‘hache’ which means “axe” (cf. English ‘hatchet'). Alternatively, perhaps they come from Vulcan 'la'ash', which means “axe”. (R.I.P. Leonard Nimoy.)
choose a random hash function h from H, require H to be a universal hashing family such that Pr {h(k) = h(k')} ≤ 1/m for all k≠ k'
For n arbitrary distinct keys and random h∈ H, where H is a universal hashing family, E[ number of keys colliding in a slot ] < 1 + α where a = n/m
Consider keys k1,k2, ..., kn. Let Ii,j =
{
1 if h(k) = h(kj)
0 otherwise
}. Then we have
E[Ii,j] = Pr{Ii,j = 1}
= Pr{h(ki) = h(kj)}
< 1/m for any j≠ i
E[# keys hashing to the same slot as ki] = E[∑j=1 Ii,j]
= ∑j=1E[i,j] (linearity of expectation)
= ∑j≠iE[i,j] + E[Ii,i]
<n/m +1
H = {all hash functions h : {0, 1, . . ., u − 1} → {0, 1, . . ., m - 1}}. Apparently, H is universal, but it is useless. On one hand, storing a single hashing function h takes log(m²) = ulog(m) bits » n bits. On the other hand, we would need to precompute u values, which takes Ω(u) time.
m is a prime
ha(k) = ∑i=0^(r-1) aiki mod m
Dot-product hash family His universal.
Take any two keys k ≠ k'. They must differ in some digits. Say ka ≠ ka'.
Define not d = {0, 1, . . ., r − 1} \{d}. Now we have
Pr{ha(k) = ha(k')} = Pr[∑i=0^(r-1) aiki = ∑i=0^(r-1)aiki' (mod m)]
= Pr[∑i≠d aiki + adka = ∑i≠d aiki' + adka' (mod m)]
= Pr[∑i≠d ai(ki - ki') + ad(ka - ka') = 0 (mod m)]
= Pr[ad = -(ka - ka')^(-1) ∑i≠d ai(ki – ki') (mod m)]
(m is prime ⇒ Zm has multiplicative inverses)
= E [Pr{ad = f(k, k', anot d)}]
Choose prime p > u (once). Define hab(k) = [(ak + b) mod p)] mod m. Let H = {hab | a, b ∈ {0, 1, . . ., u – 1}}.
Given n keys to store in table, only need to support search(k). No insertion or deletion will happen.
[Fredman, Komlós, Szemerédi 1984], polynomial build time with high probability (w.h.p.), O(1) time for search in worst case, O(n) space in worst case. Idea: 2-level hashing
Step 1: Pick h₁ : {0, 1, . . ., u − 1} → {0,1,..., m - 1} from a universal hash family for m = O(n) (e.g., nearby prime). Hash all items with chaining using h₁.
Step 2: For each slot j∈ {0,1, . . ., m − 1}, let lj be the number of items in slot j. lj = |{i | h(ki) = j}|. Pick h2,j : {0, 1, ..., u − 1} → {0,1,..., m;} from a universal hash family for lj <= m; <= O(13) (e.g., nearby prime). Replace chain in slot j with hashing-with-chaining using h₂,j.
The space complexity is O(n + ∑j=0^(m-1)13). In order to reduce it to O(n), we need to add two more steps:
Step 1.5: If ∑j=0^(m-1)12 > cn where c is a chose constant, then redo Step 1.
Step 2.5: While h2,j(ki) = h2,j(k) for any i ≠ i', j, repick h2,j and rehash those lj.
The above two steps guarantee that there are no collisions at second level, and the space complexity is O(n). As a result, search time is O(1). Now let's look at the build time of the algorithm. Both Step 1 and Step 2 are O(n). How about Step 1.5 and Step 2.5?
For Step 2.5,
Pr{h2.j(ki) = h2.j(k) for some i ≠ i'} < ∑i≠i' Pr{h2,j (ki) = h2,j (k)} (union bound)
< (1/12) *1/2 <=1/2
As a result, each trial is like a coin flip. If the outcome is “tail”, we move to the next step. By Lecture 7, we have E[#trials] < 2 and #trials = O(log n) w.h.p. By a Chernoff bound, lj = O(log n) w.h.p., so each trial takes O(logn) time. Because we have to do this for each j, the total time complexity is O(log n) · O(log n) · O(n) =
O(nlog² n) w.h.p.
For Step 1.5, we define Ii,i' = {
1 if h(k) = h(k)
0 otherwise
}. Then we have
E[∑j=0^(m-1)12] = E[∑i=1^(n)∑i'=1^(n)Ii,i'] = ∑i=1^(n)∑i'=1^(n)E[Ii,i’]≤n+2(n 2) *1/m = O(n) because m = O(n)
By Markov inequality, we have
Pr(∑j=0^(m-1) 12 > cn) < E[∑j=0^(m-1) 12] / cn <1/2
for a sufficiently large constant c. By Lecture 7, we have E[#trials] < 2 and #trials =
O(log n) w.h.p. As a result, Step 1 and Step 1.5 combined takes O(n log n) time w.h.p.
Longest palindromic sequence, Optimal binary search tree, and Alternating coin game.
1. Characterize the structure of an optimal solution. 2. Recursively define the value of an optimal solution based on optimal solutions of subproblems. 3. Compute the value of an optimal solution in bottom-up fashion (recursion & memoization). 4. Construct an optimal solution from the computed information.
Definition: A palindrome is a string that is unchanged when reversed. Examples: radar, civic, t, bb, redder. Given: A string X[1…n], n ≥ 1. To find: Longest palindrome that is a subsequence. Example: Given “character", output "carac". Answer will be ≥ 1 in length.
Strategy: L(i, j): length of longest palindromic subsequence of X[i··· j] for i < j. Code: 1 def L(i, j) : 2 if i == j: return 1 3 if X[i] == X[j]: 4 if i + 1 == j: return 2 5 else: return 2 + L(i + 1, j - 1) 6 else: 7 return max(L(i + 1, j), L(i, j - 1)). Analysis: As written, program can run in exponential time: suppose all symbols X[i] are distinct. \(T(n)\) = running time on input of length n. \(T(n) = \begin{cases} 1 & n=1 \\ 2T(n - 1) & n > 1 \end{cases} = 2^{n-1}\)
But there are only \(\binom{n}{2} = \theta(n^2)\) distinct subproblems: each is an (i, j) pair with i < j. By solving each subproblem only once. running time reduces to \(\theta(n^2) \cdot \theta(1) = \theta(n^2)\), where 0(n²) is the number of subproblems and 0(1) is the time to solve each subproblem, given that smaller ones are solved. Memoize L(i, j), hash inputs to get output value, and lookup hash table to see if the subproblem is already solved, else recurse.
1. Memoizing uses a dictionary for L(i, j) where value of L is looked up by using i, j as a key. Could just use a 2-D array here where null entries signify that the problem has not yet been solved. 2. Can solve subproblems in order of increasing j − i so smaller ones are solved first.
Given: keys \(K_1, K_2, \dots, K_n, K_1 < K_2 < \dots < K_n\), WLOG \(K_i = i\), weights \(W_1, W_2, \dots, W_n\). Find: BST T that minimizes: \(\sum_{i=1}^{n} W_i \cdot (depth_T(K_i) + 1)\). Example: \(W_i = p_i = \)probability of searching for \(K_i\). Then, we are minimizing expected search cost. (say we are representing an English \(\rightarrow\) French dictionary and common words should have greater weight).
Exponentially many trees. n = 2: 1 2,  2 1. n = 3: 3 2 1, 2 3 1, 2 1 3, 1 3 2, 1 2 3
\(W(i, j) = W_i + W_{i+1} + \cdots + W_j\), \(e(i, j) =\) cost of optimal BST on \(K_i, K_{i+1}, \dots, K_j\). Want \(e(1, n)\). Greedy solution? Pick \(K_i\) in some greedy fashion, e.g., \(W_i\) is maximum. greedy doesn't work, see example at the end of the notes.
\(e(i, j) = \begin{cases} W_i & \text{if } i = j \\ \min_{i<r<j} (e(i, r - 1) + e(r + 1, j) + W(i, j)) & \text{else} \end{cases}\) +W(i, j) accounts for \(W_r\) of root \(K_r\) as well as the increase in depth by 1 of all the other keys in the subtrees of \(K_r\) (DP tries all ways of making local choices and takes advantage of overlapping subproblems) Complexity: \(O(n^2) \cdot O(n) = O(n^3)\) where (n²) is the number of subproblems and 0(n) is the time per subproblem.
Row of n coins of values \(V_1, \dots, V_n\), n is even. In each turn, a player selects either the first or last coin from the row, removes it permanently, and receives the value of the coin.
Question: Can the first player always win? Try: 4 42 39 17 25 6. Strategy: \(V_1, V_2, ..., V_{n-1}, V_n\). 1. Compare \(V_1 + V_3 + \dots + V_{n-1}\) against \(V_2 + V_4 + \dots + V_n\) and pick whichever is greater. 2. During the game only pick from the chosen subset (you will always be able to!). How to maximize the amount of money won assuming you move first?
\(V(i, j)\): max value we can definitely win if it is our turn and only coins \(V_i, ..., V_j\) remain. \(V(i, i)\): just pick i. \(V(i, i + 1)\): pick the maximum of the two. \(V(i, i + 2), V(i, i + 3), ...\). \(V(i, j) = max\{(range becomes (i + 1, j)) + V_i, (range becomes (i, j - 1)) + V_j\}\) Solution: \(V(i + 1, j)\) subproblem with opponent picking we are guaranteed \(min\{V(i + 1, j - 1), V(i + 2, j)\} \)Where V(i+1, j−1) corresponds to opponent picking \(V_j\) and V(i+2, j) corresponds to opponent picking \(V_{i+1}\) We have \(V(i, j) = max \{\min \{V(i + 1, j - 1), V(i + 2, j)\} + V_i, \min \{V(i, j - 2), V(i + 1, j - 1)\} + V_j\}\) Complexity? \(\Theta(n^2) \cdot \Theta(1) = \Theta(n^2)\)
Algorithms that run on networked processors, or on multiprocessors that share memory. They solve many kinds of problems such as Communication, Data management, Resource management, Synchronization and Reaching consensus. They work in difficult settings where there is Concurrent activity at many processing locations, Uncertainty of timing, order of events, inputs and Failure and recovery of processors, of channels. So they can be complicated and Hard to design, prove correct, and analyze.
They have been Studied since 1967, starting with Dijkstra and Lamport. Some source materials include Lynch, Distributed Algorithms, Attiya and Welch, Distributed Computing: Fundamentals, Simulations, and Advanced Topics, Morgan Claypool series of monographs on Distributed Computing Theory. Conferences include Principles of Distributed Computing (PODC) and Distributed Computing (DISC).
Distributed algorithms are modeled with: Infinite-state interacting state machines. Proofs use invariants, proved by induction. Abstraction relations. New complexity measures which include Time complexity: Rounds, or real time, and Communication complexity: Messages, or bits.
They are Based on an undirected graph G = (V, E), where n= |V|,  Γ(u) is the set of neighbors of vertex u and deg(u) = |Г(u)| is the number of neighbors of vertex u. Each graph vertex is associated with a process which is an infinite-state automaton (Sometimes refer to processes, or vertices, as nodes). Associate two directed communication channels with each edge. We won't consider failures.
Processes at nodes of an undirected graph, communicate using messages. Each process has output ports, input ports that connect to communication channels. Process at vertex u doesn't know who its ports' channels connect to. They Knows the ports only by local names, such as 1, 2, ..., k, where k = deg(u). Processes need not be distinguishable E.g., they needn't have Unique Identifiers (UIDs). They just know how many ports they have, and their local names.
An algorithm executes in synchronous rounds. In each round, each process determines, based on its state, the messages to send on all its ports, where There is at most one message per port per round. Each message gets put into its channel, and delivered to the process at the other end. Then each process computes a new state based on its old state and the arriving messages. It generally ignore costs of local computation (time and space) and focus on time (number of rounds), and communication (number of messages or total number of bits).
Given an arbitrary connected (undirected) graph G = (V, E), the goal is for exactly one process to output a special leader signal. Motivation: Leader can take charge of Communication, Coordinating data processing, Allocating resources, Scheduling tasks and Reaching consensus.
Theorem 1: Let G = (V, E) be an n-vertex clique. Then there is no algorithm consisting of deterministic, indistinguishable processes that is guaranteed to elect a leader in G.  Proof: For example, consider n = 2. Two identical, deterministic processes. Show by induction that the processes remain in the same state forever.
Since the basic problem for distributed algorithms is breaking symmetry, we need something more. We can use Unique Identifiers (UIDs) where each process knows it. Different UIDs can appear anywhere in the graph, but each can appear only once. We can also use Randomness
Theorem 2: Let G = (V, E) be an n-vertex clique. Then there is an algorithm consisting of deterministic processes with UIDs that is guaranteed to elect a leader in G.  The algorithm takes only 1 round and uses only n² point-to-point messages. Everyone sends its UID on all its output ports, and collects UIDs received on all its input ports. The process with the maximum UID elects itself the leader.
Processes choose IDs randomly, from a sufficiently large set so that it is likely that all are different. Then use them like UIDs. Theorem 4: Let G = (V, E) be an n-vertex clique. Then there is an algorithm consisting of randomized, indistinguishable processes that eventually elects a leader in G, with probability 1. The algorithm takes expected time ≤ 1/(1-є). Processes choose random ids from a sufficiently large space. Exchange ids; if the maximum is unique, the maximum wins. Otherwise repeat, as many times as necessary.
Given a general undirected graph network, we Select a subset S of the nodes, so that they form a Maximal Independent Set. There can be no two neighbors that are both in the set(independent) and We can't add any more nodes without violating independence(maximal). Every node is either in S or has a neighbor in S.
We Assume No UIDs and Processes know a good upper bound on n. We Require compute an MIS S of the entire network graph where Each process in S should output in, others output out. It's Unsolvable by deterministic algorithms, in some graphs, so we consider randomized algorithms. Applications of distributed MIS include: Communication networks: Selected processes can take charge of communication, convey information to their neighbor processes and Developmental biology: Distinguish cells in fruit fly's nervous system to become "Sensory Organ Precursor" cells [Afek, Alon, et al., Science].
It Executes in 2-round phases. Initially all nodes are active. At each phase, some active nodes decide to be in, others decide to be out, algorithm continues to the next phase with a smaller graph. Repeat until all nodes have decided. Round 1: Choose a random value r in {1,2, ..., n5}, send it to all neighbors. Receive values from all active neighbors. If r is strictly greater than all received values, then join the MIS, output in.  Round 2: If you joined the MIS, announce it in messages to all (active) neighbors. If you receive such an announcement, decide not to join the MIS, output out. If you decided one way or the other at this phase, become inactive.
If Luby's algorithm ever terminates, then the final set S satisfies the independence and maximality property.  Theorem 5: Each node joins S only if it has the unique maximum value in its neighborhood, at some phase and When it does, all its neighbors become inactive(independence). Theorem 6: A node becomes inactive only if it joins S or a neighbor joins S. We continue until all nodes are inactive(maximality).
With probability 1, Luby's MIS algorithm eventually terminates. Theorem 7: With probability at least 1 - 1/n, all nodes decide within 4 log n phases.
Given a connected graph G = (V, E) , where V includes a distinguished vertex vo, which will be the origin (root) of the BFS tree. We assume processes have no knowledge about the graph and have UIDs. We also assume (WLOG) that processes know the UIDs of their neighbors, and know which input and output ports are connected to each neighbor. Algorithms will be deterministic (or nondeterministic), but not randomized.
Processes must produce a Breadth-First Spanning Tree rooted at vertex vo. Branches are directed paths from vo that reach all vertices(Spanning) and a vertex at distance d from vo appears at depth exactly d in the tree (Breadth-first). Each process i ≠ io should output parent(j), meaning that j's vertex is the parent of i's vertex in the BFS tree.
Processes mark themselves as they get incorporated into the tree. Initially, only io is marked. Round 1: If i = io then process i sends a search message to its neighbors. If process i receives a message, then it: Marks itself, Selects io as its parent, outputs parent(io) and Plans to send at the next round. Round r > 1: If process i planned to send, then it sends a search message to its neighbors. If process i is not marked and receives a message, then it: Marks itself, Selects one sending neighbor, j, as its parent, outputs parent(j) and Plans to send at the next round.
The algorithm is slightly nondeterministic, in that a process can choose arbitrarily among several possible parents.  For distributed algorithms, nondeterminism is regarded differently from the way it is for sequential algorithms. A distributed algorithm should work correctly for all ways of resolving the nondeterministic choices.
Key invariants include: At the end of r rounds, exactly the processes at distance ≤ r from v0 are marked. A process ≠ i0 has its parent defined iff it is marked. For any process at distance d from v0, if its parent is defined, then it is the UID of a process at distance d – 1 from v0 .
Time complexity: Number of rounds until all nodes outputs their parent information which is <= Maximum distance of any node from vo. Message complexity: Number of messages sent by all processes during the entire execution is 0(|E|).
Child pointers: So far, each process learns its parent, but not its children. To add child pointers, everyone who receives a search message sends back a parent or nonparent response, at the next round. Distances: Augment the algorithm so everyone also learns and outputs its distance from vo. Each process records its distance from vo in a new dist variable, initially 0 for process io, and ∞ for everyone else. Include the dist value in every search message; when an unmarked process receives a search(d) message, it sets its own dist to d + 1.
Assume each search message receives a response, parent or nonparent. After a node has received responses to all its outgoing search messages, it knows who its children are, and knows they are all marked. The leaves of the tree learn who they are (they receive only nonparent responses). Now use a convergecast strategy.
A process ≠ io can send a done message to its parent after: It has received responses to all its search messages (so it knows who its children are), and It has received done messages from all of its children. io knows that the BFS tree is completed, when: It has received responses to all its search messages (so it knows who its children are), and It has received done messages from all of its children.
After the tree is done, it takes ≤ diam rounds and n messages for the done information to reach io. Process io can broadcast a message to everyone along the edges of the tree. Takes an additional diam rounds and n messages.
Message broadcast: Process io can use a BFS tree with child pointers to broadcast a sequence of messages to all processes in the network. Could pipeline them, so k messages take only diam + k rounds, not diam × k. Global computation: Suppose every process starts with some initial value, and process io should determine the value of some function of the set of all processes' values.  Can use convergecast on a BFS tree. Can also apply the BFS construction to Leader election in a general graph where Every process can start its own BFS, acting as the root. Use this to determine the maximum UID; process with the max UID is the leader.
It Generalize the BFS problem to allow weights on the graph edges, weight{u,v} for edge {u, v}.  Processes know their neighbors and the weights of their incident edges, but otherwise have no knowledge about the graph.
Each process i ≠ io should output parent(j), distance(d), meaning that: j's vertex is the parent of i's vertex on a shortest path from vo, d is the total weight of a shortest path from vo to j.
Each process i has: dist, a nonnegative real or ∞, representing the shortest known distance from v₁. Initially 0 for process 10, ∞ for the others and parent, a UID or undefined, initially undefined. At each round: Send a distance(dist) message to all neighbors. Receive messages from neighbors; let dj be the distance received from neighbor j. Perform a relaxation step: dist := min(dist, min(dj + weight{i,j}) and If dist decreases then set parent := j, where j is any neighbor that produced the new dist.
Eventually, every process i has: dist = minimum weight of a path from io to i, and if i ≠ io, parent = the previous node on some shortest path from io to i. Key invariant: For every r, at the end of r rounds, every process i ≠ io has its dist and parent corresponding to a shortest path from io to i among those paths that consist of at most r edges; if there is no such path, then dist = ∞ and parent is undefined.
Number of rounds until all the variables stabilize to their final values which is n – 1 rounds. Message complexity: Number of messages sent by all processes during the entire execution which is  0(n·|E|). More expensive than BFS.
Ignore repeated messages. When process i receives a message that it does not use to improve dist, it responds with a nonparent message. When process i receives a message that it uses to improve dist, it responds with a parent message, and also responds to any previous parent with a nonparent message. Process i records nodes from which it receives parent messages in a set children. When process i receives a nonparent message from a current child, it removes the sender from its children. When process i improves dist, it empties children.
We can use convergecast.  A process ≠ io can send a done message to its current parent after: It has received responses to all its distance messages, so it believes it knows who its children are, and It has received done messages from all of those children and The same process may be involved several times in the convergecast, based on improved estimates.
Algorithms that run on networked processors, or on multiprocessors that share memory. They solve many kinds of problems, work in difficult settings, and are hard to design, prove correct, and analyze.
Studied since 1967, starting with Dijkstra and Lamport.
A quick introduction, synchronous distributed algorithms (Leader Election, Maximal Independent Set, Breadth-First Spanning Trees, Shortest Paths Trees), and Asynchronous distributed algorithms (Breadth-First Spanning Trees, Shortest Paths Trees)
Because they are complicated and error-prone.
Based on an undirected graph G = (V, E). n= |V|, Γ(u) (set of neighbors of vertex u), deg(u) = |Г(u)| (number of neighbors of vertex u).  Also, associate a process with each graph vertex and two directed communication channels with each edge.
Processes at nodes of an undirected graph communicate using messages. Each process has output ports, input ports that connect to communication channels. Process at vertex u doesn't know who its ports' channels connect to. Processes need not be distinguishable.
An algorithm executes in synchronous rounds. In each round, each process determines, based on its state, the messages to send on all its ports. Each message gets put into its channel, and delivered to the process at the other end. Then each process computes a new state based on its old state and the arriving messages.
Leader election's goal is for exactly one process to output a special leader signal.
By contradiction. Assume an algorithm A that solves the problem. Both processes begin in the same start state. Prove by induction on the number r of completed rounds that both processes are in identical states after r rounds. Since the algorithm solves the leader election problem, eventually one of them gets elected. Then they both get elected, contradiction.
Unique Identifiers (UIDs) are assumed. Or randomness.
Algorithm using UIDs:
Theorem 2: Let G = (V, E) be an n-vertex clique. Then there is an algorithm consisting of deterministic processes with UIDs that is guaranteed to elect a leader in G. The algorithm takes only 1 round and uses only n² point-to-point messages. Everyone sends its UID on all its output ports, and collects UIDs received on all its input ports. The process with the maximum UID elects itself the leader.

Algorithm using Randomness:
Theorem 4: Let G = (V, E) be an n-vertex clique. Then there is an algorithm consisting of randomized, indistinguishable processes that eventually elects a leader in G, with probability 1. The algorithm takes expected time ≤ 1/(1-є).  Also, with probability ≥ 1 – є, the algorithm finishes in only one round. Processes choose random ids from a sufficiently large space. Exchange ids; if the maximum is unique, the maximum wins. Otherwise repeat, as many times as necessary.
Select a subset S of the nodes, so that they form a Maximal Independent Set.
Independent: No two neighbors are both in the set.
Maximal: We can't add any more nodes without violating independence.
Every node is either in S or has a neighbor in S.
Executes in 2-round phases. Initially all nodes are active. At each phase, some active nodes decide to be in, others decide to be out, algorithm continues to the next phase with a smaller graph.  Repeat until all nodes have decided.

Round 1:
Choose a random value r in {1,2, ..., n5}, send it to all neighbors. Receive values from all active neighbors. If r is strictly greater than all received values, then join the MIS, output in.

Round 2:
If you joined the MIS, announce it in messages to all (active) neighbors. If you receive such an announcement, decide not to join the MIS, output out. If you decided one way or the other at this phase, become inactive.
Theorem 5: If Luby's algorithm ever terminates, then the final set S satisfies the independence property.
Proof:
Each node joins S only if it has the unique maximum value in its neighborhood, at some phase.  When it does, all its neighbors become inactive.

Theorem 6: If Luby's algorithm ever terminates, then the final set S satisfies the maximality property.
Proof:
A node becomes inactive only if it joins S or a neighbor joins S.
We continue until all nodes are inactive.
Theorem 7: With probability at least 1 – 1/n, all nodes decide within 4 log n phases.
Round 1:
If i = io then process i sends a search message to its neighbors. If process i receives a message, then it:
Marks itself.
Selects io as its parent, outputs parent(io).
Plans to send at the next round.
Round r > 1:
If process i planned to send, then it sends a search message to its neighbors.
If process i is not marked and receives a message, then it:
Marks itself.
Selects one sending neighbor, j, as its parent, outputs parent(j).
Plans to send at the next round.
State variables, per process:
marked, a Boolean, initially true for io, false for others
parent, a UID or undefined
send, a Boolean, initially true for io, false for others
uid
Invariants:
At the end of r rounds, exactly the processes at distance ≤ r from vo are marked.
A process ≠ io has its parent defined iff it is marked.
For any process at distance d from vo, if its parent is defined, then it is the UID of a process at distance d – 1 from vo.
Time complexity:
Number of rounds until all nodes outputs their parent information.
Maximum distance of any node from vo, which is ≤ diam
Message complexity:
Number of messages sent by all processes during the entire execution.
O(|E|)
Assume each search message receives a response, parent or nonparent. After a node has received responses to all its outgoing search messages, it knows who its children are, and knows they are all marked. The leaves of the tree learn who they are (they receive only nonparent responses).
Use a convergecast strategy:
Starting from the leaves, the processes fan in done messages up the
BFS tree, toward io.
State variables:
dist, a nonnegative real or ∞, representing the shortest known distance from v1. Initially 0 for process 10, ∞ for the others.
parent, a UID or undefined, initially undefined.
uid
Algorithm for process i:
At each round:
Send a distance(dist) message to all neighbors.
Receive messages from neighbors; let d; be the distance received from neighbor j.
Perform a relaxation step:
dist := min(dist, min(dj + weight{i,j}).
j
If dist decreases then set parent := j, where j is any neighbor that produced the new dist.
For every r, at the end of r rounds, every process i ≠ io has its dist and parent corresponding to a shortest path from io to i among those paths that consist of at most r edges; if there is no such path, then dist = ∞ and parent is undefined.
Time complexity:
Number of rounds until all the variables stabilize to their final values.
n – 1 rounds
Message complexity:
Number of messages sent by all processes during the entire execution.
O(n·|E|)
Hash functions, Random oracle model, Desirable Properties, Applications to security
A hash function h maps arbitrary strings of data to fixed length output. The function is deterministic and public, but the mapping should look 'random'. In other words, \(h : {0,1}* \rightarrow {0,1}^d\) for a fixed d. Hash functions do not have a secret key.
Hash functions are used for 'digesting' large data. For example, if you want to check the validity of a large file, you can check the hash value of that file with the expected hash.
It is desirable that the function is collision resistant, meaning it should be 'hard' to find two inputs M1 and m2 for hash function h such that \(h(m₁) = h(m2)\).
Most modern hash functions hope to achieve a security level of \(2^{64}\) or better. MD4 and MD5 aimed to provide \(2^{64}\) security but have been broken. SHA-1 aimed to provide \(2^{80}\) security but has been shown to be no more than \(2^{61}\) security.
The Random Oracle model is an ideal model of the hash function that is not achievable in practice. In this model, there exists an oracle h such that on input x, if h has not seen x before, then it outputs a random value as h(x). Otherwise, it returns h(x) it previously output.
1. One-way (pre-image resistance): Given \(y ∈ {0,1}^d\), it is hard to find an x such that \(h(x) = y\).
2. Strong collision-resistance: It is hard to find any pair of inputs x, x' such that \(h(x) = h(x')\).
3. Weak collision-resistance (target collision resistance, 2nd pre-image resistance): Given x, it is hard to find x' such that \(h(x) = h(x')\).
4. Pseudo-random: The function behaves indistinguishable from a random oracle.
5. Non-malleability: Given h(x), it is hard to generate h(f(x)) for any function f.
1. Password Storage: We can store hash h(p) for password p instead of p directly, and check h(p) to authenticate a user. 
2. File Authenticity: For each file F, we can store h(F) in a secure location. To check authenticity of a file, we can recompute h(F).
3. Digital Signature: We can use hash functions to generate a signature that guarantees that the message came from a said source.
4. Commitments: In a secure bidding, Alice wants to bid value x, but does not want to reveal the bid until the auction is over. Alice then computes h(x), and publicize it, which serves as her commitment.
Paradigm, Convex Hull, and Median finding.
Given a problem of size n, divide it into subproblems of size n/b, where a > 1 and b > 1. Solve each subproblem recursively and combine solutions of subproblems to get the overall solution. The time complexity is given by T(n) = aT(n/b) + [work for merge].
Given n points in the plane S = {(xi, yi)|i = 1, 2, . . ., n}, assuming no two have the same x coordinate, no two have the same y coordinate, and no three are in a line for convenience, the Convex Hull (CH(S)) is the smallest polygon containing all points in S.  CH(S) is represented by the sequence of points on the boundary in order clockwise as a doubly linked list. The provided image illustrates a convex hull with points p, q, r, s, t, and u.
Test each line segment to see if it makes up an edge of the convex hull. If the rest of the points are on one side of the segment, the segment is on the convex hull; otherwise, the segment is not. This approach has a complexity of O(n^3) because there are O(n^2) edges and O(n) tests.
First, sort points by x coordinate (once and for all, O(n log n)). For the input set S of points: Divide into the left half A and the right half B by x coords. Compute CH(A) and CH(B). Combine CH's of two halves (merge step).
Find the upper tangent (ai, bj). In the example, (a4, b₂) is U.T. Find the lower tangent (ak, bm). In the example, (a3, b3) is L.T.
Cut and paste in time Θ(n). First link aż to bj, go down b list till you see bm and link bm to ak, continue along the a list until you return to ai. In the example, this gives (a4, b2, b3, a3).
Assume aż maximizes x within CH(A) (a1, a2,..., ap). b₁ minimizes x within CH(B) (b1, b2,..., bq). L is the vertical line separating A and B. Define y(i, j) as the y-coordinate of intersection between L and segment (ai, bj). Claim: (ai, bj) is uppertangent if and only if it maximizes y(i, j). If y(i, j) is not maximum, there will be points on both sides of (ai, bj) and it cannot be a tangent.  The provided picture has two convex hulls A and B, separated by line L. The points \(a_1\), \(a_2\), \(a_3\), \(a_4\), \(a_5\) belong to A and \(b_1\), \(b_2\), \(b_3\) belong to B. \((a_4, b_2)\) is the upper tangent and \((a_3, b_3)\) is the lower tangent.
Obvious O(n²) algorithm looks at all ai, bj pairs.  T(n) = 2T(n/2) + Θ(n²) = Θ(n²).
Algorithm:
1. i = 1
2. j = 1
3. while (y(i, j + 1) > y(i, j) or y(i − 1, j) > y(i, j))
4.  if (y(i, j + 1) > y(i, j)) ▷ move right finger clockwise
5.   j = j + 1 (mod q)
6.  else
7.   i = i - 1 (mod p) ▷ move left finger anti-clockwise
8. return (ai, bj) as upper tangent
Similarly for lower tangent.
T(n) = 2T(n/2) + Θ(n) = O(n log n)
Given a set of n numbers, define rank(x) as the number of numbers in the set that are ≤ x. Find the element of rank \[ \frac{n+1}{2} \] (lower median) and \[ \frac{n+1}{2} \] (upper median).  Sorting works in O(n log n) time.
SELECT(S, i):
1. Pick x ∈ S ▷ cleverly
2. Compute k = rank(x)
3. B = {y ∈ S|y < x}
4. C = {y ∈ S|y > x}
5. if k = i
6.  return x
7. else if k > i
8.  return Select(B, i)
9. else if k < i
10.  return Select(C, i – k)

In the provided image, there is a horizontal line B, and another horizontal line C. There is a x between them. The k-1 elements are to the left of x and the n-k elements are to the right of x
Need to pick x so rank(x) is not extreme.
Arrange S into columns of size 5 (\[n/5\] cols)
Sort each column (bigger elements on top) (linear time)
Find "median of medians" as x. The image displays a matrix of numbers with 5 rows, where the median of each column is identified and medians of these medians is marked as x.
Half of the \[n/5\] groups contribute at least 3 elements > x except for 1 group with less than 5 elements and 1 group that contains x.
At lease 3(\[1/2 * n/5\] – 2) elements are > x, and at least 3(\[1/2 * n/5\] – 2) elements are < x
Recurrence:
T(n) = {O(1),                                  for n < 140 
T(n/5)+T(7n/10 + 6) +Θ(n), for n > 140 
Master theorem does not apply. Intuition 7n/10 + n/5 < n.
Prove T(n) ≤ cn by induction, for some large enough c. True for n < 140 by choosing large c

T(n) ≤ c * n/5 +c(7n/10 + 6) + an 
≤ c* n/5+ c* 7n/10 + 6c + an
= cn + (-cn/10 + 6c + an)
If c ≥ 70c/n + 10a, we are done. This is true for n ≥ 140 and c ≥ 20a.
Synchronous distributed algorithms: Leader Election, Maximal Independent Set, Breadth-First Spanning Trees, Shortest Paths Trees (started/finish). Asynchronous distributed algorithms: Breadth-First Spanning Trees, Shortest Paths Trees
Based on undirected graph G = (V,E). n = |V|, Г(u), set of neighbors of vertex u, deg(u) = |Г(u)|, number of neighbors of vertex u. Associate a process with each graph vertex and two directed communication channels with each edge.
Processes at graph vertices communicate using messages. Each process has output ports, input ports that connect to communication channels. The algorithm executes in synchronous rounds. In each round, each process sends messages on its ports. Each message gets put into the channel, delivered to the process at the other end. Each process computes a new state based on the arriving messages.
Theorem: There is no algorithm consisting of deterministic, indistinguishable processes that is guaranteed to elect a leader in G. Theorem: There is an algorithm consisting of deterministic processes with UIDs that is guaranteed to elect a leader in 1 round, n² messages. Theorem: There is an algorithm consisting of randomized, indistinguishable processes that eventually elects a leader, with probability 1. Expected time ≤ 1/(1-e). With probability ≥ 1 – e, finishes in one round.
Independent: No two neighbors are both in the set. Maximal: We can't add any more nodes without violating independence. Every node is either in S or has a neighbor in S. Assume: No UIDs, Processes know a good upper bound on n. Require: Compute an MIS S of the network graph, Each process in S should output in, others output out.
Initially all nodes are active. At each phase, some active nodes decide to be in, others decide to be out, the rest continue to the next phase. Round 1: Choose a random value r in {1,2, ..., n^5}, send it to all neighbors. Receive values from all active neighbors. If r is strictly greater than all received values, then join the MIS, output in. Round 2: If you joined the MIS, announce it in messages to all (active) neighbors. If you receive such an announcement, decide not to join the MIS, output out. If you decided one way or the other at this phase, become inactive. Theorem: If Luby's algorithm ever terminates, then the final set S is an MIS. Theorem: With probability at least 1 – 1/n, all nodes decide within 4 log n phases.
Distinguished vertex vo. Processes must produce a Breadth-First Spanning Tree rooted at vertex vo. Assume: UIDs. Processes have no knowledge about the graph. Output: Each process i ≠ io should output parent(j).
Processes mark themselves as they get incorporated into the tree. Initially, only i₀ is marked. Algorithm for process i: Round 1: If i = i₀ then process i sends a search message to its neighbors. If process i receives a message, then it: Marks itself, Selects i₀ as its parent, outputs parent(i₀), Plans to send at the next round. Round r > 1: If process i planned to send, then it sends a search message to its neighbors. If process i is not marked and receives a message, then it: Marks itself, Selects one sending neighbor, j, as its parent, outputs parent(j), Plans to send at the next round.
State variables, per process: marked, a Boolean, initially true for io, false for others, parent, a UID or undefined, send, a Boolean, initially true for io, false for others, uid. Invariants: At the end of r rounds, exactly the processes at distance ≤ r from vo are marked. A process ≠ io has its parent defined iff it is marked. For any process at distance d from vo, if its parent is defined, then it is the UID of a process at distance d – 1 from vo.
Time complexity: Number of rounds until all nodes outputs their parent information, Maximum distance of any node from vo, which is ≤ diam. Message complexity: Number of messages sent by all processes during the entire execution, 0(|E|).
Child pointers: Send parent/nonparent responses to search messages. Distances: Piggyback distances on search messages. Termination: Convergecast starting from the leaves. Applications: Message broadcast from the root, Global computation
Generalize the BFS problem to allow weights on the graph edges, weight{u,v} for edge {u, v} Connected graph G = (V, E), root vertex vo, process io. Processes have UIDs. Processes know their neighbors and the weights of their incident edges, but otherwise have no knowledge about the graph. Processes must produce a Shortest-Paths Spanning Tree rooted at vertex vo. Branches are directed paths from vo. Spanning: Branches reach all vertices. Shortest paths: The total weight of the tree branch to each node is the minimum total weight for any path from vo in G. Output: Each process i ≠ io should output parent(j), distance(d), meaning that: j's vertex is the parent of i's vertex on a shortest path from vo, d is the total weight of a shortest path from vo to j.
State variables: dist, a nonnegative real or ∞, representing the shortest known distance from vo. Initially 0 for process i0, ∞ for the others. parent, a UID or undefined, initially undefined. uid Algorithm for process i: At each round: Send a distance(dist) message to all neighbors. Receive messages from neighbors; let dj be the distance received from neighbor j. Perform a relaxation step: dist := min(dist, min(dj + weight{i,j}). If dist decreases then set parent := j, where j is any neighbor that produced the new dist.
Claim: Eventually, every process i has: dist = minimum weight of a path from io to i, and if i ≠ io, parent = the previous node on some shortest path from io to i. Key invariant: For every r, at the end of r rounds, every process i ≠ io has its dist and parent corresponding to a shortest path from io to i among those paths that consist of at most r edges; if there is no such path, then dist = ∞ and parent is undefined.
Time complexity: Number of rounds until all the variables stabilize to their final values, n – 1 rounds. Message complexity: Number of messages sent by all processes during the entire execution, O(n·|E|). More expensive than BFS: diam rounds, O(|E|) messages.
Ignore repeated messages. When process i receives a message that it does not use to improve dist, it responds with a nonparent message. When process i receives a message that it uses to improve dist, it responds with a parent message, and also responds to any previous parent with a nonparent message. Process i records nodes from which it receives parent messages in a set children. When process i receives a nonparent message from a current child, it removes the sender from its children. When process i improves dist, it empties children.
Q: How can the processes learn when the shortest-paths tree is completed? Q: How can a process even know when it can output its own parent and distance? If processes knew an upper bound on n, then they could simply wait until that number of rounds have passed. But what if they don't know anything about the graph? Recall termination for BFS: Used convergecast. Q: Does that work here? Yes, but it's trickier, since the tree structure changes. A process ≠ i₀ can send a done message to its current parent after: It has received responses to all its distance messages, so it believes it knows who its children are, and It has received done messages from all of those children.
Complications so far: Processes act concurrently. A little nondeterminism. Now things get much worse: No rounds---process steps and message deliveries happen at arbitrary times, in arbitrary orders. Processes get out of synch. Much more nondeterminism. Understanding asynchronous distributed algorithms is hard because we can't understand exactly how they execute. Instead, we must understand abstract properties of executions.
Processes at nodes of an undirected graph G = (V, E), communicate using messages. Communication channels associated with edges (one in each direction on each edge). Cu,v, channel from vertex u to vertex v. Each process has output ports and input ports that connect it to its communication channels. Processes need not be distinguishable.
Formally, an input/output automaton. Input actions: send(m)u,v Output actions: receive(m)u,v State variable: mqueue, a FIFO queue, initially empty. Transitions: send(m)u,v Effect: add m to mqueue. receive(m)u,v Precondition: m = head(mqueue) Effect: remove head of mqueue
Associate a process automaton with each vertex of G. To simplify notation, let Pu denote the process automaton at vertex u. But the process does not "know” u. Pu has send(m)u,v outputs and receive(m)v,u inputs. May also have external inputs and outputs. Has state variables. Keeps taking steps (eventually).
Input actions: receive(m)v,u Output actions: send(m)u,v State variables: max, a natural number, initially xu. For each neighbor v: send(v), a Boolean, initially true Transitions: receive(m)v,u Effect: if m > max then max:= m for every w, send(w) := true send(m)u,v Precondition: send(v) = true and m = тах Effect: send(v) := false
Undirected graph G = (V,E). Process Pu at each vertex u. Channels Cu,v and Cv,u, associated with each edge {u, v}. send(m)u,v output of process Pu gets identified with send(m)u, vinput of channel Cu,v. receive(m)v,u output of channel Cv,u gets identified with receive(m)v,u input of process Pu. Steps involving such a shared action involve simultaneous state transitions for a process and a channel.
No synchronous rounds anymore. The system executes by performing enabled steps, one at a time, in any order. Formally, an execution is modeled as a sequence of individual steps. Different from the synchronous model, in which all processes take steps concurrently at each round. Assume enabled steps eventually occur: Each channel always eventually delivers the first message in its queue, each process always eventually performs some enabled step.
Each process Maxu starts with an initial value xu. They all send out their initial values, and propagate their max values, until everyone has the globally-maximum value. Sending and receiving steps can happen in many different orders, but in all cases the global max will eventually arrive everywhere.
Message complexity: Number of messages sent by all processes during the entire execution, 0(n·|E|) Time complexity: Q: What should we measure? Not obvious, because the various components are taking steps in arbitrary orders---no “rounds”. A common approach: Assume real-time upper bounds on the time to perform basic steps: d for a channel to deliver the next message, and I for a process to perform its next step. Infer a real-time upper bound for solving the overall problem.
Assume real-time upper bounds on the time to perform basic steps: d for a channel to deliver the next message, and l for a process to perform its next step. Infer a real-time upper bound for solving the problem. For the Max system: Ignore local processing time (l = 0), consider only channel sending time. Straightforward upper bound: O(diam · n · d) Consider the time for the max to reach any particular vertex u, along a shortest path in the graph. At worst, it waits in each channel on the path for every other value, which is at most time n·d for that channel.
Problem: Compute a Breadth-First Spanning Tree in an asynchronous network. Connected graph G = (V, E). Distinguished root vertex vo. Processes have no knowledge about the graph. Processes have UIDs i0 is the UID of the root v0. Processes know UIDs of their neighbors, and know which ports are connected to each neighbor. Processes must produce a BFS tree rooted at vo. Each process i ≠ i0 should output parent(j), meaning that j's vertex is the parent of i's vertex in the BFS tree.
Just run the simple synchronous BFS algorithm asynchronously. Process i0 sends search messages, which everyone propagates the first time they receive it. Everyone picks the first node from which it receives a search message as its parent. Nondeterminism: No longer any nondeterminism in process decisions. But plenty of new nondeterminism: orders of message deliveries and process steps.
Input actions: receive(search)v,u Output actions: send(search)u,v; parent(v)u State variables: parent: Γ(u) U {1}, initially I reported: Boolean, initially false For every v ∈ Γ(и): send(v) ∈ {search, 1}, initially search if u = vo, else I Transitions: receive(search)v,u Effect: if u ≠ vo and parent = 1 then parent := v - for every w, send(w) := search
This process can lead to paths that are longer than the shortest paths. Because in asynchronous networks, messages may propagate faster along longer paths.
Message complexity: Number of messages sent by all processes during the entire execution, O(|E|) Time complexity: Time until all processes have chosen their parents. Neglect local processing time. O(diam·d) Q: Why diam, when some of the paths are longer? The time until a node receives a search message is at most the time it would take on a shortest path.
Child pointers: As for synchronous BFS. Everyone who receives a search message sends back a parent or nonparent response. Termination: After a node has received responses to all its search its messages, it knows who its children are, and knows they are marked. The leaves of the tree learn who they are. Use a convergecast strategy, as before. Time complexity: After the tree is done, it takes time 0(n·d) for the done information to reach io. Message complexity: 0(n)
Message broadcast: Process i0 can use the tree (with child pointers) to broadcast a message. Takes O(n·d) time and n messages. Global computation: Suppose every process starts with some initial value, and process i0 should determine the value of some function of the set of all processes' values. Use convergecast on the tree. Takes O(n·d) time and n messages.
A relaxation algorithm, like synchronous Bellman-Ford. Before, we corrected for paths with many hops but low weights. Now, instead, correct for errors caused by asynchrony. Strategy: Each process keeps track of the hop distance, changes its parent when it learns of a shorter path, and propagates the improved distances. Eventually stabilizes to a breadth-first spanning tree.
Input actions: receive(m)v,u, m a nonnegative integer Output actions: send(m)u,v, ma nonnegative integer State variables: parent: Γ(u) U {1}, initially I dist ∈ N U {∞}, initially 0 if u = vo, ∞ otherwise For every v ∈ Γ(и): send(v), a FIFO queue of N, initially (0) if u = vo, else empty Transitions: receive(m)v,u Effect: if m + 1 dist then dist := m + 1 parent := v for every w, add dist to send(w)
For synchronous BFS, we characterized precisely the situation after r rounds. We can't do that now. Instead, state abstract properties, e.g., invariants and timing properties, e.g.: Invariant: At any point, for any node u ≠ vo, if its dist ≠ ∞, then it is the actual distance on some path from vo to u, and its parent is u's predecessor on such a path. Timing property: For any node u, and any r, 0 ≤ r ≤ diam, if there is an at-most-r-hop path from vo to u, then by time r·n·d, node u's dist is ≤ r.
Message complexity: Number of messages sent by all processes during the entire execution, O(n |E|) Time complexity: Time until all processes' dist and parent values have stabilized. Neglect local processing time. O(diam·n·d), Time until each node receives a message along a shortest path, counting time O(n·d) to traverse each link.
How can processes learn when the tree is completed? How can a process know when it can output its own dist and parent? Knowing a bound on n doesn't help here: can't use it to count rounds. Can use convergecast, as for synchronous Bellman-Ford: Compute and recompute child pointers, Process ≠ v0 sends done to its current parent after: It has received responses to all its messages, so it believes it knows all its children, and It has received done messages from all of those children, The same process may be involved several times, based on improved estimates.
Same as in synchronous networks, e.g.: Broadcast a sequence of messages Global function computation Similar costs, but now count time d instead of one round.
Problem: Compute a Shortest Paths Spanning Tree in an asynchronous network. Connected weighted graph, root vertex vo. weight{u,v} for edge {u, v}. Processes have no knowledge about the graph, except for weights of incident edges. UIDS Processes must produce a Shortest Paths spanning tree rooted at vo. Each process u ≠ vo should output its distance and parent in the tree.
Use a relaxation algorithm, once again. Asynchronous Bellman-Ford. Now, it handles two kinds of corrections: Because of long, small-weight paths (as in synchronous Bellman-Ford), Because of asynchrony (as in asynchronous Breadth-First search). The combination leads to surprisingly high message and time complexity, much worse than either type of correction alone (exponential).
Input actions: receive(m)v,u, m a nonnegative integer Output actions: send(m)u,v, ma nonnegative integer State variables: parent: Γ(u) U {1}, initially I dist ∈ N U {∞}, initially 0 if u = vo, ∞ otherwise For every v ∈ Γ(и): send(v), a FIFO queue of N, initially (0) if u = vo, else empty Transitions: receive(m)v,u Effect: if m + weight{v,u} < dist then dist := m + weight{v,u} parent := v for every w, add dist to send(w)
Invariant: At any point, for any node u ≠ vo, if its dist ≠ ∞, then it is the actual distance on some path from vo to u, and its parent is u's predecessor on such a path. Timing property: For any node u, and any r, 0 ≤ r ≤ diam, if p is any at-most-r-hop path from vo to u, then by time ???, node u's dist is ≤ total weight of p. It depends on how many messages might pile up in a channel, this can be a lot!
O(n!) simple paths from vo to any other node u, which is O(nn). So the number of messages sent on any channel is 0(n^n). Message complexity: O(n^n |E|). Time complexity: O(n^n n. d). The execution of the network in which node vk sends 2k ≈ 2n/2 messages to node vk+1. Message complexity is Ω(2n/2). Time complexity is Ω(2n/2 d).
Moral: Unrestrained asynchrony can cause problems, but what to do? Find out in 6.852/18.437, Distributed Algorithms!
Linear programming (LP) is a method to achieve the optimum outcome under some requirements represented by linear relationships. More precisely, LP can solve the problem of maximizing or minimizing a linear objective function subject to some linear constraints.
The standard form of LP consists of:
Variables: $x = (x_1, x_2,...,x_d)^T$
Objective function: c.x
Inequalities (constraints): $Ax \le b$, where A is a n × d matrix
and we maximize the objective function subject to the constraints and x ≥ 0.
In general, there are n demographics, each with pi people, and m issues that the voters are interested in. Given the information on how many votes can be obtained per dollar spent advertising in support of an issue, how can we guarantee victory by ensuring a majority vote in all demographics?
Minimize $x_1 + x_2 + x_3 + x_4$
Subject to
$2x_1 + 8x_2 + 0x_3 + 10x_4 ≥ 50,000$ (Urban Majority)
$5x_1 + 2x_2 + 0x_3 + 0x_4 ≥ 100,000$ (Suburban Majority)
$3x_1 - 5x_2 + 10x_3 - 2x_4 ≥ 25,000$ (Rural Majority)
$x_1, x_2, x_3, x_4 ≥ 0$ (Can't unadvertise)
The table shows the votes per dollar spent on advertising and population for different policies and demographics. The policies are Building roads, Gun Control, Farm Subsidies, and Gasoline Tax. The demographics are Urban, Suburban, and Rural. The population for each demographic is 100,000, 200,000, and 50,000 respectively. The votes per dollar spent are as follows:
Building roads: -2 (Urban), 5 (Suburban), 3 (Rural)
Gun Control: 8 (Urban), 2 (Suburban), -5 (Rural)
Farm Subsidies: 0 (Urban), 0 (Suburban), 10 (Rural)
Gasoline Tax: 10 (Urban), 0 (Suburban), 2 (Rural)
Though we have not presented an algorithm for solving this problem, given a solution, we can verify that the solution is optimal with a proper certificate. For example,
$x_1 = \frac{2050000}{111}$
$x_2 = \frac{425000}{111}$
$x_3 = 0$
$x_4 = \frac{625000}{111}$
$x_1 + x_2 + x_3 + x_4 = \frac{3100000}{111}$
is a solution to this problem. Now consider the following equation (certificate):
$\frac{25}{222} (1) + \frac{46}{222} (2) + \frac{14}{222} (3) = x_1 + x_2 + \frac{140}{222} x_3 + x_4$
$\ge \frac{25}{222} 50000 + \frac{46}{222} 100000 + \frac{14}{222} 25000 = \frac{3100000}{111}$
$\Rightarrow x_1 + x_2 + \frac{140}{222} x_3 + x_4 \ge \frac{3100000}{111}$
We also know that $x_1 + x_2 + x_3 + x_4 \ge x_1 + x_2 + \frac{140}{222} x_3 + x_4$. Therefore, the given solution is an optimal solution to the problem.
The short certificate provided in the last section is not a coincidence, but a consequence of duality of LP problems. For every primal LP problem in the form of:
Maximize cx
Subject to $Ax \le b, x \ge 0$,
there exists an equivalent dual LP problem:
Minimize by
Subject to $A^Ty \ge c, y \ge 0$.
This property of LP can be used show many important theorems. For instance, the max-flow min-cut theorem can be proven by formulating the max-flow problem as the primal LP problem.
The natural LP formulation of a problem may not result in the standard LP form. In these cases, we can convert the problem to standard LP form without affecting the answers by using the following rules:
Minimize an objective function: Negate the coefficients and maximize.
Variable xj does not have a non-negativity constraint: Replace xj with $x_j' - x_j''$, and $x_j', x_j'' \ge 0$.
Equality constraints: Split into two different constraints; $x \le b, x \ge b$.
Greater than or equal to constraints: Negate the coefficients, and translate to less than or equal to constraint.
We can model the max flow problem as maximization of sum of flows, under some constraints which will model different properties of the flow. Given G(V, E), the capacity c(e) for each e ∈ E, the source s, and the sink t,
Maximize $\sum_{v \in V} f(s, v)$
Subject to
f(u, v) = −f(v, u) ∀u, v ∈ V skew symmetry
$\sum_{v \in V} f(u, v) = 0 \forall u \in V – {s, t}$ conservation
f(u, v) ≤ c(u, v) ∀u, v ∈ V capacity.
We can model the shortest paths problem as minimization of the sum of all distances from a node. Note that this sum is minimized only when all distances are minimized. Given G(V, E), the weight w(e) for each e ∈ E, and the source s,
Maximize $\sum_{v \in V} d(v)$
Subject to
d(v) – d(u) ≤ w(u, v)∀u, v ∈ V triangular inequality
$\sum_{v \in V} d(s) = 0$.
Note the maximization above, so all distances don't end up being zero. There is no solution to this LP if and only if there exists a negative weight cycle reachable from s.
The are many algorithms for solving LP problems:
Simplex algorithm: In the feasible region, x moves from vertex to vertex in direction of c. The algorithm is simple, but runs in exponential time in the worst case.
Ellipsoid algorithm: It starts with an ellipsoid that includes the optimal solution, and keeps shrinking the ellipsoid until the optimal solution is found. This was the first poly-time algorithm, and was a theoretical breakthrough. However, the algorithm is impractical in practice.
Interior Point Method: æ moves inside the polytope following c. This algorithm runs in poly-time, and is practical.
The simplex algorithm works well in practice, but runs in exponential time in the worst case. At a high level, the algorithm works as Gaussian elimination on the inequalities or constraints. The simplex algorithm works as follows:
Represent LP in “slack” form.
Convert one slack form into an equivalent slack form, while likely increasing the value of the objective function, and ensuring that the value does not decrease.
Repeat until the optimal solution becomes apparent.
Change the given LP problem to slack form, consisting of the original variables called nonbasic variables, and new variables representing slack called basic variables.
$z = 3x_1 + x_2 + 2x_3$
$x_4 = 30 - x_1 - x_2 - 3x_3$
$x_5 = 24 - 2x_1 - 2x_2 - 5x_3$
$x_6 = 36 - 4x_1 - x_2 - 2x_3$
We start with a basic solution: we set all nonbasic variables on the right hand side to some feasible value, and compute the values of the basic variables. For instance, we can set $x_1 = x_2 = x_3 = 0$. Note that the all 0 solution satisfies all constraints in this problem, but may not do so in the general case.
Select a nonbasic variable xe whose coefficient in the objective function is positive.
Increase the value of xe as much as possible without violating any constraints.
Set xe to be basic, while some other basic variable becomes nonbasic.
$x_1 = 9 - \frac{x_2}{4} - \frac{x_3}{2} + \frac{x_6}{4}$
$z = 27 + \frac{x_2}{4} - \frac{x_3}{2} + \frac{3x_6}{4}$
$x_1 = 9 - \frac{x_2}{4} - \frac{x_3}{2} + \frac{x_6}{4}$
$x_4 = 21 + \frac{3x_2}{4} - \frac{5x_3}{2} + \frac{x_6}{4}$
$x_5 = 6 + \frac{3x_2}{2} - 4x_3 + \frac{x_6}{2}$
$z = \frac{111}{4} + \frac{x_2}{16} - \frac{x_5}{8} + \frac{11x_6}{16}$
$x_1 = \frac{33}{4} + \frac{x_2}{16} - \frac{x_5}{8} + \frac{5x_6}{16}$
$x_2 = \frac{3}{2} + \frac{3x_2}{8} + \frac{x_5}{4} - \frac{x_6}{8}$
$x_4 = \frac{69}{4} + \frac{3x_2}{16} + \frac{5x_5}{8} - \frac{x_6}{16}$
$z = 28 - \frac{x_3}{6} - \frac{x_5}{3} - \frac{2x_6}{3}$
$x_1 = 8 + \frac{x_3}{6} + \frac{x_5}{6} + \frac{x_6}{3}$
$x_2 = 4 - \frac{8x_3}{3} - \frac{2x_5}{3} + \frac{x_6}{3}$
$x_4 = 18 - \frac{x_3}{2} + \frac{x_5}{2}$
There are several important questions regarding LP that were not discussed in this lecture:
How do we determine if LP is feasible?
What if LP is feasible, but the initial basic solution is infeasible?
How do we determine if the LP is unbounded?
How do we choose the pivot?
For a problem of size n, an approximation algorithm has an approximation ratio ρ(n) if, for any input, the algorithm produces a solution of cost C such that: max(C/Copt) ≤ ρ(n) where Copt is the cost of the optimal algorithm. Such an algorithm is called a ρ(n)-approximation algorithm.
An approximation scheme takes input ε > 0 and produces a solution such that C = (1 + ε)Copt for any fixed ε. A PTAS is an approximation algorithm that runs in time polynomial in the size of the input, n. An FPTAS runs in time polynomial in both n and ε.
Given an undirected graph G(V, E), the Vertex Cover problem is to find a subset V' ⊆ V such that for every edge (u, v) ∈ E, either u ∈ V' or v ∈ V'. The goal is to find a V' such that |V'| is minimum. This is an NP-Complete problem.
The Approx_Vertex_Cover algorithm starts with an empty set V'. While there are edges in E, it picks an edge (u, v) arbitrarily, adds both u and v into V', and removes all edges incident on u or v. It repeats until there are no more edges left in E. It runs in polynomial time.
Consider a graph G with nodes a,b,c,d,e,f,g and edges (b,c), (c,e), (b,e), (e,f), (c,d), (d,g). Approx_Vertex_Cover could pick edges (b,c), (e, f) and (d,g), resulting in V' = {b, c, e, f, d, g} and |V'| = 6. The optimal solution is {b, d, e}, with Copt = 3.
Approx-Vertex_Cover is a 2-approximation algorithm.
Proof: Let U ⊆ V be the set of all the edges that are picked by Approx_Vertex_Cover. The optimal vertex cover must include at least one endpoint of each edge in U (and other edges). Furthermore, no two edges in U share an endpoint. Therefore, |U| is a lower bound for Copt. i.e. Copt ≥ |U|. The number of vertices in V' returned by Approx-Vertex_Cover is 2·|U|. Therefore, C = |V'| = 2·|U| ≤ 2Copt. Hence C≤2.Copt
Given a set X and a family of subsets S1, S2, ..., Sm ⊆ X such that ∪Si = X, the Set Cover problem is to find a set P ⊆ {1, 2, 3, ..., m} such that ∪i∈PSi = X. The goal is to find a P such that |P| is minimum. Set Cover is an NP-Complete problem.
The Approx_Set_Cover algorithm starts by initializing the set P to the empty set. While there are still elements in X, it picks the largest set Si, adds i to P, and removes all elements in Si from X and all other subsets Sj. It repeats until there are no more elements in X. Approx_Set_Cover runs in polynomial time.
Consider a set X = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11} and subsets S1, S2, S3, S4, S5, S6 covering X. Each dot is an element in X and each Si are subsets of X. The Approx_Set_Cover selects sets S1, S4, S5, S3 in that order. Therefore it returns P = {1,4,5,3} and its cost C = |P| = 4. The optimal solution is Popt = {S3, S4, S5} and Copt = |Popt| = 3.
Approx_Set_Cover is a (ln(n) + 1)-approximation algorithm (where n = |X|).
Proof: Let the optimal cover be Popt such that Copt = |Popt| = t. Let Xk be the set of elements remaining in iteration k of Approx_Set_Cover. Hence, Xo = X.
Then:
• for all k, Xk can be covered by t sets (from the optimal solution)
• one of them covers at least |Xk|/t elements
• Approx_Set_Cover picks a set of (current) size > |Xk|/t
The proof of the approximation ratio of Approx_Set_Cover continues as follows:
• for all k, |Xk+1| ≤ (1-(1/t))|Xk| (More careful analysis (see CLRS, Ch. 35) relates ρ(n) to harmonic numbers. t should shrink.)
• for all k, |Xk+1| ≤ (1 − (1/t))^k * n ≤ e^(-k/t) * n (n = |Xo|)
Algorithm terminates when |Xk| < 1, i.e., |Xk| = 0 and will have cost C = k.
e^(-k/t) * n < 1
e^(k/t) > n
Hence algorithm terminates when k/t > ln(n). Therefore C = k < t * ln(n) + 1. Hence Approx_Set_Cover is a (ln(n) + 1)-approximation algorithm for Set Cover.
The Partition problem takes as input a set S = {1, 2, ..., n} of n items with weights s1, s2, ..., sn. It partitions S into sets A and B to minimize max(w(A), w(B)), where w(A) = ∑(i∈A) si and w(B) = ∑(j∈B) sj. Partition is an NP-Complete problem.
Define 2L = ∑(i=1 to n) si = w(S). Then the optimal solution will have cost Copt > L by definition. The goal is to find a PTAS (1 + ε)-approximation. Note that a 2-approximation in this case is trivial. An FPTAS also exists for this problem.
The Approx_Partition algorithm defines m = floor(1/ε) - 1 (with ε ≈ (m+1)/L). It proceeds in two phases:
First Phase: Find an optimal partition A', B' of s1, ..., sm. This takes O(2^m) time.
Second Phase: Initialize sets A and B to A' and B' respectively. Then, for each i from m + 1 to n, if w(A) ≤ w(B), add i to A; otherwise, add i to B.
Approx_Partition is a PTAS for Partition.
Proof: Without loss of generality, assume w(A) ≥ w(B). Then the approximation ratio is w(A)/Copt = w(A)/L. Let k be the last item added to A. There are two cases, either k was added in the first phase or the second phase.
Case 1: k is added to A in the first phase. This means that A = A'. We have an optimal partition since we can't do better than w(A') when we have n ≥ m items, and we know that w(A') is optimal for the m items.
Case 2: k is added to A in the second phase. Here we know w(A) - sk ≤ w(B) since this is why k was added to A and not to B. Now, because w(A) + w(B) = 2L, w(A) - sk ≤ w(B) = 2L - w(A). Therefore w(A) ≤ L + (sk/2). Since s1 ≥ s2 ≥ ... ≥ sn, we can say that s1, s2, ..., sm ≥ sk. Now since k > m, 2L ≥ (m + 1)sk.
Now w(A)/L ≤ (L+(sk/2))/L = 1 + (sk/2L) ≤ 1 + (sk/(m+1)sk) = 1 + (1/(m+1)) = 1 + ε. Hence Approx_Partition is a (1 + ε)-approximation for Partition.
The Approx_Vertex_Cover_Natural algorithm starts with an empty set V'. While there are edges left in E, it picks the vertex v ∈ V that has the maximum degree and adds it to V'. Then remove v and all incident edges from E. Repeat until no more edges left in E. In the end, return V'.
Approx_Vertex_Cover_Natural is a (log n)-approximation. Given the initial graph G0 and m the number of vertices in the optimal vertex cover for G. Let di be the degree of the maximum degree vertex of Gi−1. After that vertex is removed that vertex has degree di. |Gm| = |Go| - ∑di. 
∑di >∑|Gi-1|/m. From here the approximation factor of log n is shown. However, in some instances the approximation factor may actually be loglog n.
A flow network is a directed graph G = (V, E) with two distinguished vertices: a source s and a sink t. Each edge (u, v) ∈ E has a nonnegative capacity c(u, v). If (u, v) ∉ E, then c(u, v) = 0.
Given a flow network G, find a flow of maximum value on G.
If edge (u, v) ∈ E exists, then (v, u) ∉ Ε. No self-loop edges (u, u) exist.
A (net) flow on G is a function f: V × V → R satisfying the following: Capacity constraint: For all u, v ∈ V, \(f(u, v) ≤ c(u, v)\). Flow conservation: For all u ∈ V – {s, t}, \(Σ f (u, v) = 0\). Skew symmetry: For all u, v ∈ V, \(f(u, v) = -f(v, u)\).
The value of a flow f, denoted by |f|, is given by \(|f| = Σ f(s,v) = f(s,V)\).
Theorem: |f|= f(V, t). Proof: |f| = f(s, V) = f(V, V)-f(V-s, V) = f (V, V-s) = f(V, t)+f(V, V-s-t) = f(V, t).
A cut (S, T) of a flow network G = (V, E) is a partition of V such that s ∈ S and t ∈ T. If f is a flow on G, then the flow across the cut is f(S, T).
Lemma: For any flow fand any cut (S, T), we have | f | = f(S, T). Proof: f(S, T) = f (S, V) – f (S, S) = f(S, V) = f (s, V) + f (S-s, V) = f (s, V) = |f|.
The capacity of a cut (S, T) is c(S, T).
The value of any flow is bounded above by the capacity of any cut. |f|= f(S,T) = ΣΣ f(u,v) ≤ΣΣc(u, v) = c(S,T) .
Let f be a flow on G = (V, E). The residual network Gf(V, Ef) is the graph with strictly positive residual capacities cf(u, v) = c(u, v) − f(u, v) > 0. Edges in Ef admit more flow. If (v, u) ∉ E, c(v, u) = 0, but f(v, u) = − f(u, v). |Ef| ≤ 2 |E|.
Any path from s to t in Gf is an augmenting path in G with respect to f. The flow value can be increased along an augmenting path p by cf (p) = min {cf(u,v)}.
The following are equivalent: 1. |f | = c(S, T) for some cut (S, T). 2. f is a maximum flow. 3. f admits no augmenting paths.
f[u, v] ← 0 for all u, v ∈ V. While an augmenting path p in G wrt f exists: augment f by cf(p)
This lecture studies how to use max-flow algorithms to compute the elimination of sports teams in a league, using the standings of the AL Eastern Division of the Major League Baseball on August 30, 1996, as an example.
The table shows the standings of the AL East teams including their wins (\(w_i\)), losses (\(l_i\)), games to play (\(r_i\)), and games against each other.  The teams listed are NY, Baltimore, Boston, Toronto, and Detroit.
A naive approach is to check if \(w_i + r_i < w_j\) for some other team j. For instance, if Detroit's record was \(w_5 = 46\), they would be eliminated since \(w_5 + r_5 = 46 + 28 < 75 = w_1\).
The naive condition is sufficient but not necessary. For example, if \(w_5 = 47\), even though \(w_5 + r_5 = 75\), either NY or Baltimore could reach 76 wins because they have 5 games remaining against each other.
A max-flow network can be constructed where the capacity between node s and node i-j is the number of games left to be played between team i and j, the capacity between node i-j and node k (representing team k) is infinity, and the capacity between node k and t is \(w_5 + r_5 - w_k\). Detroit is assumed to win all \(r_5\) games, and the network checks if the number of wins per team can be kept less than or equal to \(w_5 + r_5\).
Team 5 (Detroit) is eliminated if and only if the max-flow does not saturate all edges leaving the source, i.e., the max flow value is less than 26.
Saturation of the edge capacity corresponds to playing all the remaining games. If all the games cannot be played while keeping the number of wins of a team to be less than or equal to \(w_5 + r_5\), then Team 5 is eliminated.
The min-cut is defined by the sets \(S = \{s, 1-2, 1-3, 2-3, 1, 2, 3\}\) and \(T = \{1-4, 2-4, 3-4, 4, t\}\). The capacity of the min-cut \(c(S, T) = 4 + 4 + 4 + 1 + 5 + 7 = 25 < 26\). Therefore, Team 5 Detroit is eliminated.
The max-flow will find the subset of teams that eliminates Team 5.  Consider teams 1, 2, and 3.  The total wins among the 3 teams is 215, and they have 14 games left.  Thus, there will be 229 total wins, meaning at least one team will win \(\lceil\frac{229}{3}\rceil = 77\) games. If Detroit has only 48 wins, it is eliminated because \(48 + 28 = 76 < 77\). This can be determined using max-flow and the max-flow min-cut theorem.
Network Flow & Applications, Review, Max-flow min-cut theorem, Edmonds Karp algorithm, Flow Integrality, and Part II: Applications.
Flow value: | f | = f(s, V).
Cut: Any partition (S, T) of V such that s ∈ S and t ∈ T.
Lemma: |f| = f(S, T) for any cut (S, T).
Corollary: | f | ≤ c(S, T) for any cut (S, T).
Residual graph: The graph Gf= (V, Ef) with strictly positive residual capacities cf(u, v) = c(u, v) – f(u, v) > 0.
Augmenting path: Any path from s to t in Gf.
Residual capacity of an augmenting path: cf(p) = min {cf (u, v)} where (u,v) ∈ p.
The algorithm is as follows:
f[u, v] ← 0 for all u, v ∈ V
while an augmenting path p in G wrt f exists
do augment f by cf(p)
The following are equivalent:
1. | f | = c(S, T) for some cut (S, T).
2. f is a maximum flow.
3. f admits no augmenting paths.
Suppose that f admits no augmenting paths.
Define S = {v ∈ V: there exists a path in Gf from s to v}, and let T = V - S. Observe that s ∈ S and t∈ T, and thus (S, T) is a cut. Consider any vertices u ∈ S and v ∈ T.
We must have cf (u, v) = 0, since if cf (u, v) > 0, then v ∈ S, not v∈T as assumed. Thus, f(u, v) = c(u, v), since cf (u, v) = c(u, v) – f(u, v). Summing over all u ∈ S and v∈T yields f(S, T) = c(S, T), and since | f | = f(S, T), the theorem follows.
Ford-Fulkerson max-flow algorithm can be slow if the augmenting path is not chosen carefully, as demonstrated by the example given.  For a graph with 4 vertices, it may take 2 billion iterations.
Edmonds and Karp noticed that many people's implementations of Ford-Fulkerson augment along a breadth-first augmenting path: a shortest path in Gf from s to t where each edge has weight 1. These implementations would always run relatively fast.
The Edmonds-Karp maximum-flow algorithm runs in O(VE^2) time. Breadth-first search takes O(E) time, and there are O(VE) augmentations in the worst case.
The asymptotically fastest algorithm through 2011 for maximum flow, due to King, Rao, and Tarjan, runs in O(VE log_{E/(V lg V)} V) time. Recently Orlin came up with an O(VE) time algorithm!
Suppose the flow network has integer capacities. Then, the maximum flow will be integer-valued.
Start with a flow of 0 on all edges. Use Ford-Fulkerson. Initially, and at each step, Ford-Fulkerson will find an augmenting path with residual capacity that is an integer. Therefore, all flow values on edges always remain integral throughout the algorithm.
Baseball Elimination and Bipartite Matching.
Matrix multiplication, and Quicksort are covered.
An algorithm that generates a random number \(r \in {1, ..., R}\) and makes decisions based on r's value. On the same input on different executions, a randomized algorithm may run a different number of steps or produce a different output.
Randomized algorithms are classified into two types: Monte Carlo and Las Vegas.
Monte Carlo runs in polynomial time always and its output is correct with high probability. Las Vegas runs in expected polynomial time and its output is always correct.
Given \(C = A \times B\), a simple algorithm uses \(O(n^3)\) multiplications. Strassen's algorithm multiplies two 2 × 2 matrices in 7 multiplications, with a complexity of \(O(n^{log_2 7}) = O(n^{2.81})\). The Coppersmith-Winograd algorithm has a complexity of \(O(n^{2.376})\).
Given \(n \times n\) matrices \(A, B, C\), the goal is to check if \(A \times B = C\) or not. We will see an \(O(n^2)\) algorithm that:
-if \(A \times B = C\), then \(Pr[output=YES] = 1\).
-if \(A \times B \neq C\), then \(Pr[output=YES] \le \frac{1}{2}\).
Entries in matrices are in \({0,1}\) and also that the arithmetic is mod 2.
Choose a random binary vector r[1...n] such that \(Pr[r_i = 1] = 1/2\) independently for \(r = 1,...,n\). The algorithm will output 'YES' if \(A(Br) = Cr\) and 'NO' otherwise.
The algorithm will take \(O(n^2)\) time, since there are 3 matrix multiplications Br, A(Br) and Cr of a \(n \times n\) matrix by a \(n \times 1\) matrix.
Quicksort is a divide and conquer algorithm that works mostly in the divide step. It sorts 'in place' like insertion sort. Different variants are: Basic(good in average case), Median-based pivoting(uses median finding), Random(good for all inputs in expectation (Las Vegas algorithm))
Divide: pick a pivot element \(x\) in \(A\), partition the array into sub-arrays \(L\), consisting of all elements \(< x\), \(G\) consisting of all elements \(> x\) and \(E\) consisting of all elements \(= x\). Conquer: recursively sort subarrays \(L\) and \(G\). Combine: trivial
Pivot around \(x = A[1]\) or \(A[n]\) (first or last element). Remove, in turn, each element \(y\) from \(A\). Insert \(y\) into \(L, E\) or \(G\) depending on the comparison with pivot \(x\). Each insertion and removal takes \(O(1)\) time. Partition step takes \(O(n)\) time.
If input is sorted or reverse sorted, we are partitioning around the min or max element each time. This means one of L or G has n - 1 elements, and the other 0. This gives:
\(T(n) = T(0) + T(n − 1) + Θ(n)\)
\(= Θ(1) + T(n − 1) + Θ(n)\)
\(= Θ(n^2)\)
Can guarantee balanced \(L\) and \(G\) using rank/median selection algorithm that runs in O(n) time. The first O(n) below is for the pivot selection and the second for the partition step.
\(T(n) = 2T(\frac{n}{2}) + Θ(n) + Θ(n)\)
\(T(n) = O(nlog n)\)
\(x\) is chosen at random from array \(A\) (at each recursion, a random choice is made). Expected time is \(O(nlogn)\) for all input arrays \(A\). For "Paranoid” Quicksort: repeat, choose pivot to be random element of \(A\), perform Partition until resulting partition is such that \(|L| \le \frac{3}{4}|A|\) and \(|G| \le \frac{3}{4}|A|\), recurse on \(L\) and \(G\)
Let's define a 'good pivot' and a 'bad pivot'-
Good pivot: sizes of \(L\) and \(G \le \frac{3}{4}n\) each
Bad pivot: one of \(L\) and \(G\) is \(\le \frac{3}{4}n\) each
We see that a pivot is good with probability \(> 1/2\).
Let \(T(n)\) be an upper bound on the expected running time on any array of \(n\) size.
\(T(n)\) comprises:
-time needed to sort left subarray
-time needed to sort right subarray
-the number of iterations to get a good call. Denote as \(c \cdot n\) the cost of the partition step
\(T(n) \le max_{n/4<i<3n/4}(T(i) +T(n − i)) + E(\#iterations) \cdot cn\)
Now, since probability of good pivot \(> \frac{1}{2}\), \(E(\#iterations) \le 2\)
\(T(n) \le T(\frac{n}{4}) + T(\frac{3n}{4}) + 2cn\)
We see in the figure that the height of the tree can be at most \(log_{\frac{4}{3}}(2cn)\) no matter what branch we follow to the bottom. At each level, we do a total of \(2cn\) work. Thus, expected runtime is \(T(n) = Θ(nlogn)\)
Topics include: memory hierarchy, external memory vs. cache-oblivious model, cache-oblivious scanning, and cache-oblivious divide & conquer algorithms: median finding & matrix multiplication.
The memory hierarchy consists of CPU, L1, L2, L3, memory, and disk. Size increases from ~10KB (L1) to TB (disk). Latency also increases from ~1ns (L1) to 10ms (disk). Each hierarchy on the right is bigger, but has longer latency due to the longer distance data has to travel. Yet, bandwidth between different hierarchies is usually matched.
A common technique to mitigate latency is blocking: when fetching a word of data, get the entire block containing it. The idea is to amortize latency over a whole block. For this idea to work, we additional require the algorithm to use all words in a block (spatial locality) and reuse blocks in cache (temporal locality).
In the external memory model, cache accesses are free. The algorithm explicitly reads and writes memory in blocks. We count the number of memory transfers between the cache and the memory as a metric of the algorithm's performance. The cache has a total size of M, divided into M/B blocks, with each block having B words. The memory/disk has infinite size, divided into blocks, with each block having B words.
The only change from the external memory model is that the algorithm no longer knows B and M. Accessing a word in the memory automatically fetches an entire block into the cache, and evicts the least recently used (LRU) block from the cache if the cache is full.
Because this way, an algorithm can auto-tune itself and run efficiently on different computers (possibly with different B and M).
The example program is 'for i in range(N): sum += A[i]'. Assuming A is stored contiguously in memory, the external memory model can align A with a block boundary, so it needs [N/B] memory transfers. Cache-oblivious algorithms cannot control alignment, so it needs [N/B] + 1 = N/B + O(1) memory transfers. O(1) parallel scans still need O(N/B + 1) memory transfers.
Divide & Conquer algorithms divide problems down to O(1) size. The base case of the recursion is either when the problem fits in cache i.e., ≤ M, or the problem fits in O(1) blocks, i.e., O(B).
The steps are: 1. view array as partitioned into columns of 5 (each column is O(1) size). 2. sort each column. 3. recursively find the median of the column medians. 4. partition array by x. 5. recurse on one side
The recurrence relation for the memory transfers is:  MT(N) = MT(N/5) + MT(7N/10) + O(N/B + 1).
The base cases are MT(O(1)) = O(1) and MT(O(B)) = O(1). Using the base case, the recursion solves to MT(N) = O(N/B + 1).
Compute Z = X · Y where X, Y, Z are all N × N matrices. X is stored in row-major order, and Y is stored in column-major order to improve locality.
Computing each element takes O(N/B + 1) memory transfers, so computing the entire Z costs O(N³/B + N²) memory transfers.
The recursion is MT(N) = 8MT(N/2) + O(N²/B + 1). The first term is recursive sub-matrix multiplication, and the second term is matrix addition which requires scanning the matrices.
weak: MT(O(1)) = O(1), better: MT(O(B)) = O(1), and even better: MT(√√M/3) = O(M/B)
MT(N) = O(M/B) * 8^{0(lg N/√M)} = O(M/B) * O((N/√M)³) = O(N³/B√M).
The lecture covers NP-hardness and NP-completeness, 3SAT, Super Mario Brothers, 3 Dimensional Matching, Subset Sum, Partition, Rectangle Packing, and Jigsaw Puzzles.
P is the set of problems that are solvable in polynomial time, meaning a problem of size n should be solved in \(n^{O(1)}\). NP is the set of decision problems solvable in nondeterministic polynomial time, with a YES or NO answer, where a solution can be guessed out of polynomially many options in O(1) time.
A reduction from problem A to problem B is a polynomial-time algorithm that converts inputs to problem A into equivalent inputs to problem B, ensuring both problems output the same YES or NO answer for the input and converted input. If B∈ P, then A ∈ NP. If B ∈ NP, then A ∈ NP. If A is NP-hard, then B is NP-hard.
1. Show \(X \in NP\) by finding a nondeterministic algorithm or giving a valid verifier for a certificate.
2. Show X is NP-hard by reducing from a known NP-complete problem Y to X, ensuring a polynomial-time conversion from Y inputs to X inputs, and that if Y's answer is YES, then X's answer is YES, and vice versa.
3SAT: Given a boolean formula of the form \((x_1 \lor x_3 \lor x_6) \land (x_2 \lor x_3 \lor x_7) \land ...\), is there an assignment of variables to True and False such that the entire formula evaluates to True? 3SAT is NP-complete, discovered by Cook in 1971.
Super Mario Brothers is NP-hard, shown by giving a reduction from 3SAT, using gadgets for variables and clauses to construct a level of Super Mario Brothers corresponding to a given 3SAT instance. By solving the level the 3SAT can be solved.
The gadgets consist of Variable gadget where Mario jumps down from the ledge to the left or right, corresponding to assigning the variable to True or False. The Clause gadget and the Crossover gadget, ensures that Mario does not switch between variable and clause gadgets when it is not allowed.
3DM: Given disjoint sets X, Y, and Z, each of n elements and triples \(T \subseteq X \times Y \times Z\), is there a subset \(S \subseteq T\) such that each element \(\in X \cup Y \cup Z\) is in exactly one \(s \in S\)? 3DM is NP-complete, shown via reduction from 3SAT, and gadgets for the variables and clauses are created.
Subset Sum: Given n integers \(A = {a_1, a_2, ..., a_n}\) and a target sum t, is there a subset \(S \subseteq A\) such that  \(\sum_{a_i \in S} a_i = t\)? Subset Sum is NP-complete, shown via reduction from 3DM.
Partition: Given \(A = {a_1, a_2,..., a_n}\), is there a subset \(S \subseteq A\) such that \(\sum S = \sum A \setminus S = \frac{1}{2} \sum A\)? Partition is also weakly NP-complete. It is a special case of the Subset Sum problem.
Rectangle Packing: Given a set of rectangles \(R_i\) and a target rectangle T, can we pack the rectangles in T such that there is no overlap?  The sum of the area of the rectangles \(R_i\) is equivalent to the area of the target rectangle or \(\sum_i R_i = T\). Rectangle packing is weakly NP-hard via a reduction from Partition.
Jigsaw Puzzles: Given square tiles with no patterns, can these tiles be arranged to fit a target rectangular shape? The tiles can have a side tab, pocket, or boundary, but tabs and pockets must have matching shapes. 4-Partition is a strongly NP-complete problem. We reduce from 4-Partition to Jigsaw Puzzles to show that Jigsaw Puzzles are NP-hard.
This lecture covers augmentation of data structures, including easy tree augmentation, order-statistics trees, finger search trees, and range trees.
The main idea is to modify 'off-the-shelf' common data structures to store (and update) additional information.
The goal is to store x.f at each node x, which is a function of the node, namely f(subtree rooted at x). If x.f can be computed (updated) in O(1) time from x, children and children.f, modification a set S of nodes costs O(# of ancestors of S) to update x.f. Examples of O(lgn) updates are:
AVL trees: after rotating two nodes, first update the new bottom node and then update the new top node. 2-3 trees: after splitting a node, update the two new nodes. In both cases, then update up the tree.
The goal of order-statistics trees is to design an Abstract Data Type (ADT) interface that supports the following operations:
insert(x), delete(x), successor(x), rank(x): find x's index in the sorted order, i.e., # of elements < x, select(i): find the element with rank i.
We can implement the above ADT using easy tree augmentation on AVL trees (or 2-3 trees) to store subtree size: f(subtree) = # of nodes in it. Then we also have x.size = 1 + ∑c.size for c in x.children. As a comparison, we cannot store the rank for each node. In that case, insert(-∞) will change the ranks for all nodes.
rank(x) can be computed as follows: initialize rank = x.left.size + 1, walk up from x to root, whenever taking a left move (x → x'), rank += x'.left.size + 1
select(i) can be implemented as follows: x = root, rank = x.left.size + 1, if i = rank: return x, if i < rank: x = x.left, if i > rank: x = x.right, i -= rank
The goal of finger search trees [Brown and Tarjan, 1980] is that, if we already have node y, we want to search x from y in O (lg|rank(y) – rank(x)|) time. Intuitively, we would like the search of x to be fast if we already have a node y that is close to x. One idea is to use level-linked 2-3 trees, where each node has pointers to its next and previous node on the same level.
The level links can be maintained during split and merge.
We store all keys in the leaves. Non-leaf nodes do not store keys; instead, they store the min and max key of the subtree (via easy tree augmentation). Then the original top-down search(x) (without being given y) can be implemented as follows: start from the root, look at min & max of each child ci, if c₁. min ≤ x ≤ c₁. max, go down to ci, if c. max ≤ x ≤ Ci+1. min, return ci. max (as predecessor) or Ci+1. min (as successor)
search(x) from y can be implemented as follows. Initialize v to the leaf node containing y (given), and then in a loop do:
if v. min ≤ x ≤ v. max (this means x is in the subtree rooted at v), do top-down search for x from v and return
elif x < v. min: v = v.prev (the previous node in this level)
elif x > v. max: v = v.next (the next node in this level)
v = v.parent
We start at the leaf level, and go up by 1 level in each iteration. At step i, level link at height i skips roughly c² keys (ranks), where c∈ [2,3]. Therefore, if |rank(y) - rank(x)| = k, we will reach the subtree containing x in O(lgk) steps, and the top-down search that follows is also O(lgk).
Suppose we have n points in a d-dimension space. We would like a data structure that supports range query on these points: find all the points in a give axis-aligned box. An axis-aligned box is simply an interval in 1D, a rectangle in 2D, and a cube in 3D. To be more precise, each point xi (for i from 1 to n) is a d-dimension vector = (X1, X2, ..., Xid). Range-query(a, b) takes two points a = (a1, a2,..., ad) and b = (b1, b2, . . ., ba) as input, and should return a set of indices {i | ∀j, aj ≤ Xij ≤ bj}.
We start with the simple case of 1D points, i.e., all xi's and a and b are scalars. Then, we can simply use a sorted array. To do range-query(a,b), we simply perform two binary searches for a and b, respectively, and then return all the points in between (say there are k of them). The complexity is O(lgn + k).
Sorted arrays are inefficient for insertion and deletion. For a dynamic data structure that supports range queries, we can use finger search tree from the previous section. Finger search trees support efficient insertion and deletion. To do range-query(a, b), we first search for a, and then keep doing finger search to the right by 1 until we exceed b. Each finger search by 1 takes O(1), so the total complexity is also O(lgn + k).
However, neither of the above approaches generalizes to high dimensions. That's why we now introduce range trees.
A 1D range tree is a complete binary search tree (for dynamic, use an AVL tree). Range-query(a, b) can be implemented as follows:
search(a), search(b), find the least common ancestor (LCA) of a and b, Usplit, return the nodes and subtrees “in between'. There are O(lgn) nodes and O(lgn) subtrees “in between'. Analysis. O(lgn) to implicitly represent the answer. O(lgn + k) to output all k answers. O(lgn) to report k via subtree size augmentation.
A 2D range tree consists of a primary 1D range tree and many secondary 1D range trees. The primary range stores all points, keyed on the first coordinate. Every node v in the primary range tree stores all points in v's subtree in a secondary range tree, keyed on the second coordinate.
Range-query(a, b) can be implemented as follows:
use the primary range tree to find all points with the correct range on the first coordinate. Only implicitly represent the answer, so this takes O(lgn).
for the O(lgn) nodes, manually check whether their second coordinate lie in the correct range.
for the O(lgn) subtrees, use their secondary range tree to find all points with the correct range on the second coordinate.
Analysis. O(lg² n) to implicitly represent the answer, because we will find O(lg² n) nodes and subtrees in secondary range trees. O(lg2n + k) to output all k answers. O(lg2n) to report k via subtree size augmentation. Space complexity is O(nlgn). The primary subtree is O(n). Each point is duplicated up to O(lgn) times in secondary subtrees, one per ancestor.
Just recurse: primary 1D range tree → secondary 1D range trees → tertiary 1D range trees → ...
Range-query complexity: O(lgan + k). Space complexity: O(nlgd-1n).
See 6.851 for Chazelle's improved results: O(lgd-1 n + k) range-query complexity and O(n()-1) space complexity.
Data structures such as heaps, trees, graphs and Algorithms for sorting, shortest paths, graph search, dynamic programming
1. Divide and Conquer - FFT, Randomized algorithms
2. Optimization - greedy and dynamic programming
3. Network Flow
4. Intractibility (and dealing with it)
5. Linear programming
6. Sublinear algorithms, approximation algorithms
7. Advanced topics
P: class of problems solvable in polynomial time. \(O(n^k)\) for some constant k. Shortest paths in a graph can be found in \(O(V^2)\) for example.
NP: class of problems verifiable in polynomial time. Hamiltonian cycle in a directed graph G(V, E) is a simple cycle that contains each vertex in V.
NP-complete: problem is in NP and is as hard as any problem in NP. If any NPC problem can be solved in polynomial time, then every problem in NP has a polynomial time solution.
Requests 1,2,..., n, single resource
s(i) start time, f(i) finish time, s(i) < f(i) (start time must be less than finish time for a request). Two requests i and jare compatible if they don't overlap, i.e., f(i) ≤ s(j) or f(j) ≤ s(i).
The image shows a timeline representing requests, where 2 and 3 are compatible, and requests 4, 5 and 6 are compatible as well, but requests 2 and 4 are not compatible.
Select a compatible subset of requests of maximum size.
A greedy algorithm is a myopic algorithm that processes the input one piece at a time with no apparent look ahead.
1. Use a simple rule to select a request i.
2. Reject all requests incompatible with i.
3. Repeat until all requests are processed.
1. Select request that starts earliest, i.e., minimum s(i).
2. Select request that is smallest, i.e., minimum f(i) – s(i).
3. For each request, find number of incompatibles, and select request with mini- mum such number.
4. Select request with earliest finish time, i.e., minimum f(i).
Greedy algorithm outputs a list of intervals <s(11), f(i₁) >, < s(i2), f(i₂) >, ..., <s(ik), f(ik) > such that \(s(i₁) < f(i₁) ≤ s(12) < f(i2) < ... < s(ik) < f(ik)\)
Given list of intervals L, greedy algorithm with earliest finish time produces k* intervals, where k* is optimal.
Each request i has weight w(i). Schedule subset of requests that are non-overlapping with maximum weight. The greedy algorithm no longer works.
R* = {j ∈ R\s(j) ≥ x}, Here, R is the set of all requests.
As before, we have n requests {1,2,..., n}. Each request i is associated with a start time s(i) and finish time f(i), m different machine types as well ㅜ = {T₁,...,Tm}. Each request i is associated with a set Q(i) ⊆ τ that represents the set of machines that request i can be serviced on.
Each request has a weight of 1. We want to maximize the number of jobs that can be scheduled on the m machines.
1. Approximation algorithms: Guarantee within some factor of optimal in poly- nomial time.
2. Pruning heuristics to reduce (possible exponential) runtime on “real-world" examples.
3. Greedy or other sub-optimal heuristics that work well in practice but provide no guarantees.