QUESTION: # 6.034 Quiz 1, Spring 2005
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 757.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: ## 1 Search Algorithms (16 points)
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 735.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: ### 1.1 Games
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 763.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: The standard alpha-beta algorithm performs a depth-first exploration (to a pre-specified depth) of the game tree.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 741.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 1. Can alpha-beta be generalized to do a breadth-first exploration of the game tree and still get the optimal answer? Explain how or why not. If it can be generalized, indicate any advantages or disadvantages of using breadth-first search in this application.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 717.00 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 2. Can alpha-beta be generalized to do a progressive-deepening exploration of the game tree and still get the optimal answer? Explain how or why not. If it can be generalized, indicate any advantages or disadvantages of using progressive-deepening search in this application.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: ### 1.2 Algorithms
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 1. You are faced with a path search problem with a very large branching factor, but where the answers always involve a relative short sequence of actions (whose exact length is unknown). All the actions have the same cost. What search algorithm would you use to find the optimal answer? Indicate under what conditions, if any, a visited or expanded list would be a good idea.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 2. You are faced with a path search problem with a very large branching factor, but where the answers always involve a relative short sequence of actions (whose exact length is unknown). These actions, however, have widely varying costs. What search algorithm would you use to find the optimal answer? Indicate under what conditions, if any, a visited or expanded list would be a good idea.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: ## 2 Constraints (16 points)
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: Consider assigning colors to a checkerboard so that squares that are adjacent vertically or horizontally do not have the same color. We know that this can be done with only two colors, say red (R) and black (B). We will limit our discussion to five squares on a 3x3 board, numbered as follows:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 1 | 2 | 3
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: ----------
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 4 | 5 |
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: ----------
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: |   |
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: Let's look at the CSP formulation of this problem. Let the squares be the variables and the colors be the values. All the variables have domains { R, B } .
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 1. If we run full constraint propagation on the initial state, what are the resulting domains of the variables?
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 2. Say, instead, the initial domain of variable 5 is restricted to { B } , with the other domains as before. If we now run full constraint propagation, what are the resulting domains of the variables?
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 3. If in the initial state (all variables have domains { R, B } ), we assign variable 1 to R and do forward checking, what are the resulting domains of the other variables?
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 4. Assume that during backtracking we first attempt assigning variables to R and then to B. Assume, also, that we examine the variables in numerical order, starting with 1. Also, let the domain of variable 5 be { B } , the other domains are { R, B } . In the following tree, which shows the space of assignments to the 5 variables we care about, indicate how pure backtracking (BT) would proceed by placing a check mark next to any assignment that would be attempted during the search and crossing out the nodes where a constraint test would fail. Leave unmarked those nodes that would never be explored.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: RB
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: RBRB
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: RBRBRBRB
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: RBRBRBRBRBRBRBRB
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: BBBBBBBBBBBBBBBB
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 5. If we use backtracking with forward checking (BT-FC) in this same situation, give a list of all the assignments attempted, in sequence. Use the notation variable = color for assignments, for example, 1=R.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: | Assignment:   | None    | 1 = R   | 2= B   | 1= B    | 2= R   | 3= B   | 4= R   | 5= B   |
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: |---------------|---------|---------|--------|---------|--------|--------|--------|--------|
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: | Domain of 1:  | { R,B } |         |        |         |        |        |        |        |
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: | Domain of 2:  | { R,B } | { B }   |        | { R }   |        |        |        |        |
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: | Domain of 3:  | { R,B } | { R,B } | { R }  | { R,B } | { B }  |        |        |        |
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: | Domain of 4:  | { R,B } | { B }   | { B }  | { R }   | { R }  | { R }  |        |        |
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: | Domain of 5:  | { B }   | { B }   | {} ⇓   | { B }   | { B }  | { B }  | { B }  |        |
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 6. If we use backtracking with forward checking (BT-FC) but with dynamic variable ordering, using the most-constrained-variable strategy, give a list of all the variable assignments attempted, in sequence. If there is a tie between variables, use the lowest-numbered one first. Use the notation variable = color for assignments, for example, 1=R.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: | Assignment:   | None     | 5 = B    | 2= R   | 1= B   | 3= B   | 4= R   |
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: |---------------|----------|----------|--------|--------|--------|--------|
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: | Domain of 1:  | { R, B } | { R, B } | { B }  |        |        |        |
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: | Domain of 2:  | { R, B } | { R }    |        |        |        |        |
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: | Domain of 3:  | { R, B } | { R, B } | { B }  | { B }  |        |        |
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: | Domain of 4:  | { R, B } | { R }    | { R }  | { R }  | { R }  |        |
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: | Domain of 5:  | { B }    |          |        |        |        |        |
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: {
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: }
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: ## 3 Constraint satisfaction (24 points)
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: You are trying to schedule observations on the space telescope. We have m scientists who have each submitted a list of n telescope observations they would like to make. An observation is specified by a target, a telescope instrument, and a time slot. Each scientist is working on a different project so the targets in each scientist's observations are different from those of other scientists. There are k total time slots, and the telescope has three instruments, but all must be aimed at the same target at the same time.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: The greedy scientists cannot all be satisfied, so we will try to find a schedule that satisfies the following constraints:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: C1 . Exactly two observations from each scientist's list will be made (the choice of the two will be part of the solution).
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: C2 . At most one observation per instrument per time slot is scheduled.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: C3 . The observations scheduled for a single time slot must have the same target.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: Note that for some set of requested observations, there may not be any consistent schedule, but that's fine.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: Consider the following three formulations of the problem.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: A . The variables are the 3 k instrument/time slots.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: B . The variables are the m scientists.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: C . The variables are the mn scientists' requests.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: For each formulation, specify
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 1 . The value domain for the variables.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 2 . The size of the domain for the variables (in terms of k , m ,and n ).
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 3 . Which of the constraints are necessarily satisfied because of the formulation.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 4 . Whether the constraints can be specified as binary constraints in this formulation. If they can, explain how. If not, provide a counterexample.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: ### Formulation A: The variables are the 3 k instrument/time slots.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 1. Domain:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 2. Size of domain:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 3. Satisfied constraints:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 4. Binary constraints?:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: ### Formulation B: The variables are the m scientists.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 1. Domain:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 2. Size of domain:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 3. Satisfied constraints:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 4. Binary constraints?:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: ### Formulation C: The variables are the mn scientists' requests.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 1. Domain:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 2. Size of domain:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 3. Satisfied constraints:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 4. Binary constraints?:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: ## 4 Search Problem formulation (23 points)
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: Consider a Mars rover that has to drive around the surface, collect rock samples, and return to the lander. We want to construct a plan for its exploration.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: · It has batteries. The batteries can be charged by stopping and unfurling the solar collectors (pretend it's always daylight). One hour of solar collection results in one unit of battery charge. The batteries can hold a total of 10 units of charge.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: · It can drive. It has a map at 10-meter resolution indicating how many units of battery charge and how much time (in hours) will be required to reach a suitable rock in each square.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: · It can pick up a rock. This requires one unit of battery charge. The robot has a map at 10-meter resolution that indicates the type of rock expected in that location and the expected weight of rocks in that location. Assume only one type of rock and one size can be found in each square.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: The objective for the rover is to get one of each of 10 types of rocks, within three days, while minimizing a combination of their total weight and the distance traveled. You are given a tradeoff parameter α that converts units of weight to units of distance. The rover starts at the lander with a full battery and must return to the lander.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: Here is a list of variables that might be used to describe the rover's world:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: · types of rocks already collected
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: · current rover location (square on map)
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: · current lander location (square on map)
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: · weight of rocks at current location (square on map)
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: · cost to traverse the current location (square on map)
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: · time since last charged
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: · time since departure from lander
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: · current day
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: · current battery charge level
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: · total battery capacity
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: · distance to lander
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: · total weight of currently collected rocks
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 1. Use a set of the variables above to describe the rover's state. Do not include extraneous information.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 2. Specify the goal test.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 3. Specify the actions. Indicate how they modify the state and any preconditions for being used.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 4. Specify a function that determines the cost of each action.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: charge :
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: move :
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: pick-up-rock :
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### 5. This can be treated as a path search problem. We would like to find a heuristic. Say whether each of these possible heuristics would be useful in finding the optimal path or, if not, what's wrong with them. Let l be the number of rocks already collected.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: H1 : The sum of the distances (in the map) from the rover to the 10 -l closest locations for the missing types of rocks.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: H2 : The length of the shortest tour through the 10 -l closest locations for the missing types of rocks.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: H3 : The distance back to the lander
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: ## 5 Search traces (21 points)
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: Consider the graph shown in the figure below. We can search it with a variety of different algorithms, resulting in different search trees. Each of the trees (labeled G1-G7) was generated by searching this graph, but with a different algorithm. Assume that children of a node are visited in alphabetical order. Each tree shows all the nodes that have been visited. Numbers next to nodes indicate the relevant 'score' used by the algorithm for those nodes.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: G:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: A (1) → B
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: A (3) → D
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: A (2) → B
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: B (5) → C
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: B (6) → G
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: B (4) → D
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: D (1) → C
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: D (3) → G
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: C (1) → G
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: For each tree, indicate whether it was generated with
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 1. Depth first search
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 2. Breadth first search
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 3. Uniform cost search
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 4. A* search
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 5. Best-first (greedy) search
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: In all cases a strict expanded list was used. Furthermore, if you choose an algorithm that uses a heuristic function, say whether we used
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: H1 :heuristic 1 = { h ( A )=3 ,h ( B )=6 ,h ( C )=4 ,h ( D )=3 }
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: H2 :heuristic 2 = { h ( A )=3 ,h ( B )=3 ,h ( C )=0 ,h ( D )=2 }
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: Also, for all algorithms, say whether the result was an optimal path (measured by sum of link costs), and if not, why not. Be specific.
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: Write your answers in the space provided below (not on the figure).
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### G1:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: A → B
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: A → D
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: B → C
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: B → D
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: B → G
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 1. Algorithm:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 2. Heuristic (if any):
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 3. Did it find least-cost path? If not, why
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### G2:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: A (6) → B
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: A (3) → D
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: D (4) → C
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: D → G
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 1. Algorithm:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 2. Heuristic (if any):
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 3. Did it find least-cost path? If not, why
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### G3:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: A (7) → B
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: A (6) → D
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: D (8) → C
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: D (6) → G
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 1. Algorithm:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 2. Heuristic (if any):
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 3. Did it find least-cost path? If not, why
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### G4:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: A (3) → B
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: A (2) → D
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: D (0) → C
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: C → G
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 1. Algorithm:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 2. Heuristic (if any):
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 3. Did it find least-cost path? If not, why
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### G5:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: A → B
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: A → D
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: B → C
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: B → D
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: B → G
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: C → G
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 1. Algorithm:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 2. Heuristic (if any):
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 3. Did it find least-cost path? If not, why?
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### G6:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: A (4) → B
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: B (6) → C
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: B (7) → D
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: B (7) → G
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: A (5) → D
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: D (4) → C
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: D (6) → G
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: C (5) → G
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 1. Algorithm:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 2. Heuristic (if any):
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 3. Did it find least-cost path? If not, why?
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: #### G7:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: A (1) → B
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: A (3) → D
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: B (6) → C
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: B (5) → D
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: B (7) → G
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: D (6) → C
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: D (8) → G
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: D (4) → C
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: D (6) → G
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: C (5) → G
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 1. Algorithm:
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 2. Heuristic (if any):
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

QUESTION: 3. Did it find least-cost path? If not, why?
//// ANSWER: Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 11.75 MiB is free. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.57 GiB is allocated by PyTorch, and 5.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

