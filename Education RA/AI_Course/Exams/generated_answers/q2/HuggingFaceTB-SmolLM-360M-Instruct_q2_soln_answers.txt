MODEL: HuggingFaceTB/SmolLM-360M-Instruct
EXAM: q2_soln

QUESTION: 6.034 Quiz 2, Spring 2005 > 1 Decision Trees > 1. Construct a decision tree for the data.:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  1 Decision Trees  1. Construct a decision tree for the data.: 6.034 Quiz 2, Spring 2005  2 Decision Trees  2. Construct a decision tree for the data.: 6.034 Quiz 2, Spring 2005  3 Decision Trees  3. Construct a decision tree for the data.: 6.034 Quiz 2, Spring 2005  4 Decision Trees  4. Construct a decision tree for the data.: 6.034 Quiz 2, Spring 2005  5 Decision Trees  5. Construct a decision tree for the data.: 6.034 Quiz 2, Spring 2005  6 Decision Trees  6. Construct a decision tree for the data.: 6.034 Quiz 2, Spring 2005  7 Decision Trees  7. Construct a decision tree for the data.: 6.034 Quiz 2, Spring 2005  8 Decision Trees  8. Construct a decision tree for the data.: 6.034 Quiz 2, Spring 2005  9 Decision Trees  9.

QUESTION: 6.034 Quiz 2, Spring 2005 > 1 Decision Trees > 2. Draw decision boundaries on the graph.:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  1 Decision Trees  2. Draw decision boundaries on the graph.:

**Question 6.034 Quiz 2, Spring 2005**

**Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  1 Decision Trees  2. Draw decision boundaries on the graph.:

**Question 6.034 Quiz 2, Spring 2005**

**Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  1 Decision Trees  2. Draw decision boundaries on the graph.:

**Question 6.034 Quiz 2, Spring 2005**

**Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  1 Decision Trees  2. Draw decision boundaries on the graph.:

**Question 6.034 Quiz 2, Spring 2005**

**Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  1 Decision Trees  2. Draw decision boundaries on the graph.

QUESTION: 6.034 Quiz 2, Spring 2005 > 1 Decision Trees > 3. Explain how you chose the top-level test in the tree.:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  1 Decision Trees  3. Explain how you chose the top-level test in the tree.: 6.034 Quiz 2, Spring 2005  2 Decision Trees  2. Explain how you chose the top-level test in the tree.: 6.034 Quiz 2, Spring 2005  1 Decision Trees  4. Explain how you chose the top-level test in the tree.: 6.034 Quiz 2, Spring 2005  3 Decision Trees  3. Explain how you chose the top-level test in the tree.: 6.034 Quiz 2, Spring 2005  4 Decision Trees  4. Explain how you chose the top-level test in the tree.: 6.034 Quiz 2, Spring 2005  5 Decision Trees  5. Explain how you chose the top-level test in the tree.: 6.034 Quiz 2, Spring 2005  6 Decision Trees  6. Explain how you chose the top-level test in the tree.: 6.034 Quiz 2, Spring 2005  7 Decision Trees  7.

QUESTION: 6.034 Quiz 2, Spring 2005 > 1 Decision Trees > 4. What class does the tree predict for the point (1, -1.01)?:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  1 Decision Trees  4. What class does the tree predict for the point (1, -1.01)?: 4.034 Quiz 2, Spring 2005  1 Decision Trees  3. What class does the tree predict for the point (1, -1.01)?: 4.034 Quiz 2, Spring 2005  1 Decision Trees  2. What class does the tree predict for the point (1, -1.01)?: 4.034 Quiz 2, Spring 2005  1 Decision Trees  3. What class does the tree predict for the point (1, -1.01)?: 4.034 Quiz 2, Spring 2005  1 Decision Trees  4. What class does the tree predict for the point (1, -1.01)?: 4.034 Quiz 2, Spring 2005  1 Decision Trees  5. What class does the tree predict for the point (1, -1.01)?: 4.034 Quiz 2, Spring 2005  1 Decision Trees  6.

QUESTION: 6.034 Quiz 2, Spring 2005 > 1 Decision Trees > Data points:  
Negative: (-1, 0), (2, 1), (2, -2)  
Positive: (0, 0), (1, 0):
ANSWER: Answer concisely in English without code: 6.

QUESTION: 6.034 Quiz 2, Spring 2005 > 2 Nearest Neighbors > 1. Draw 1-NN decision boundaries.:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  2 Nearest Neighbors  1. Draw 1-NN decision boundaries.: 6.034 Quiz 2, Spring 2005  2 Nearest Neighbors  2. Draw 2-NN decision boundaries.: 6.034 Quiz 2, Spring 2005  3 Nearest Neighbors  3 Nearest Neighbors  3. Draw 3-NN decision boundaries.: 6.034 Quiz 2, Spring 2005  4 Nearest Neighbors  4 Nearest Neighbors  4. Draw 4-NN decision boundaries.: 6.034 Quiz 2, Spring 2005  5 Nearest Neighbors  5 Nearest Neighbors  5. Draw 5-NN decision boundaries.: 6.034 Quiz 2, Spring 2005  6 Nearest Neighbors  6 Nearest Neighbors  6. Draw 6-NN decision boundaries.: 6.034 Quiz 2, Spring 2005  7 Nearest Neighbors  7 Nearest Neighbors  7. Draw 7-NN decision boundaries.: 6.

QUESTION: 6.034 Quiz 2, Spring 2005 > 2 Nearest Neighbors > 2. What class does 1-NN predict for (1, -1.01)? Explain.:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  2 Nearest Neighbors  2. What class does 1-NN predict for (1, -1.01)? Explain.: 2.034 Quiz 2, Spring 2005  2 Nearest Neighbors  2. What class does 1-NN predict for (1, -1.01)? Explain.: 2.034 Quiz 2, Spring 2005  2 Nearest Neighbors  2. What class does 1-NN predict for (1, -1.01)? Explain.: 2.034 Quiz 2, Spring 2005  2 Nearest Neighbors  2. What class does 1-NN predict for (1, -1.01)? Explain.: 2.034 Quiz 2, Spring 2005  2 Nearest Neighbors  2. What class does 1-NN predict for (1, -1.01)? Explain.: 2.034 Quiz 2, Spring 2005  2 Nearest Neighbors  2. What class does 1-NN predict for (1, -1.01)? Explain.: 2.

QUESTION: 6.034 Quiz 2, Spring 2005 > 2 Nearest Neighbors > 3. What class does 3-NN predict for (1, -1.01)? Explain.:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  2 Nearest Neighbors  3. What class does 3-NN predict for (1, -1.01)? Explain.: 3-NN predicts for 3-NN.

**Question 6.035 Quiz 2, Spring 2005  2 Nearest Neighbors  4. What class does 3-NN predict for (1, -1.01)? Explain.: 3-NN predicts for 3-NN.

**Question 6.036 Quiz 2, Spring 2005  2 Nearest Neighbors  5. What class does 3-NN predict for (1, -1.01)? Explain.: 3-NN predicts for 3-NN.

**Question 6.037 Quiz 2, Spring 2005  2 Nearest Neighbors  6. What class does 3-NN predict for (1, -1.01)? Explain.: 3-NN predicts for 3-NN.

**Question 6.038 Quiz 2, Spring 2005  2 Nearest Neighbors  7. What class does 3-NN predict for (1, -1.01)? Explain.

QUESTION: 6.034 Quiz 2, Spring 2005 > 2 Nearest Neighbors:
ANSWER: Answer concisely in English without code: 6.

QUESTION: 6.034 Quiz 2, Spring 2005 > 3 Perceptron > 1. Explain how the perceptron algorithm produces the separator (0, 1, 2).:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  3 Perceptron  1. Explain how the perceptron algorithm produces the separator (0, 1, 2).: 6.034 Quiz 2, Spring 2005  2 Perceptron  1. Explain how the perceptron algorithm produces the separator (0, 1, 2).: 6.034 Quiz 2, Spring 2005  3 Perceptron  1. Explain how the perceptron algorithm produces the separator (0, 1, 2).: 6.034 Quiz 2, Spring 2005  4 Perceptron  1. Explain how the perceptron algorithm produces the separator (0, 1, 2).: 6.034 Quiz 2, Spring 2005  5 Perceptron  1. Explain how the perceptron algorithm produces the separator (0, 1, 2).: 6.034 Quiz 2, Spring 2005  6 Perceptron  1. Explain how the perceptron algorithm produces the separator (0, 1, 2).: 6.034 Quiz 2, Spring 2005  7 Perceptron  1.

QUESTION: 6.034 Quiz 2, Spring 2005 > 3 Perceptron > 2. Predict the class for (2.0, -1.01).:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  3 Perceptron  2. Predict the class for (2.0, -1.01).: 2.034 Quiz 2, Spring 2005  3 Perceptron  2. Predict the class for (2.0, -1.01).: 2.034 Quiz 2, Spring 2005  3 Perceptron  2. Predict the class for (2.0, -1.01).: 2.034 Quiz 2, Spring 2005  3 Perceptron  2. Predict the class for (2.0, -1.01).: 2.034 Quiz 2, Spring 2005  3 Perceptron  2. Predict the class for (2.0, -1.01).: 2.034 Quiz 2, Spring 2005  3 Perceptron  2. Predict the class for (2.0, -1.01).: 2.034 Quiz 2, Spring 2005  3 Perceptron  2. Predict the class for (2.0, -1.01).: 2.

QUESTION: 6.034 Quiz 2, Spring 2005 > 3 Perceptron > 3. Describe the result if applied to the 5-point dataset from Problem 1.:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  3 Perceptron  3. Describe the result if applied to the 5-point dataset from Problem 1.: 3.1.2.1. The output of the perceptron is 1.0. The output of the perceptron is 1.0. The output of the perceptron is 1.0. The output of the perceptron is 1.0. The output of the perceptron is 1.0. The output of the perceptron is 1.0. The output of the perceptron is 1.0. The output of the perceptron is 1.0. The output of the perceptron is 1.0. The output of the perceptron is 1.0. The output of the perceptron is 1.0. The output of the perceptron is 1.0. The output of the perceptron is 1.0. The output of the perceptron is 1.0. The output of the perceptron is 1.0. The output of the perceptron is 1.0. The output of the perceptron is 1.0. The output of the perceptron is 1.0. The output of the perceptron is 1.0.

QUESTION: 6.034 Quiz 2, Spring 2005 > 3 Perceptron > Data points:  
Negative: (-1, 0), (2, -2)  
Positive: (1, 0):
ANSWER: Answer concisely in English without code: 6.

QUESTION: 6.034 Quiz 2, Spring 2005 > 4 Neural Net > 1. Compute sigmoid outputs for points (-1,0), (2,-2), (1,0) with weights \(w_0=0, w_1=1, w_2=1\).:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  4 Neural Net  1. Compute sigmoid outputs for points (-1,0), (2,-2), (1,0) with weights \(w_0=0, w_1=1, w_2=1\).: 6.034 Quiz 2, Spring 2005  4 Neural Net  2. Compute sigmoid outputs for points (-1,0), (2,-2), (1,0) with weights \(w_0=0, w_1=1, w_2=1\).: 6.034 Quiz 2, Spring 2005  4 Neural Net  3. Compute sigmoid outputs for points (-1,0), (2,-2), (1,0) with weights \(w_0=0, w_1=1, w_2=1\).: 6.034 Quiz 2, Spring 2005  4 Neural Net  4. Compute sigmoid outputs for points (-1,0), (2,-2), (1,0) with weights \(w_0=0, w_1=1, w_2=1\).: 6.034 Quiz 2, Spring 2005  4 Neural Net  5.

QUESTION: 6.034 Quiz 2, Spring 2005 > 4 Neural Net > 2. Calculate \(\Delta w_2\) via backpropagation for input (2,-2).:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  4 Neural Net  2. Calculate \(\Delta w_2\) via backpropagation for input (2,-2).: 2. Calculate \(\Delta w_1\) via backpropagation for input (1,1).: 2. Calculate \(\Delta w_1\) via backpropagation for input (1,0).: 2. Calculate \(\Delta w_1\) via backpropagation for input (0,0).: 2. Calculate \(\Delta w_1\) via backpropagation for input (0,1).: 2. Calculate \(\Delta w_1\) via backpropagation for input (0,0).: 2. Calculate \(\Delta w_1\) via backpropagation for input (0,1).: 2. Calculate \(\Delta w_1\) via backpropagation for input (0,0).: 2. Calculate \(\Delta w_1\) via backpropagation for input (0,1).: 2. Calculate \(\Delta w_1\) via backpropagation for input (0,0).: 2. Calculate \(\Delta w_1\) via backpropagation for input (0,1).: 2.

QUESTION: 6.034 Quiz 2, Spring 2005 > 4 Neural Net:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  4 Neural Net: 6.034 Quiz 2, Spring 2005  4 Neural Net: 6.034 Quiz 2, Spring 2005  4 Neural Net: 6.034 Quiz 2, Spring 2005  4 Neural Net: 6.034 Quiz 2, Spring 2005  4 Neural Net: 6.034 Quiz 2, Spring 2005  4 Neural Net: 6.034 Quiz 2, Spring 2005  4 Neural Net: 6.034 Quiz 2, Spring 2005  4 Neural Net: 6.034 Quiz 2, Spring 2005  4 Neural Net: 6.034 Quiz 2, Spring 2005  4 Neural Net: 6.034 Quiz 2, Spring 2005  4 Neural Net: 6.034 Quiz 2, Spring 2005  4 Neural Net: 6.

QUESTION: 6.034 Quiz 2, Spring 2005 > 5 Naive Bayes > 1. Compute \(\Pr(x_1=1|y=0)\), \(\Pr(x_2=1|y=1)\), \(\Pr(x_3=0|y=0)\) with Laplacian correction.:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  5 Naive Bayes  1. Compute \(\Pr(x_1=1|y=0)\), \(\Pr(x_2=1|y=1)\), \(\Pr(x_3=0|y=0)\) with Laplacian correction.: 6.034 Quiz 2, Spring 2005  4 Naive Bayes  2. Compute \(\Pr(x_1=1|y=0)\), \(\Pr(x_2=1|y=1)\), \(\Pr(x_3=0|y=0)\) with Laplacian correction.: 6.034 Quiz 2, Spring 2005  3 Naive Bayes  3. Compute \(\Pr(x_1=1|y=0)\), \(\Pr(x_2=1|y=1)\), \(\Pr(x_3=0|y=0)\) with Laplacian correction.: 6.034 Quiz 2, Spring 2005  2 Naive Bayes  2. Compute \(\Pr(x_1=1|y=0)\), \(\Pr(x_2=1|y=1)\), \(\Pr(x_3=0|y=0)\) with Laplacian correction.: 6.

QUESTION: 6.034 Quiz 2, Spring 2005 > 5 Naive Bayes > 2. Identify the most influential feature.:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  5 Naive Bayes  2. Identify the most influential feature.: 6.034 Quiz 2, Spring 2005  4 Naive Bayes  1. Identify the most influential class: 6.034 Quiz 2, Spring 2005  3 Naive Bayes  2. Identify the most influential feature: 6.034 Quiz 2, Spring 2005  2 Naive Bayes  1. Identify the most influential class: 6.034 Quiz 2, Spring 2005  1 Naive Bayes  1. Identify the most influential feature: 6.034 Quiz 2, Spring 2005  1 Naive Bayes  1. Identify the most influential class: 6.034 Quiz 2, Spring 2005  1 Naive Bayes  1. Identify the most influential feature: 6.034 Quiz 2, Spring 2005  1 Naive Bayes  1. Identify the most influential class: 6.

QUESTION: 6.034 Quiz 2, Spring 2005 > 5 Naive Bayes > Training data (12 examples: 6 positive, 6 negative):  
|  Feature  | \(y=0\) | \(y=1\) |  
|-----------|---------|---------|  
| \(x_1=1\) | 6       | 6       |  
| \(x_2=1\) | 0       | 0       |  
| \(x_3=1\) | 2       | 4       |:
ANSWER: Answer concisely in English without code: 6.

QUESTION: 6.034 Quiz 2, Spring 2005 > 6 Learning Algorithms > 1. 1M training examples, 6D features, 100 test queries.:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  1. 1M training examples, 6D features, 100 test queries.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  1. 1M training examples, 6D features, 100 test queries.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  1. 1M training examples, 6D features, 100 test queries.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  1. 1M training examples, 6D features, 100 test queries.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  1. 1M training examples, 6D features, 100 test queries.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  1. 1M training examples, 6D features, 100 test queries.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  1.

QUESTION: 6.034 Quiz 2, Spring 2005 > 6 Learning Algorithms > 2. Classifier for kindergarten special education requiring justification.:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  2. Classifier for kindergarten special education requiring justification.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  2. Classifier for kindergarten special education requiring justification.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  2. Classifier for kindergarten special education requiring justification.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  2. Classifier for kindergarten special education requiring justification.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  2. Classifier for kindergarten special education requiring justification.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  2. Classifier for kindergarten special education requiring justification.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  2. Classifier for kindergarten special education requiring justification.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  2. Classifier for kindergarten special education requiring justification.: 6.

QUESTION: 6.034 Quiz 2, Spring 2005 > 6 Learning Algorithms > 3. Book preference prediction with 1M features and frequent updates.:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  3. Book preference prediction with 1M features and frequent updates.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  2. Book preference prediction with 1M features and frequent updates.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  1. Book preference prediction with 1M features and frequent updates.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  1. Book preference prediction with 1M features and frequent updates.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  1. Book preference prediction with 1M features and frequent updates.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  1. Book preference prediction with 1M features and frequent updates.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  1. Book preference prediction with 1M features and frequent updates.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  1.

QUESTION: 6.034 Quiz 2, Spring 2005 > 6 Learning Algorithms > 4. Rainfall prediction from ocean currents/tides.:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  4. Rainfall prediction from ocean currents/tides.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  4. Rainfall prediction from ocean currents/tides.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  4. Rainfall prediction from ocean currents/tides.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  4. Rainfall prediction from ocean currents/tides.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  4. Rainfall prediction from ocean currents/tides.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  4. Rainfall prediction from ocean currents/tides.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  4. Rainfall prediction from ocean currents/tides.: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  4. Rainfall prediction from ocean currents/tides.: 6.

QUESTION: 6.034 Quiz 2, Spring 2005 > 6 Learning Algorithms > For each scenario, choose the best algorithm and justify:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  For each scenario, choose the best algorithm and justify: a) The best algorithm for the given problem. b) The worst algorithm for the given problem. c) The best algorithm for the given problem. d) The worst algorithm for the given problem.

**Question 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  For each scenario, choose the best algorithm and justify: a) The best algorithm for the given problem. b) The worst algorithm for the given problem. c) The best algorithm for the given problem. d) The worst algorithm for the given problem.

**Question 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  For each scenario, choose the best algorithm and justify: a) The best algorithm for the given problem. b) The worst algorithm for the given problem. c) The best algorithm for the given problem. d) The worst algorithm for the given problem.

**Question 6.034 Quiz 2, Spring 2005  6 Learning Algorithms  For each scenario, choose the best algorithm and justify: a) The best algorithm for the given problem. b) The worst algorithm for the given problem.

QUESTION: 6.034 Quiz 2, Spring 2005 > 7 Error vs Complexity > 1. Perceptron:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  7 Error vs Complexity  1. Perceptron: 1.234 Quiz 2, Spring 2005  2. Perceptron: 1.234 Quiz 2, Spring 2005  3. Perceptron: 1.234 Quiz 2, Spring 2005  4. Perceptron: 1.234 Quiz 2, Spring 2005  5. Perceptron: 1.234 Quiz 2, Spring 2005  6. Perceptron: 1.234 Quiz 2, Spring 2005  7. Perceptron: 1.234 Quiz 2, Spring 2005  8. Perceptron: 1.234 Quiz 2, Spring 2005  9. Perceptron: 1.234 Quiz 2, Spring 2005  10. Perceptron: 1.234 Quiz 2, Spring 2005  11. Perceptron: 1.

QUESTION: 6.034 Quiz 2, Spring 2005 > 7 Error vs Complexity > 2. Linear SVM:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  7 Error vs Complexity  2. Linear SVM: 6.034 Quiz 2, Spring 2005  3. Linear SVM: 6.034 Quiz 2, Spring 2005  4. Linear SVM: 6.034 Quiz 2, Spring 2005  5. Linear SVM: 6.034 Quiz 2, Spring 2005  6. Linear SVM: 6.034 Quiz 2, Spring 2005  7. Linear SVM: 6.034 Quiz 2, Spring 2005  8. Linear SVM: 6.034 Quiz 2, Spring 2005  9. Linear SVM: 6.034 Quiz 2, Spring 2005  10. Linear SVM: 6.034 Quiz 2, Spring 2005  11. Linear SVM: 6.034 Quiz 2, Spring 2005  12. Linear SVM: 6.

QUESTION: 6.034 Quiz 2, Spring 2005 > 7 Error vs Complexity > 3. Decision Tree:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  7 Error vs Complexity  3. Decision Tree: 6.034 Quiz 2, Spring 2005  4. Decision Tree: 6.034 Quiz 2, Spring 2005  5. Decision Tree: 6.034 Quiz 2, Spring 2005  6. Decision Tree: 6.034 Quiz 2, Spring 2005  7. Decision Tree: 6.034 Quiz 2, Spring 2005  8. Decision Tree: 6.034 Quiz 2, Spring 2005  9. Decision Tree: 6.034 Quiz 2, Spring 2005  10. Decision Tree: 6.034 Quiz 2, Spring 2005  11. Decision Tree: 6.034 Quiz 2, Spring 2005  12. Decision Tree: 6.034 Quiz 2, Spring 2005  13. Decision Tree: 6.034 Quiz 2, Spring 2005  14.

QUESTION: 6.034 Quiz 2, Spring 2005 > 7 Error vs Complexity > 4. Neural Network:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  7 Error vs Complexity  4. Neural Network: 6.034 Quiz 2, Spring 2005  5. Neural Network: 6.034 Quiz 2, Spring 2005  6. Neural Network: 6.034 Quiz 2, Spring 2005  7. Neural Network: 6.034 Quiz 2, Spring 2005  8. Neural Network: 6.034 Quiz 2, Spring 2005  9. Neural Network: 6.034 Quiz 2, Spring 2005  10. Neural Network: 6.034 Quiz 2, Spring 2005  11. Neural Network: 6.034 Quiz 2, Spring 2005  12. Neural Network: 6.034 Quiz 2, Spring 2005  13. Neural Network: 6.034 Quiz 2, Spring 2005  14. Neural Network: 6.034 Quiz 2, Spring 2005  15.

QUESTION: 6.034 Quiz 2, Spring 2005 > 7 Error vs Complexity > 5. SVM:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  7 Error vs Complexity  5. SVM: 7.534 Quiz 2, Spring 2005  6. SVM: 7.534 Quiz 2, Spring 2005  7. SVM: 7.534 Quiz 2, Spring 2005  8. SVM: 7.534 Quiz 2, Spring 2005  9. SVM: 7.534 Quiz 2, Spring 2005  10. SVM: 7.534 Quiz 2, Spring 2005  11. SVM: 7.534 Quiz 2, Spring 2005  12. SVM: 7.534 Quiz 2, Spring 2005  13. SVM: 7.534 Quiz 2, Spring 2005  14. SVM: 7.534 Quiz 2, Spring 2005  15. SVM: 7.

QUESTION: 6.034 Quiz 2, Spring 2005 > 7 Error vs Complexity > For each algorithm, specify:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  7 Error vs Complexity  For each algorithm, specify:  1. The input and output sizes  2. The number of iterations  3. The number of iterations per iteration  4. The number of iterations per iteration  5. The number of iterations per iteration  6. The number of iterations per iteration  7. The number of iterations per iteration  8. The number of iterations per iteration  9. The number of iterations per iteration  10. The number of iterations per iteration  11. The number of iterations per iteration  12. The number of iterations per iteration  13. The number of iterations per iteration  14. The number of iterations per iteration  15. The number of iterations per iteration  16. The number of iterations per iteration  17. The number of iterations per iteration  18. The number of iterations per iteration  19. The number of iterations per iteration  20. The number of iterations per iteration  21. The number of iterations per iteration  22. The number of iterations per iteration  23. The number of iterations per iteration  24.

QUESTION: 6.034 Quiz 2, Spring 2005 > 8 Regression > 1. 2-NN:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  8 Regression  1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1. 2-NN: 1.

QUESTION: 6.034 Quiz 2, Spring 2005 > 8 Regression > 2. Regression Trees:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  8 Regression  2. Regression Trees: A Random Forest Approach

**Q1. What is the purpose of regression trees?**

A. To predict a continuous value
B. To predict a categorical value
C. To predict a continuous value and a categorical value
D. To predict a continuous value and a categorical value

**Answer: A. To predict a continuous value**

**Q2. What is the purpose of random forests?**

A. To predict a continuous value
B. To predict a categorical value
C. To predict a continuous value and a categorical value
D. To predict a continuous value and a categorical value

**Answer: B. To predict a categorical value**

**Q3. What is the difference between a decision tree and a random forest?**

A. A decision tree is a random forest
B. A decision tree is a random forest
C. A decision tree is a random forest
D. A decision tree is a random forest

**Answer: A. A decision tree is a random forest**

**Q4. What is the purpose of a random forest?**

A. To predict a continuous value
B. To predict a categorical value
C.

QUESTION: 6.034 Quiz 2, Spring 2005 > 8 Regression > 3. Linear Neural Network:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  8 Regression  3. Linear Neural Network: A Simple Example

**Question 1**

What is the difference between a linear and a non-linear model?

**Answer**

A linear model is a model that is used to describe the relationship between two or more variables, while a non-linear model is a model that is used to describe the relationship between two or more variables, but not necessarily in a linear way.

**Question 2**

What is the difference between a regression model and a classification model?

**Answer**

A regression model is a model that is used to predict a continuous output variable, while a classification model is a model that is used to predict a categorical output variable.

**Question 3**

What is the difference between a logistic regression model and a linear regression model?

**Answer**

A logistic regression model is a model that is used to predict a binary output variable, while a linear regression model is a model that is used to predict a continuous output variable.

**Question 4**

What is the difference between a neural network and a decision tree?

QUESTION: 6.034 Quiz 2, Spring 2005 > 8 Regression > 4. Multi-layer Neural Network:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  8 Regression  4. Multi-layer Neural Network: 4.11.1  2.2.1  1.1.1  1.1.2  1.1.3  1.1.4  1.1.5  1.1.6  1.1.7  1.1.8  1.1.9  1.1.10  1.1.11  1.1.12  1.1.13  1.1.14  1.1.15  1.1.16  1.1.17  1.1.18  1.1.19  1.1.20  1.1.21  1.1.22  1.1.23  1.1.24  1.1.25  1.1.26  1.1.27  1.1.28  1.1.29  1.1.30  1.1.

QUESTION: 6.034 Quiz 2, Spring 2005 > 8 Regression > Draw regression outputs for:
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  8 Regression  Draw regression outputs for:  1.  2.  3.  4.  5.  6.  7.  8.  9.  10.  11.  12.  13.  14.  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.  28.  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.  42.  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.

QUESTION: 6.034 Quiz 2, Spring 2005 > 9 SVM > 1. Evaluate if separators satisfy SVM conditions: > (a) \(x_1 + x_2 = 0\)  
   (b) \(x_1 + 1.5x_2 = 0\)  
   (c) \(x_1 + 2x_2 = 0\)  
   (d) \(2x_1 + 3x_2 = 0\):
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  9 SVM  1. Evaluate if separators satisfy SVM conditions:  (a) \(x_1 + x_2 = 0\)  
   (b) \(x_1 + 1.5x_2 = 0\)  
   (c) \(x_1 + 2x_2 = 0\)  
   (d) \(2x_1 + 3x_2 = 0\): 1. Evaluate if separators satisfy SVM conditions:  (a) \(x_1 + x_2 = 0\)  
   (b) \(x_1 + 1.5x_2 = 0\)  
   (c) \(x_1 + 2x_2 = 0\)  
   (d) \(2x_1 + 3x_2 = 0\): 1. Evaluate if separators satisfy SVM conditions:  (a) \(x_1 + x_2 = 0\)  
   (b) \(x_1 + 1.5x_2 = 0\)  
   (c) \(x_1 + 2x_2 = 0\)  
   (d) \(2x_1 + 3x_2 = 0\): 1. Evaluate if separators satisfy SVM conditions:  (a) \(x_1 + x_2 = 0\)  
   (b) \(x_1 + 1.

QUESTION: 6.034 Quiz 2, Spring 2005 > 9 SVM > 2. Match kernels to decision boundaries: > (a) Polynomial (degree=2)  
   (b) Polynomial (degree=3)  
   (c) RBF (\(\sigma=0.5\))  
   (d) RBF (\(\sigma=1.0\)):
ANSWER: Answer concisely in English without code: 6.034 Quiz 2, Spring 2005  9 SVM  2. Match kernels to decision boundaries:  (a) Polynomial (degree=2)  
   (b) Polynomial (degree=3)  
   (c) RBF (\(\sigma=0.5\))  
   (d) RBF (\(\sigma=1.0\)): 1.0
   (e) RBF (\(\sigma=1.5\)): 1.5
   (f) RBF (\(\sigma=2.0\)): 2.0
   (g) RBF (\(\sigma=3.0\)): 3.0
   (h) RBF (\(\sigma=4.0\)): 4.0
   (i) RBF (\(\sigma=5.0\)): 5.0
   (j) RBF (\(\sigma=6.0\)): 6.0
   (k) RBF (\(\sigma=7.0\)): 7.0
   (l) RBF (\(\sigma=8.0\)): 8.0
   (m) RBF (\(\sigma=9.0\)): 9.0
   (n) RBF (\(\sigma=10.0\)): 10.0
   (o) RBF (\(\sigma=11.0\)): 11.0
   (p) RBF (\(\sigma=12.0\)): 12.

QUESTION: 6.034 Quiz 2, Spring 2005 > 9 SVM > Data points:  
Negative: (-1, 0), (2, -2)  
Positive: (1, 0):
ANSWER: Answer concisely in English without code: 6.

