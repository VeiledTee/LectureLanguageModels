{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is amortized analysis?"}, {"role": "assistant", "content": "Amortized analysis is a powerful technique for data structure analysis, involving the total runtime of a sequence of operations. This lecture covers different techniques of amortized analysis (aggregate method, accounting method, charging method, potential method) and examples of amortized analysis (table doubling, binary counter, 2-3 tree and 2-5 tree)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe Table doubling."}, {"role": "assistant", "content": "To store n elements in a table of size m = O(n), double m whenever n becomes larger than m (due to insertions). The cost to double a table of size m is clearly \u0472(m) = \u0398(n), which is also the worse case cost of an insertion. The total cost of n insertions is at most:\n\n2\u00ba + 21 + 22 + \u00b7\u00b7\u00b7 + 2[lgn] = \u0398(n).\n\nEach insertion has O(n)/n = \u0398(1) amortized cost."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe Aggregate Method."}, {"role": "assistant", "content": "The aggregate method is: add up the cost of all the operations and then divide by the number of operations.\namortized cost per operation = total cost of k operations / k.\nIt is the simplest method but may not be able to analyze more complicated algorithms."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe Amortized Bound Definition."}, {"role": "assistant", "content": "Amortized cost can be, but does not have to be, average cost. We can assign any amortized cost to each operation, as long as they\u201cpreserve the total cost\", i.e., for any sequence of operations,\n\n\u2611 amortized cost \u2265 \u2611 actual cost\n\nwhere the sum is taken over all operations. A 2-3 tree achieves O(1) amortized cost per create, O(lg n*) amortized cost per insert, and 0 amortized cost per delete, where n* is the maximum size of the 2-3 tree during the entire sequence of operations. For any sequence of operations, suppose there are c creations, i insertions and d \u2264 i deletions (cannot delete from an empty tree), the total amortized cost is asymptotically the same as the total actual cost:\n\nO(c + ilgn* + 0d) = O(c + ilgn* + dlgn*)\n\nThe amortized cost per insert to O(lgn) where n is the current size."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe Accounting Method."}, {"role": "assistant", "content": "This method allows an operation to store credit into a bank for future use, if its assigned amortized cost > its actual cost; it also allows an operation to pay for its extra actual cost using existing credit, if its assigned amortized cost < its actual cost. For table doubling, if an insertion does not trigger table doubling, store a coin representing c = O(1) work for future use. If an insertion does trigger table doubling, there must be n/2 elements that are inserted after the previous table doubling, whose coins have not been consumed. Use up these n/2 coins to pay for the O(n) table doubling. amortized cost for table doubling: O(n) \u2013 c . n/2 = 0 for large enough c. amortized cost per insertion: 1 + c = O(1)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe Charging Method."}, {"role": "assistant", "content": "The charging method allows operations to charge cost retroactively to past operations.\namortized cost of an operation = actual cost of this operation \u2013 total cost charged to past operations + total cost charged by future operations\n\nFor example, in table doubling, when the table doubles from m to 2m, we can charge (m) cost to the m/2 insert operations since the last doubling. Each insert is charged by (1), and will not be charged again. So the amortized cost per insert is \u0398(1). Now let's extend the above example with table halving. The motivation is to save space when with deletes. If the table is down to 1/4 full, n = m/4, we shrink the table size from m to m/2 at \u04e8(m) cost. This way, the table is half full again after any resize (doubling or shrinking). Now each table doubling still has \u2265 m/2 insert operations to charge to, and each table halving has \u2265 m/4 delete operations to charge to. So the amortized cost per insert or delete is still \u04e8(1)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe Free deletion in 2-3 trees."}, {"role": "assistant", "content": "Insert has O(lgn) amortized cost, where n is the size of the tree when that insert happens, and delete has 0 amortized cost. Insert does not need to charge anything. Delete will charge an insert operation. But we will not charge the insert of the element to be deleted, because we will run into the same problem as the accounting method. Instead, each delete operation will charge the insert operation that brought the tree to its current size n. Each insert is still charged at most once, because for the tree size to reach n again, another insert must happen."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe Potential Method."}, {"role": "assistant", "content": "This method defines a potential function that maps a data structure (DS) configu- ration to a value. This function \u00de is equivalent to the total unused credits stored up by all past operations (the bank account balance). Now\n\namortized cost of an operation = actual cost of this operation + \u0394\u03a6\n\nand\n\namortized cost = \u2211 actual cost + \u03a6(final DS) \u2013 \u0424(initial DS).\n\nIn order for the amortized bound to hold, I should never go below (initial DS) at any point. If (initial DS) = 0, which is usually the case, then I should never go negative (intuitively, we cannot \"owe the bank\u201d). In accounting method, we specify \u0394\u03a6, while in potential method, we specify \u0424. One determines the other, so the two methods are equivalent. But sometimes one is more intuitive than the other."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe Binary counter using Potential Method."}, {"role": "assistant", "content": "Cost of increment is \u0472(1 + #1), where #1 represents the number of trailing 1 bits. So the intuition is that 1 bits are bad.\nDefine \u03a6 = c . #1. Then for large enough c,\n\namortized cost = actual cost + \u0394\u03a6 =  \u0398(1 + #1) + c(\u2212#1 + 1) = \u0398(1)\n\n\u03a6(initial DS) = 0 if the counter starts at 0000. This is necessary for the above amortized analysis. Otherwise, I may become smaller than \u03a6(initial DS)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe Insert in 2-3 trees using Potential Method."}, {"role": "assistant", "content": "Insert can cause O(lg n) splits in the worst case, but we can show it causes only O(1) amortized splits. First consider what causes a split: insertion into a 3-node (a node with 3 children). In that case, the 3-node needs to split into two 2-nodes. So 3-nodes are bad. We define \u0424 = the number of 3-nodes. Then \u0394\u03a6 < 1 the number of splits. Amortized number of splits = actual number of splits + \u0394\u03a6 = 1. \u03a6(initial DS) = 0 if the tree is empty initially. The above analysis holds for any (a, b)-tree, if we define \u00de to be the number of b-nodes. If we consider both insertion and deletion in 2-3 trees, can we claim both O(1) splits for insert, and O(1) merges for delete? The answer is no, because a split creates two 2-nodes, which are bad for merge. In the worse case, they may be merged by the next delete, and then need split again on the next insert, and so on. What do we solve this problem? We need to prevent split and merge from creating 'bad' nodes."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe Insert and delete in 2-5 trees."}, {"role": "assistant", "content": "We can claim O(1) splits for insert, and O(1) merges for delete in 2-5 trees. In 2-5 trees, insertion into a 5-node (a node with 5 children) causes it to split into two 3-nodes. Deletion from a 2-node causes it to merge with another 2-node to form a 3-node. 5-nodes and 2-nodes are bad. We define \u03a6 = # of 5-nodes + # of 2-nodes. Amortized splits and merges = 1. \u03a6(initial DS) = 0 if the tree is empty initially. The above analysis holds for any (a, b)-tree where b > 2a, because splits and merges do not produce bad nodes. We define \u00de to be the number of b-nodes plus the number of a nodes. Note: The potential examples could also be done with the accounting method by placing coins on 1s (binary counter) or 2/5-nodes ((2,5)-trees)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the main topics covered in Lecture 7?"}, {"role": "assistant", "content": "Skip Lists, including data structure, randomized insertion, and with high probability (w.h.p.) bound."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe Skip Lists."}, {"role": "assistant", "content": "Skip lists are simple randomized dynamic search structures invented by William Pugh in 1989, easy to implement, and maintain a dynamic set of n elements in O(lg n) time per operation in expectation and with high probability. They provide a strong guarantee on the tail of the distribution of T(n) and achieve O(lg n) 'almost always'."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the time complexity for searches in a sorted linked list?"}, {"role": "assistant", "content": "Searches take O(n) time in the worst case."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How can we speed up searches?"}, {"role": "assistant", "content": "By using two sorted linked lists. It is assumed that you have two sorted linked lists on subsets of the elements, and each element can appear in one or both lists."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the SEARCH(x) process in two linked lists?"}, {"role": "assistant", "content": "Walk right in the top linked list (L\u2081) until going right would go too far, walk down to the bottom linked list (L\u2082), and walk right in L\u2082 until the element is found (or not)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Which nodes should be in L\u2081 when designing two linked lists?"}, {"role": "assistant", "content": "Evenly space the nodes in L\u2081 to care about worst-case performance. In a subway, the \"popular stations\""}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the search cost analysis of two linked lists?"}, {"role": "assistant", "content": "The search cost is roughly |L\u2081| + |L\u2082|/|L\u2081|, which is minimized (up to constant factors) when the terms are equal.  This leads to |L\u2081|\u00b2 = |L\u2082| = n, implying |L\u2081| = \\sqrt{n}. Therefore L\u2081 = \\sqrt{n}, L\u2082 = n and search cost is roughly |L\u2081| + |L\u2082|/|L\u2081| = \\sqrt{n} + n/\\sqrt{n} = 2\\sqrt{n}"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "If we have k sorted lists, how does the search change?"}, {"role": "assistant", "content": "If there are 2 sorted lists \u2192 2\\cdot \\sqrt{n}, If there are 3 sorted lists \u2192 3\\cdot \\sqrt[3]{n}, If there are k sorted lists \u2192 k\\cdot \\sqrt[k]{n}, If there are lg n sorted lists \u2192 lg n \\cdot \\sqrt[lgn]{n} = 2lgn"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How are lg n sorted linked lists similar to another data structure?"}, {"role": "assistant", "content": "lg n sorted linked lists are like a binary tree (in fact, level-linked B+-tree)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is an Ideal Skip List?"}, {"role": "assistant", "content": "An ideal skip list is a lg n linked list structure."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the process to insert an element x into a skip list?"}, {"role": "assistant", "content": "To insert an element x into a skip list:  SEARCH(x) to see where x fits in the bottom list, always insert into the bottom list, which contains all elements, and insert into some of the lists above. For the question, 'To which other lists should we add x?' flip a (fair) coin; if HEADS, promote x to the next level up and flip again.  The probability of promotion to the next level = p = 1/2. On average, 1/2 of the elements are promoted 0 levels, 1/4 of the elements are promoted 1 level, 1/8 of the elements are promoted 2 levels, etc."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What modifications are suggested to a skip list?"}, {"role": "assistant", "content": "Add a special -\u221e value to every list, so you can search with the same algorithm."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are insertions and deletions like in Skip Lists?"}, {"role": "assistant", "content": "A skip list is the result of insertions (and deletions) from an initially empty structure (containing just -\u221e). INSERT(x) uses random coin flips to decide the promotion level, and DELETE(x) removes x from all lists containing it."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the expected time for Search?"}, {"role": "assistant", "content": "Expected Time for Search: O(lg n)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How does searching in a skip list work?"}, {"role": "assistant", "content": "Search for the target begins with the head element in the top list. Proceed horizontally until the current element is greater than or equal to the target. If the current element equals the target, it has been found. If the current element is greater than the target, go back to the previous element and drop down vertically to the next lower list and repeat the procedure. The expected number of steps in each linked list is seen to be 1/p, by tracing the search path backwards from the target until reaching an element that appears in the next higher list. The total expected cost of a search is O(log1/p n) (1/p), which is O(lg n) when p is a constant."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What does the With-high-probability theorem state about search in a skip list?"}, {"role": "assistant", "content": "With high probability, every search in an n-element skip list costs O(lg n)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain the terms \"with high probability\" informally and formally."}, {"role": "assistant", "content": "Informally: Event E occurs with high probability (w.h.p.) if, for any a \u2265 1, there is an appropriate choice of constants for which E occurs with probability at least 1 - O(1/na).  In fact, the constant in O(lg n) depends on a.\nFormally: Parameterized event E\u03b1 occurs with high probability if, for any a \u2265 1, there is an appropriate choice of constants for which E\u03b1 occurs with probability at least 1 - c\u03b1/na."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is Boole's Inequality/Union Bound?"}, {"role": "assistant", "content": "For any random events E\u2081, E\u2082, ..., E\u2096, Pr{E\u2081 \u222a E\u2082 \u222a ... \u222a E\u2096} \u2264 Pr{E\u2081} + Pr{E\u2082} + ... + Pr{E\u2096}."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Give the analysis warmup for the number of levels in a skip list."}, {"role": "assistant", "content": "An n-element skip list has O(lg n) expected number of levels. The probability that x has been promoted once is p. The probability that x has been promoted k times is pk f. The expected number of promotions is Sigma I = 0 \\infty i. p^I = O(log Error probability for having at most c lg n levels = Pr{more than c lg n levels} \u2264 n \\cdot Pr{element x promoted at least c lg n times} = n\\cdot (1/2^{c lgn}) = n\\cdot (1/nc) = 1/nc-1 (by Boole's Inequality)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What does the error probability look like?"}, {"role": "assistant", "content": "Error probability for having at most c lg n levels <= 1/n^{c-1}. We can make a arbitrarily large by choosing the constant c in the O(lg n) bound accordingly."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How do we analyze search backwards, from leaf to root?"}, {"role": "assistant", "content": "Search starts [ends] at leaf (node in the bottom level). At each node visited: If node wasn't promoted higher (got TAILS here), then we go [came from] left. If node was promoted higher (got HEADS here), then we go [came from] up.  Search stops [starts] at the root (or -\u221e)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What does the Proof of theorem state about 'up' and 'left' moves?"}, {"role": "assistant", "content": "The search makes \"up\" and \"left\" moves until it reaches the root (or -\u221e). The expected number of \"up\" moves < num. of levels <= O(lg n) (Lemma)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Provide the Chernoff bound theorem."}, {"role": "assistant", "content": "Let Y be a random variable representing the total number of heads (tails) in a series of m independent coin flips, where each flip has a probability p of coming up heads (tails). Then, for all r > 0, Pr[Y > E[Y] + r] < e^{-2r^2/m}."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "State the Lemma for the number of heads in flipping d lgn fair coins."}, {"role": "assistant", "content": "For any c there is a constant d such that w.h.p. the number of heads in flipping d lgn fair coins is at least c lgn."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Give the Proof (contd.) for above Lemma."}, {"role": "assistant", "content": "Pr[Y >= (d - c) lgn] = Pr[Y >= E[Y] + (1/2 d - c) lgn]. Choose d = 3c => r = 3clgn.  By Chernoff, the probability of <= c lgn heads is <= e^{-2r^2/m} = e^{-2(3clgn)^2/8clgn} = e^{-9/4clgn} <= e^{-clgn} <= 2^{-clgn} (e > 2) = 1/nc."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the final Proof of Theorem?"}, {"role": "assistant", "content": "With high probability, every search in an n-element skip list costs O(lg n).\nevent A: number of levels <= c lgn w.h.p.\nevent B: number of moves until c lgn 'up' moves <= d lgn w.h.p.\nA and B are not independent!\nWant to show A & B occurs w.h.p. to prove theorem\nPr(A & B) = Pr(A + B) <= Pr(A) + Pr(B) (union bound)\n<= 1/nc-1 + 1/nc = O(1/nc-1)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What topics are covered in Lecture 24: Cache-oblivious algorithms II?"}, {"role": "assistant", "content": "Search (binary, B-ary, cache-oblivious) and Sorting (mergesorts, cache-oblivious)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Why is the LRU block replacement strategy important, and what does LRUM \u22642\u00b7OPTM/2 [Sleater and Tarjan 1985] imply?"}, {"role": "assistant", "content": "Proof: partition block access sequence into maximal phases of M/B distinct blocks, LRU spends < M/B memory transfers/phase, and OPT must spend \u2265 M/B memory transfers per phase: at best, starts phase with entire M/2 cache with needed items. But there are M/B blocks during phase. So \u2264 half free"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "In the context of searching, what is the initial preprocessing step and the performance of B-trees?"}, {"role": "assistant", "content": "Preprocess n elements in comparison model to support predecessor search for x. B-trees support predecessor (and insert and delete) in O(logB+1 N) memory transfers. Each node occupies \u0398(1) blocks, height= O(logB N), and we need to know B."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the performance of binary search, and what does MT(N) = \u0398(log N \u2013 log B) = \u0398(log(N/B)). SLOW imply?"}, {"role": "assistant", "content": "Approximately, every iteration visits a different block until we are in x's block. Thus, MT(N) = \u0398(log N \u2013 log B) = \u0398(log(N/B)). SLOW"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe van Emde Boas layout [Prokop 1999]?"}, {"role": "assistant", "content": "store N elements in complete BST, carve BST at middle level of edges, recursively layout the pieces and concatenate, like block matrix multiplication, order of pieces doesn't matter; just need each piece to be stored consecutively"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the Analysis of BST search in vEB layout?"}, {"role": "assistant", "content": "Consider recursive level of refinement at which structure has < B nodes, the height of the vEB tree is between lg B and lg B => size is between \u221aB and B => any root-to-node path (search path) visits < lg N = 2logB N trees that have size < B, each tree of size < B occupies \u2264 2 memory blocks => 4logB N = O(logB N) memory transfers"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What does this generalizes to heights that are not powers of 2, B-trees of constant branching factor and dynamic B-trees: O(logB N) insert/delete. [Bender, Demaine, Farach-Colton 2000] mean?"}, {"role": "assistant", "content": "this generalizes to heights that are not powers of 2, B-trees of constant branching factor and dynamic B-trees: O(logB N) insert/delete. [Bender, Demaine, Farach-Colton 2000]"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How do B-trees perform in terms of insertions, and what does MT(N) = \u0398(NlogB N) NOT OPTIMAL. By contrast, BST sort is optimal O(N lg N) mean?"}, {"role": "assistant", "content": "N inserts into (cache-oblivious) B-tree = MT(N) = \u0398(NlogB N) NOT OPTIMAL. By contrast, BST sort is optimal O(N lg N)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is Binary mergesort?"}, {"role": "assistant", "content": "Binary mergesort is cache-oblivious. The merge is 3 parallel scans => MT(N) = 2MT(N/2) + O(N/B + 1). MT(M) = O(M/B). The recursion tree has lg(N/M) levels, and each level contributes O(N/B) => MT(N) = lg(N/M) * (N/B) <= faster than the B-tree version discussed earlier!"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is M/B-way mergesort?"}, {"role": "assistant", "content": "Split array into M/B equal subarrays, recursively sort each, merge via M/B parallel scans (keeping one \u201ccurrent\u201d block per list) => MT(N) = (M/B)*MT(N/(M/B)) + O(N/B + 1). MT(M) = O(M/B), height becomes logM/B (N/M) + 1 = logM/B (N/B)-logM/B (M/B)+1 = logM/B (N/B)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the performance of cache-oblivious sorting, and what requirements does it have?"}, {"role": "assistant", "content": "MT(N) = O((N/B)logM/B (N/B)). This is asymptotically optimal, in the comparison model. This requires the tall-cache assumption: M = \u03a9(B1+e) for some fixed e > 0, e.g., M = \u03a9(B2) or M/B = \u03a9(B). Then, \u2248 N-way mergesort with recursive (\u201cfunnel\u201d) merge works."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are Priority Queues?"}, {"role": "assistant", "content": "O(logM/B N) per insert or delete-min, generalizes sorting, external memory and cache-oblivious, and see 6.851"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What topics are covered in Lecture 18?"}, {"role": "assistant", "content": "Vertex Cover, Fixed-Parameter Tractability, Kernelization, and Connection to Approximation"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are Fixed Parameter Algorithms?"}, {"role": "assistant", "content": "Fixed Parameter Algorithms are an alternative way to deal with NP-hard problems instead of approximation algorithms. There are three general desired features of an algorithm: Solve (NP-)hard problems, Run in polynomial time (fast), Get exact solutions. In general, unless P = NP, an algorithm can have two of these three features, but not all three. An algorithm that has Features 2 and 3 is an algorithm in P (poly-time exact). An approximation algorithm has Features 1 and 2. It solves hard problems, and it runs fast, but it does not give exact solutions. Fixed-parameter algorithms will have Features 1 and 3. They will solve hard problems and give exact solutions, but they will not run very fast."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the key idea behind Fixed Parameter Algorithms?"}, {"role": "assistant", "content": "The idea is to aim for an exact algorithm but isolate exponential terms to a specific parameter. When the value of this parameter is small, the algorithm gets fast instances. Hopefully, this parameter will be small in practice."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is a 'parameter' in the context of Fixed Parameter Algorithms?"}, {"role": "assistant", "content": "A parameter is a nonnegative integer k(x) where x is the problem input. Typically, the parameter is a natural property of the problem (some k in input). It may not necessarily be efficiently computable (e.g., OPT)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is a 'Parameterized Problem'?"}, {"role": "assistant", "content": "A parameterized problem is simply the problem plus the parameter or the problem as seen with respect to the parameter. There are potentially many interesting parameterizations for any given problem."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the goal of fixed-parameter algorithms?"}, {"role": "assistant", "content": "The goal of fixed-parameter algorithms is to have an algorithm that is polynomial in the problem size n but possibly exponential in the parameter k, and still get an exact solution."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Define the k-Vertex Cover problem."}, {"role": "assistant", "content": "Given a graph G = (V, E) and a nonnegative integer k, is there a set S\u2286 V of vertices of size at most k, |S| \u2264 k, that covers all edges. This is a decision problem for Vertex Cover and is also NP-hard. We will use k as the parameter to develop a fixed-parameter algorithm for k-Vertex Cover. Note that we can have k << |V|."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the brute-force solution to the k-Vertex Cover problem and its issues."}, {"role": "assistant", "content": "Try all $binom{n}{0} + binom{n}{1} + ... + binom{n}{k}$ sets of \u2264 k vertices. Can skip all terms smaller than $binom{n}{k}$ because bigger sets have more coverage. Testing coverage takes O(m) time where m is the number of edges. Therefore, the total runtime is O(Vk|E|). It is polynomial for fixed k but not the same polynomial for all k's. It is inefficient in most cases. Hence we define nf(k) to be bad, where n = |V| + |E| is the input size."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the bounded search-tree algorithm for the k-Vertex Cover problem."}, {"role": "assistant", "content": "The bounded search-tree algorithm works as follows: pick arbitrary edge e = (u, v), we know that either u \u2208 S or v \u2208 S (or both) but don't know which, guess which one: try both possibilities:\n1. add u to S, delete u and incident edges from G, and recurse with k\u2032 = k\u22121.\n2. do the same but with v instead of u\n3. return the OR of the two outcomes"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the recursion tree in the context of the search-tree algorithm."}, {"role": "assistant", "content": "Image Description:  A tree structure is displayed.  The root node is labeled u, v.  This node has two child nodes. The left child node is labeled u', v' and the right child node is labeled u\", v\".  The left child node has two children labeled u' and v' respectively.  The right child node has two children labeled u\" and v\" respectively."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the time complexity of the bounded search-tree algorithm?"}, {"role": "assistant", "content": "At a leaf (k = 0), return YES if |E| = 0 (all edges covered). It takes O(V) time to delete u or v. Therefore this has a total runtime of (2k|V|).  \\begin{itemize}\n    \\item O(V) for fixed k\n    \\item degree of polynomial is independent of k\n    \\item also polynomial for k = O(lg|V|)\n    \\item practical for e.g. k \u2264 32\n    \\item Hence we define $f(k) n^{O(1)}$ to be good\n\\end{itemize}"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is Fixed Parameter Tractability?"}, {"role": "assistant", "content": "A parameterized problem is fixed-parameter tractable (FPT) if there is an algorithm with running time \u2264 f(k) \u00b7 no(1), such that f : N \u2192 N (non negative) and k is the parameter, and the O(1) degree of the polynomial is independent of k and n."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Why is f(k) * n^O(1) preferred over f(k) + n^O(1) in the context of FPT?"}, {"role": "assistant", "content": "Question: Why f(k) \u00b7 no(1) and not f(k) + no(1)?\nTheorem: \u2203f(k)\u00b7nalgorithm \u2203f\u2032(k) + nc\nProof:\n(\u2190)\nTrivial (assuming f'(k) and n' are \u2265 1)\n(\u21d2)\nif n \u2264 f(k), then f(k) \u00b7 n\u00ba \u2264 f(k)c+1"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is Kernelization?"}, {"role": "assistant", "content": "Kernelization is a simplifying self-reduction. It is a polynomial time algorithm that converts an input (x, k) into a small and equivalent input (x', k'). Here, small means |x'| \u2264 f(k) and equivalent means the answer to x is the same as the answer to x'."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the relationship between Kernelization and FPT?"}, {"role": "assistant", "content": "Theorem: a problem is FPT \u21d4 a kernelization\nProof:\n(\u2190)\nKernelize \u21d2 n' \u2264 f(k)\nRun any finite g(n') algorithm\nTotals to no(1) + g(f(k)) time\n(\u21d2)\nlet A be an f(k) \u00b7 n\u00ba algorithm, then assuming k is known:\nif n \u2264 f(k), it's already kernelized.\nif f(k) \u2264 n, then\n1. run A \u2192 f(k) \u00b7 n\u00ba \u2264 nc+1 time\n2. output O(1)-sized YES/NO instance as appropriate (to kernelize)\nif k is unknown: run A for nc+1 time and if it is still not done, we know it is already kernelized."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe how to create a polynomial kernel for k-Vertex Cover."}, {"role": "assistant", "content": "To create a kernel for k-Vertex Cover, the algorithm follows the following steps:\n\u2022 Make graph simple by removing all self loops and multi-edges\n\u2022 Any vertex of degree > k must be in the cover (else would need to add > k vertices to cover incident edges)\n\u2022 Remove such vertices (and incident edges) one at a time, decreasing k accordingly\n\u2022 Remaining graph has maximum degree \u2264 k\n\u2022 Each remaining vertex covers \u2264 k edges\n\u2022 If the number of remaining edges is > k, answer NO and output canonical NO instance.\n\u2022 Else, |E'| \u2264 k\u00b2\n\u2022 Remove all isolated vertices (degree 0 vertices)\n\u2022 Now |V'| \u2264 2k2\n\u2022 The input has been reduced to instance (V', E') of size O(k\u00b2)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the runtime of the kernelization algorithm for k-Vertex Cover?"}, {"role": "assistant", "content": "The runtime of the kernelization algorithm is naively O(VE). (O(V + E) with more work.) After this, we can apply either a brute-force algorithm on the kernel, which yields an overall runtime O(V + E + (2k\u00b2)*k\u00b2) = O(V + E + 2kk2k+2). Or we can apply a bounded search-tree solution, which yields a runtime of O(V + E + 2k*k\u00b2)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the best algorithm to date for k-Vertex Cover?"}, {"role": "assistant", "content": "The best algorithm to date: O(kV + 1.274k) by [Chen, Kanj, Xia - TCS 2010]."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How does the Connection to Approximation Algorithms relate to parameterized complexity?"}, {"role": "assistant", "content": "Take an optimization problem, integral OPT and consider its associated decision problem: \u201cOPT \u2264 k ?\u201d and parameterize by k.\nTheorem: optimization problem has EPTAS\n(EPTAS: efficient PTAS, f(1) \u00b7 no(1) e.g. Approxpartition[L17])\n\u21d2 decision problem is FPT\nProof: (like FPTAS, pseudopolynomial algorithm)\n\u2022 Say maximization problem (and \u2264 k decision)\n\u2022 run EPTAS with e = 1/(2k) in f(2k) \u00b7 n\u00ba(1) time.\n\u2022 relative error \u2264 k/(2k) = 1/2\n\u2022 \u21d2 absolute error < 1 if OPT \u2264 k\n\u2022 So if we find a solution with value < k, then OPT \u2264 (1+1/2)\u00b7 k \u2264 k + 1/2\nIntegral \u21d2 OPT < k \u21d2 YES\n\u2022 else OPT > k\nAlso: =, <, > decision problems are equivalent with respect to FPT."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are some algorithms used to solve the all-pairs shortest paths problem?"}, {"role": "assistant", "content": "Dynamic programming, Matrix multiplication, Floyd-Warshall algorithm, Johnson's algorithm, and Difference constraints."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the single-source shortest paths problem?"}, {"role": "assistant", "content": "Given a directed graph G = (V, E), a vertex s \u2208 V, and edge weights w : E \u2192 R, find d(s, v), which equals the shortest-path weight s \u2192 v, \u2200v \u2208 V (or -\u221e if there is a negative-weight cycle along the way, or \u221e if no path)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the algorithms for single-source shortest paths based on the graph situation?"}, {"role": "assistant", "content": "If the graph is unweighted (w = 1), use BFS with a time complexity of O(V + E). If the graph has non-negative edge weights, use Dijkstra with a time complexity of O(E + V lg V). For a general graph, use Bellman-Ford with a time complexity of O(VE). For an acyclic graph (DAG), use Topological sort + one pass of B-F with a time complexity of O(V + E).  We achieve a O(E + V lg V) bound on Dijkstra's algorithm using Fibonacci heaps."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the all-pairs shortest paths problem?"}, {"role": "assistant", "content": "Given an edge-weighted graph G = (V, E, w), find \u03b4(u, v) for all u, v \u2208 V."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the time complexity for solving APSP problems by running a single-source shortest path algorithm from each of the V vertices in the graph for an unweighted graph?"}, {"role": "assistant", "content": "|V| x BFS and the time complexity is O(VE) , E = \u0398(V\u00b2), which is O(V\u00b3)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the time complexity for solving APSP problems by running a single-source shortest path algorithm from each of the V vertices in the graph for a non-negative edge weights graph?"}, {"role": "assistant", "content": "|V| x Dijkstra and the time complexity is O(VE + V\u00b2 lg V), E = \u0398(V\u00b2), which is O(V\u00b3)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the time complexity for solving APSP problems by running a single-source shortest path algorithm from each of the V vertices in the graph for a general graph?"}, {"role": "assistant", "content": "|V| x Bellman-Ford and the time complexity is O(V\u00b2E) , E = \u0398(V\u00b2), which is O(V\u2074) or  Johnson's and the time complexity is O(VE + V\u00b2 lg V), E = \u0398(V\u00b2), which is O(V\u00b3)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the dynamic programming approach for solving APSP?"}, {"role": "assistant", "content": "Sub-problems: d(m) = weight of shortest path u \u2192 v using \u2264 m edges. Guessing: What's the last edge (x, v)?\nRecurrence: \nd(m) = min(d(m-1) + w(x, v) for x \u2208 V)\n0 if u = v\nd(0) =  otherwise\nTopological ordering: for m = 0,1,2, . . ., n \u2212 1: for u and v in V.  If graph contains no negative-weight cycles (by Bellman-Ford analysis), then shortest path is simple \u21d2 \u03b4(u, v) = d(n-1) = d(n)\nIn this Dynamic Program, we have O(V3) total sub-problems. Each sub-problem takes O(V) time to solve, since we need to consider V possible choices. This gives a total runtime complexity of O(V4)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How to perform bottom-up via relaxation steps?"}, {"role": "assistant", "content": "1 form = 1 to n by 1\n2 for u in V\n3 for v in V\n4 for x in V\n5 if duv > dux + dxv\n6 duv = dux + dxv\nIn the above pseudocode, we omit superscripts because more relaxation can never hurt."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How can the relaxation step be changed to improve the overall running time?"}, {"role": "assistant", "content": "Note that we can change our relaxation step to d(m) = min(d[m/21+d[m/2] for x \u2208 V). This change would produce an overall running time of O(n\u00b3 lgn) time. (student suggestion)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How to perform Matrix multiplication?"}, {"role": "assistant", "content": "Given n \u00d7 n matrices A and B, compute C = A. B, such that Cij = \u2211k=1 aik.bkj\n\u2022 O(n\u00b3) using standard algorithm\n\u2022 O(n 2.807) using Strassen's algorithm\n\u2022 O(n2.376) using Coppersmith-Winograd algorithm\n\u2022 O(n2.3728) using Vassilevska Williams algorithm"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the connection to shortest paths?"}, {"role": "assistant", "content": "Define \u2299 = min and + = -. Then, C = A \u2299 B produces Cij = mink(aik + bkj). Define D(m) = (d(m)), W = (w(i, j)), V = {1, 2, ..., n}. With the above definitions, we see that D(m) can be expressed as D(m-1) \u2299 W. In other words, D(m) can be expressed as the circle-multiplication of W with itself m times."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How to perform Matrix multiplication algorithm?"}, {"role": "assistant", "content": "n 2 multiplications \u21d2 O(n\u2074) time (stil no better)\n\u2022 Repeated squaring: ((W2)2)2... = W2lg n = Wn-1 = (\u03b4(i, j)) if no negative-weight cycles. Time complexity of this algorithm is now O(n\u00b3 lgn).\nWe can't use Strassen, etc. since our new multiplication and addition operations don't support negation."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is Floyd-Warshall: Dynamic Programming?"}, {"role": "assistant", "content": "(k)\n1. Sub-problems: c) = weight of shortest path u \u2192 v whose intermediate\nvertices \u2208 {1,2,..., k}\n2. Guessing: Does shortest path use vertex k?\n3. Recurrence:\nc(k) = min(c(k-1), c(k-1) + C(k-1))\ncuv              cuk      Ckv\nc(0) = w(u, v)\ncuv\n4. Topological ordering: for k: for u and v in V:\n5. Original problem: \u03b4(u, v) = c(n). Negative weight cycle \u21d2 negative c(n)\nTime complexity\nThis Dynamic Program contains O(V\u00b3) problems as well. However, in this case, it takes only O(1) time to solve each sub-problem, which means that the total runtime of this algorithm is O(V\u00b3)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the algorithm for Bottom up via relaxation?"}, {"role": "assistant", "content": "1 C = (w(u, v))\n2 for k = 1 to n by 1\n3 for u in V\n4 for v in V\n5 if Cuv > Cuk + Ckv\n6 Cuv = Cuk + Ckv\nAs before, we choose to ignore subscripts."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is Johnson's algorithm?"}, {"role": "assistant", "content": "1. Find function h : V \u2192 R such that wh(u, v) = w(u, v) + h(u) \u2013 h(v) \u2265 0 for all\nu, v \u2208 V or determine that a negative-weight cycle exists.\n2. Run Dijkstra's algorithm on (V, E, wh) from every source vertex s \u2208 V \u21d2 get\n\u03b4\u03b7(u, v) for all u, v \u2208 V\n3. Given \u03b4\u03b7(u, v), it is easy to compute \u03b4(u, v)\nClaim. \u03b4(u, v) = \u03b4\u03b7(u, v) \u2013 h(u) + h(v)\nProof. Look at any u \u2192 v path p in the graph G\nSay p is vo \u2192 U1 \u2192 U2 \u2192 \u2026\u2026 \u2192 Uk, where v\u2081 = u and vk = v.\nWh(p) = \u2211Wh(Vi-1, Vi) = \u2211[W(Vi\u22121, Vi) + h(vi\u22121) - h(vi)] = \u2211(Vi-1, Vi) + h(vo) \u2013 h(vk) = w(p) + h(u) \u2013 h(v)\nHence all u \u2192 v paths change in weight by the same offset h(u) \u2013 h(v),\nwhich implies that the shortest path is preserved (but offset).\nWe know that\nwn(u, v) = w(u, v) + h(u) \u2013 h(v) \u2265 0\nThis is equivalent to,\nh(v) \u2013 h(u) \u2264 w(u, v)\nfor all (u, v) \u2208 V. This is called a system of difference constraints.\nTheorem. If (V, E, w) has a negative-weight cycle, then there exists no solution to\nthe above system of difference constraints."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How to proof for Johnson's algorithm?"}, {"role": "assistant", "content": "Say vo \u2192 V1 \u2192 \u2026 \u2192 Uk \u2192 vo is a negative weight cycle.\nLet us assume to the contrary that the system of difference constraints has a\nsolution; let's call it h.\nThis gives us the following system of equations,\nh(v\u2081) - h(vo) \u2264 w(\u03bd\u03bf, \u03c51)\nh(v2) - h(v1) \u2264 w(v1, v2)\n:\nh(vk) \u2013 h(Uk-1) \u2264 W(Uk\u22121, Uk)\nh(vo) - h(vk) \u2264 w(\u03c5\u03ba, \u03c5\u03bf)\nSumming all these equations gives us 0 < w(cycle) < 0 which is obviously not possible. From this, we can conclude that no solution to the above system of difference constraints exists if the graph (V, E, w) has a negative weight cycle.\nTheorem. If (V, E,w) has no negative-weight cycle, then we can find a solution to the difference constraints.\nAdd a new vertex s to G, and add edges (s, v) of weight 0 for all v \u2208 V.\nClearly, these new edges do not introduce any new negative weight cycles to the graph\nAdding these new edges ensures that there now exists at least one path from s\nto v. This implies that d(s, v) is finite for all v \u2208 V\nWe now claim that h(v) = d(s, v). This is obvious from the triangle inequality:\n\u03b4(s, u) + w(u, v) \u2265 \u03b4(s, v) \u21d4 \u03b4(s, v) \u2013 \u03b4(s, u) \u2264 w(u, v) \u21d4 h(v) \u2013 h(u) \u2264 w(u, v)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the time complexity for Johnson's algorithm?"}, {"role": "assistant", "content": "1. The first step involves running Bellman-Ford from s, which takes O(VE) time.\nWe also pay a pre-processing cost to reweight all the edges (O(E))\n2. We then run Dijkstra's algorithm from each of the V vertices in the graph; the\ntotal time complexity of this step is O(VE + V2 lg V)\n3. We then need to reweight the shortest paths for each pair; this takes O(V2) time.\nThe total running time of this algorithm is O(VE + V\u00b2 lg V)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the Applications for Bellman-Ford algorithm?"}, {"role": "assistant", "content": "Bellman-Ford consult any system of difference constraints (or report that it is un-solvable) in O(VE) time where V = variables and E = constraints. An exercise is to prove the Bellman-Ford minimizes maxi Xi mini Xi.\nThis has applications to:\nReal-time programming\nMultimedia scheduling\nTemporal reasoning\nFor example, you can bound the duration of an event via difference constraint LB < tend - tstart < UB, or bound a gap between events via 0 < tstart2 - tend1 \u2264 \u03b5, or synchronize events via |tstart1 - tstart2| \u2264 \u025b or 0."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How can a polynomial \\(A(x)\\) be written?"}, {"role": "assistant", "content": "A polynomial \\(A(x)\\) can be written as:\n\n\\(A(x) = a_0 + a_1x + a_2x^2 + \\cdots + a_{n-1}x^{n-1} = \\sum_{k=0}^{n-1} a_kx^k = (a_0, a_1, a_2, \\ldots, a_{n-1})\\) (coefficient vector)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the three primary operations for polynomials?"}, {"role": "assistant", "content": "The three primary operations for polynomials are evaluation, addition, and multiplication."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain the evaluation of polynomials."}, {"role": "assistant", "content": "Given a polynomial \\(A(x)\\) and a number \\(x_0\\), compute \\(A(x_0)\\). This can be done in \\(O(n)\\) time using \\(O(n)\\) arithmetic operations via Horner's rule: \\(A(x) = a_0 + x(a_1 + x(a_2 + \\cdots x(a_{n-1})\\cdots))\\). \\(O(n)\\) multiplications and \\(O(n)\\) additions are required."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain the addition of polynomials."}, {"role": "assistant", "content": "Given two polynomials \\(A(x)\\) and \\(B(x)\\), compute \\(C(x) = A(x) + B(x)\\). This takes \\(O(n)\\) time using basic arithmetic, because \\(c_k = a_k + b_k\\)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain the multiplication of polynomials."}, {"role": "assistant", "content": "Given two polynomials \\(A(x)\\) and \\(B(x)\\), compute \\(C(x) = A(x) \\cdot B(x)\\). Then \\(c_k = \\sum_{j=0}^{k} a_j b_{k-j}\\) for \\(0 \\leq k \\leq 2(n-1)\\), because the degree of the resulting polynomial is twice that of \\(A\\) or \\(B\\). The convolution is the inner product of all relative shifts, an operation also useful for smoothing etc. in digital signal processing.\nNaive polynomial multiplication takes \\(O(n^2)\\).\n\\(O(n^{1.83})\\) or even \\(O(n^{1+\\epsilon})\\) (for \\(\\epsilon > 0\\)) is possible via Strassen-like divide-and-conquer tricks.\nToday, we will compute the product in \\(O(n \\lg n)\\) time via Fast Fourier Transform!"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the 3 main representations of polynomials to consider?"}, {"role": "assistant", "content": "The 3 main representations of polynomials to consider are:\n1. Coefficient vector with a monomial basis\n2. Roots and a scale term\n3. Samples"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain the 'Roots and a scale term' representation of polynomial."}, {"role": "assistant", "content": "A(x) = (x - r_0) \\cdot (x - r_1) \\cdot \\ldots \\cdot (x - r_{n-1}) \\cdot c\nIt is impossible to find exact roots with only basic arithmetic operations and kth root operations. Furthermore, addition is extremely hard with this representation, or even impossible. Multiplication simply requires roots to be concatenated, and evaluation can be completed in O(n)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain the 'Samples' representation of polynomial."}, {"role": "assistant", "content": "Samples: (x_0, y_0), (x_1, y_1), \\ldots, (x_{n-1}, y_{n-1}) with \\(A(x_i) = y_i\\) (\\(\\forall i\\)) and each \\(x_i\\) is distinct. These samples uniquely determine a degree \\(n - 1\\) polynomial \\(A\\), according to the Lagrange and Fundamental Theorem of Algebra. Addition and multiplication can be computed by adding and multiplying the \\(y_i\\) terms, assuming that the \\(x_i\\)'s match. However, evaluation requires interpolation."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How to convert between coefficients and samples in O(nlgn) time?"}, {"role": "assistant", "content": "Consider the polynomial in matrix form:\n\n\\[\n\\begin{bmatrix}\n1 & x_0 & x_0^2 & \\cdots & x_0^{n-1} \\\\\n1 & x_1 & x_1^2 & \\cdots & x_1^{n-1} \\\\\n1 & x_2 & x_2^2 & \\cdots & x_2^{n-1} \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n1 & x_{n-1} & x_{n-1}^2 & \\cdots & x_{n-1}^{n-1}\n\\end{bmatrix}\n\\begin{bmatrix}\na_0 \\\\\na_1 \\\\\na_2 \\\\\n\\vdots \\\\\na_{n-1}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\ny_0 \\\\\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_{n-1}\n\\end{bmatrix}\n\\]\n\nwhere V is the Vandermonde matrix with entries \\(v_{jk} = x_k^j\\).\nThen we can convert between coefficients and samples using the matrix vector product \\(V \\cdot A\\), which is equivalent to evaluation. This takes \\(O(n^2)\\).\nSimilarly, we can samples to coefficients by solving \\(V\\backslash Y\\) (in MATLAB\u00ae notation). This takes \\(O(n^3)\\) via Gaussian elimination, or \\(O(n^2)\\) to compute \\(A = V^{-1} \\cdot Y\\), if \\(V^{-1}\\) is precomputed."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How can polynomial multiplication be formulated as a divide and conquer algorithm?"}, {"role": "assistant", "content": "Polynomial multiplication can be formulated as a divide and conquer algorithm with the following steps for a polynomial \\(A(x)\\) \\(\\forall x \\in X\\):\n\n1. Divide the polynomial \\(A\\) into its even and odd coefficients:\n\\(A_{even}(x) = \\sum_{k=0}^{\\lfloor \\frac{n}{2} - 1 \\rfloor} a_{2k}x^k = (a_0, a_2, a_4, \\ldots)\\)\n\\(A_{odd}(x) = \\sum_{k=0}^{\\lfloor \\frac{n}{2} - 1 \\rfloor} a_{2k+1}x^k = (a_1, a_3, a_5, \\ldots)\\)\n\n2. Recursively conquer \\(A_{even}(y)\\) for \\(y \\in X^2\\) and \\(A_{odd}(y)\\) for \\(y \\in X^2\\), where \\(X^2 = \\{ x^2 \\mid x \\in X \\}\\).\n\n3. Combine the terms: \\(A(x) = A_{even}(x^2) + x \\cdot A_{odd}(x^2)\\) for \\(x \\in X\\)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the set that can be constructed via square roots."}, {"role": "assistant", "content": "Collapsing sets can be constructed via square roots. Each of the following collapsing sets is computing by taking all square roots of the previous set.\n1. \\(\\{1\\}\\)\n2. \\(\\{1,-1\\}\\)\n3. \\(\\{1, -1, i, -i\\}\\)\n4. \\(\\{1, -1, \\pm \\frac{\\sqrt{2}}{2}(1 + i), \\pm \\frac{\\sqrt{2}}{2}(-1 + i)\\} \\), which lie on a unit circle"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are nth roots of unity?"}, {"role": "assistant", "content": "The nth roots of unity are n x's such that \\(x^n = 1\\). These points are uniformly spaced around the unit circle in the complex plane (including 1). These points are of the form \\((\\cos \\theta, \\sin \\theta) = \\cos \\theta + i \\sin \\theta = e^{i\\theta}\\) by Euler's Formula, for \\(\\theta = 0, \\frac{\\tau}{n}, \\frac{2\\tau}{n}, \\ldots, \\frac{n-1}{n}\\tau\\) (where \\(\\tau = 2\\pi\\)).\nThe nth roots of unity where \\(n = 2^p\\) form a collapsing set, because \\((e^{i\\theta})^2 = e^{i(2\\theta)} = e^{i(2\\theta \\mod \\tau)}\\). Therefore the even nth roots of unity are equivalent to the \\(\\frac{n}{2}\\)nd roots of unity."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain Discrete Fourier Transform (DFT)."}, {"role": "assistant", "content": "The DFT allows the transformation between coefficients and samples, computing \\(A^* = V \\cdot A\\) for \\(x_k = e^{i\\tau k/n}\\) where \\(n = 2^p\\), where \\(A\\) is the set of coefficients and \\(A^*\\) is the resulting samples. The individual terms \\(a_k^* = \\sum_{j=0}^{n-1} e^{i\\tau jk/n} \\cdot a_j\\)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain Fast Fourier Transform (FFT)."}, {"role": "assistant", "content": "The FFT algorithm is an \\(O(n \\lg n)\\) divide and conquer algorithm for DFT, used by Gauss circa 1805, and popularized by Cooley and Turkey and 1965. Gauss used the algorithm to determine periodic asteroid orbits, while Cooley and Turkey used it to detect Soviet nuclear tests from offshore readings.\nA practical implementation of FFT is FFTW, which was described by Frigo and Johnson at MIT. The algorithm is often implemented directly in hardware, for fixed \\(n\\)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain Inverse Discrete Fourier Transform."}, {"role": "assistant", "content": "The Inverse Discrete Fourier Transform is an algorithm to return the coefficients of a polynomial from the multiplied samples. The transformation is of the form \\(A^* \\rightarrow V^{-1} \\cdot A^* = A\\). In order to compute this, we need to find \\(V^{-1}\\), which in fact has a very nice structure.\n\nClaim 1. \\(V^{-1} = \\frac{1}{n} \\overline{V}\\), where \\(\\overline{V}\\) is the complex conjugate of \\(V\\)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe Fast Polynomial Multiplication."}, {"role": "assistant", "content": "In order to compute the product of two polynomials \\(A\\) and \\(B\\), we can perform the following steps:\n\n1. Compute \\(A^* = FFT(A)\\) and \\(B^* = FFT(B)\\), which converts both \\(A\\) and \\(B\\) from coefficient vectors to a sample representation.\n2. Compute \\(C^* = A^* \\cdot B^*\\) in sample representation in linear time by calculating \\(C_k^* = A_k^* \\cdot B_k^*\\) (\\(\\forall k\\)).\n3. Compute \\(C = IFFT(C^*)\\), which is a vector representation of our final solution."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe applications of FFT."}, {"role": "assistant", "content": "Fourier (frequency) space many applications. The polynomial \\(A^* = FFT(A)\\) is complex, and the amplitude \\(|a_k^*|\\) represents the amplitude of the frequency-k signal, while \\(\\arg(a_k^*)\\) (the angle of the 2D vector) represents the phase shift of that signal. For example, this perspective is particularly useful for audio processing, as used by Adobe Audition, Audacity, etc.:\n\n*   High-pass filters zero out high frequencies\n*   Low-pass filters zero out low frequencies\n*   Pitch shifts shift the frequency vector\n*   Used in MP3 compression, etc."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the topics covered in Lecture 4?"}, {"role": "assistant", "content": "Series of Improved Data Structures, Insert, Successor, Delete, and Space"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the goal for maintaining n elements in the range {0, 1, 2, ..., u \u2013 1}?"}, {"role": "assistant", "content": "To perform Insert, Delete and Successor operations in O(log log u) time."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the time operation if n = n^(o(1)) or n = (logn)^(0(1))?"}, {"role": "assistant", "content": "O(log log n)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Where might the O(log log u) bound arise?"}, {"role": "assistant", "content": "Binary search over O(log u) elements. Recurrences: T(log u) = T(log u / 2) + O(1), T(u) = T(\u221au) + O(1)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How can we improve performance when splitting the universe into clusters?"}, {"role": "assistant", "content": "By splitting up the range {0, 1, 2, ..., u \u2013 1} into \u221au clusters of size \u221au. If x = i\u221au + j, then V[x] = V.Cluster[i][j]. The formulas are: low(x) = x mod \u221au = j, high(x) = floor(x / \u221au) = i, index(i, j) = i\u221au + j"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How to Insert a number to van Ende Boas Tree and what is the time complexity for the Insert operation?"}, {"role": "assistant", "content": "Set V.cluster[high(x)][low(x)] = 1, the time complexity is O(1)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How to Mark cluster high(x) as non-empty and what is the time complexity for the operation?"}, {"role": "assistant", "content": "Mark cluster high(x) as non-empty with O(1) time complexity."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the steps and time complexity for the Successor operation?"}, {"role": "assistant", "content": "Look within cluster high(x) with complexity O(\u221au). Else, find next non-empty cluster i with O(\u221au). Find minimum entry j in that cluster with O(\u221au). Return index(i, j). Total time complexity: O(\u221au)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the algorithm INSERT(V, x)."}, {"role": "assistant", "content": "1 Insert(V.cluster[high(x)], low[x]). 2 Insert(V.summary, high(x))."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the recurrence relation for the operations of Successor calls to vectors of size \u221au in van Emde Boas Tree?"}, {"role": "assistant", "content": "T(u) = 2T(\u221au) + O(1); T'(log u) = 2T'(log u / 2) + O(1) => T(u) = T'(log u) = O(log u)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the algorithm SUCCESSOR (V,x)."}, {"role": "assistant", "content": "1 i = high(x). 2 j = Successor(V.cluster[i], j). 3 if j = = \u221e, 4 i = Successor(V.summary, i). 5 j = Successor(V.cluster[i], -\u221e). 6 return index(i, j)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How to obtain the O(log log u) running time for van Emde Boas Tree operations?"}, {"role": "assistant", "content": "We need to reduce the number of recursions to one."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the modification for the time overhead of the Insert operation?"}, {"role": "assistant", "content": "We store the minimum and maximum entry in each structure. This gives an O(1) time overhead for each Insert operation."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the algorithm SUCCESSOR (V,x) for van Emde Boas Tree with min and max stored for each structure."}, {"role": "assistant", "content": "1 i = high(x). 2 if low(x) < V.cluster[i].max, 3 j = Successor(V.cluster[i], low(x)). 4 else i = Successor(V.summary, high(x)). 5 j = V.cluster[i].min. 6 return index(i, j)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Recurrence relation for van Emde Boas Tree with min and max stored for each structure?"}, {"role": "assistant", "content": "T(u) = T(\u221au) + O(1) => T(u) = O(log log u)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the purpose of not storing Min recursively in van Emde Boas Tree?"}, {"role": "assistant", "content": "The Successor call now needs to check for the min separately.  if x < V.min : return V.min"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the algorithm INSERT(V, x) for van Emde Boas Tree?"}, {"role": "assistant", "content": "1 if V.min == None, 2 V.min = V.max = x \u25b7 O(1) time, 3 return, 4 if x < V.min, 5 swap(x <-> V.min), 6 if x > V.max, 7 V.max = x), 8 if V.cluster[high(x) == None, 9 Insert(V.summary, high(x)) \u25b7 First Call, 10 Insert(V.cluster.high(x)], low(x)) \u25b7 Second Call"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the time complexity of INSERT(V, x) for van Emde Boas Tree?"}, {"role": "assistant", "content": "T(u) = T(\u221au) + O(1) => T(u) = O(log log u)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the algorithm DELETE(V, x) for van Emde Boas Tree?"}, {"role": "assistant", "content": "1 if x == V.min \u25b7 Find new min, 2 i = V.summary.min, 3 if i = None, 4 V.min = V.max = None \u25b7 O(1) time, 5 return, 6 V.min = index(i, V.cluster[i].min) \u25b7 Unstore new min, 7 Delete(V.cluster[high(x)], low(x)) \u25b7 First Call, 8 if V.cluster[high(x)].min == None, 9 Delete(V.summary, high(x)) \u25b7 Second Call, 10 \u25b7 Now we update V.max, 11 if x == V.max, 12 if V.summary.max = None, 13 else, 14 i = V.summary.max, 15 V.max = index(i, V.cluster[i].max)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the time complexity of DELETE(V, x) for van Emde Boas Tree?"}, {"role": "assistant", "content": "T(u) = T(\u221au) + O(1) => T(u) = O(log log u)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the lower bound for static queries in van Emde Boas Tree?"}, {"role": "assistant", "content": "\u03a9(log logu) time per query for u = n^(log n)^(o(1)). O(n poly(log n)) space"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How can we improve the space complexity of van Emde Boas Tree?"}, {"role": "assistant", "content": "We can improve from \u0398(u) to O(n log log u). Only create nonempty clusters If V.min becomes None, deallocate V. Store V.cluster as a hashtable of nonempty clusters. Each insert may create a new structure O(log log u) times (each empty insert)Can actually happen [Vladimir \u010cun\u00e1t]. Charge pointer to structure (and associated hash table entry) to the structure. This gives us O(n log log u) space (but randomized)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How can we further reduce the space to O(n) in van Emde Boas Tree?"}, {"role": "assistant", "content": "Store vEB structure with n = O(log log u) using BST or even an array => O(log log n) time once in base case. We use O(n/ log log u) such structures (disjoint) => O(log logn * log logu) = O(n) space for small. Larger structures \u201cstore\u201d pointers to them => O(log logn * log logu) = O(n) space for large. Details: Split/Merge small structures"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What topics will be covered in Lecture 12?"}, {"role": "assistant", "content": "Greedy Algorithms and Minimum Spanning Tree, including Optimal Substructure, Greedy Choice Property, Prim's algorithm and Kruskal's algorithm."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is a greedy algorithm?"}, {"role": "assistant", "content": "A greedy algorithm repeatedly makes a locally best choice or decision, but ignores the effects of the future."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Define a tree and a spanning tree."}, {"role": "assistant", "content": "A tree is a connected, acyclic graph. A spanning tree of a graph G is a subset of the edges of G that form a tree and include all vertices of G."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the Minimum Spanning Tree problem?"}, {"role": "assistant", "content": "Given an undirected graph G = (V, E) and edge weights W : E \u2192 R, find a spanning tree T of minimum weight \u03a3e\u2208T w(e)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe a naive algorithm for MST and its drawback."}, {"role": "assistant", "content": "The obvious MST algorithm is to compute the weight of every tree, and return the tree of minimum weight. Unfortunately, this can take exponential time in the worst case. In the worst case, there can be an exponential number of spanning trees."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the two main properties of problems that can be solved by greedy algorithms?"}, {"role": "assistant", "content": "Optimal Substructure: the optimal solution to a problem incorporates the optimal solution to subproblem(s). Greedy choice property: locally optimal choices lead to a globally optimal solution."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "State Lemma 1 regarding optimal substructure for MST."}, {"role": "assistant", "content": "If T' is a minimum spanning tree of G/e, then T' \u222a {e} is an MST of G."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "State Lemma 2 (Greedy-Choice Property for MST)."}, {"role": "assistant", "content": "For any cut (S, V \\ S) in a graph G = (V, E, w), any least-weight crossing edge e = {u, v} with u \u2208 S and v \u2209 S is in some MST of G."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is Prim's Algorithm Psuedocode?"}, {"role": "assistant", "content": "1 Maintain priority queue Q on V \\ S, where v.key = min{w(u, v) | u \u2208 S}\n2 Q=V\n3 Choose arbitrary start vertex s \u2208 V, s.key = \u00d8\n4 for v in V \\{s}\n5  v.key = \u221e\n6 while Q is not empty\n7  u = Extract-Min(Q), add u to S\n8  for v \u2208 Adj[u]\n9   if v \u2208 Q and v \u2209 S and w(u, v) < v.key:\n10    v.key = w(u, v) (via a Decrease-Key operation)\n11    v.parent = u\n12 return {{v, v.parent} | v \u2208 V \\ {s}}"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the invariants used to prove the correctness of Prim's Algorithm?"}, {"role": "assistant", "content": "1. v \u00a2 S = v.key = min{w(u, v) | u \u2208 S}\n2. Tree Ts within SC MST of G."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the runtime of Prim's algorithm?"}, {"role": "assistant", "content": "O(V)\u00b7TExtract-Min + O(E) \u00b7TDecrease-Key"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is Kruskal's Algorithm?"}, {"role": "assistant", "content": "Kruskal's Algorithm is another algorithm to solve the MST problem. It constructs an MST by taking the globally lowest-weight edge and contracting it."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is Kruskal's Algorithm Pseudocode?"}, {"role": "assistant", "content": "1 Maintain connected components that have been added to the\nMST so far T, in a Union-Find structure\n2 Initialize T = 0\n3 for v in V\n4  Make-Set(v)\n5 Sort E by weight\n6 For e = (u, v) \u2208 E (in increasing-weight order):\n7  if Find-Set(u) \u2260 Find-Set(v):\n8   Add e to T\n9   Union(u, v)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the claim used to prove the correctness of Kruskal's Algorithm?"}, {"role": "assistant", "content": "The tree-so-far T \u2286 MST T*."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the runtime of Kruskal's algorithm?"}, {"role": "assistant", "content": "Tsort(E) + O(V) \u00b7 TMake-Set + O(E)(TFind + TUnion) = O(Elg E + Ea(V))"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the fastest MST algorithm and its expected runtime."}, {"role": "assistant", "content": "Currently, the fastest MST algorithm is a randomized algorithm with an expected runtime of O(V + E). The algorithm was proposed by Karger, Klein, and Tarjan in 1993."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What topics are covered in Lecture 22: Cryptography: Encryption?"}, {"role": "assistant", "content": "The lecture covers: Symmetric key encryption, Key exchange, Asymmetric key encryption, RSA, NP-complete problems and cryptography (graph coloring, knapsack)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain symmetric key encryption with equations."}, {"role": "assistant", "content": "Symmetric key encryption involves the following equations: \\(c = e_k(m)\\) and \\(m = d_k(c)\\), where \\(c\\) is the ciphertext, \\(m\\) is the plaintext, \\(e\\) is the encryption function, \\(d\\) is the decryption function, and \\(k\\) is the secret key. \\(e\\) and \\(d\\) permute and reverse-permute the space of all messages. Reversible operations include \u2295, +/-, and shift left/right. Examples of symmetric algorithms are AES, RC5, and DES."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the key management question and its solution."}, {"role": "assistant", "content": "The key management question is: How does the secret key \\(k\\) get exchanged/shared? Alice wants to send a message to Bob, but there are pirates who will take any keys or messages in unlocked boxes but won't touch locked boxes. The solution is: Alice puts message \\(m\\) in a box, locks it with key \\(k_a\\), and sends the box to Bob. Bob locks the box with key \\(k_b\\), and sends it to Alice. Alice unlocks the box with \\(k_a\\), and sends it to Bob. Bob unlocks the box with \\(k_b\\), and reads \\(m\\). This relies on the commutativity of the locks."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain the Diffie-Hellman Key Exchange."}, {"role": "assistant", "content": "In Diffie-Hellman Key Exchange, \\(G = F_p^*\\), where \\(F_p\\) is a finite field (mod \\(p\\), a prime), and \\(*\\) means invertible elements only (\\({1, 2, ..., p - 1}\\)). Alice selects a and computes \\(g^a\\), while Bob selects b and computes \\(g^b\\). Alice can compute \\((g^b)^a \\mod p = k\\), and Bob can compute \\((g^a)^b \\mod p = k\\). This assumes the Discrete Log Problem is hard (given \\(g^a\\), compute a) and the Diffie-Hellman Problem is hard (given \\(g^a, g^b\\), compute \\(g^{ab}\\)). A potential attack is the Man-in-the-middle attack, where Alice and Bob unknowingly communicate with Eve instead."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe public key encryption."}, {"role": "assistant", "content": "Public key encryption involves: message + public key = ciphertext; ciphertext + private key = message. The two keys need to be linked in a mathematical way, and knowing the public key should not reveal the private key."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain the RSA encryption process."}, {"role": "assistant", "content": "In RSA: Alice picks two large secret primes \\(p\\) and \\(q\\). Alice computes \\(N = p \\cdot q\\). Alice chooses an encryption exponent \\(e\\) such that \\(\\gcd(e, (p - 1)(q - 1)) = 1\\), with examples of \\(e = 3, 17, 65537\\). Alice's public key is \\((N, e)\\). The decryption exponent \\(d\\) is obtained using the Extended Euclidean Algorithm by Alice such that \\(ed = 1 \\mod (p - 1)(q - 1)\\). Alice's private key is \\((d, p, q)\\). Encryption: \\(c = m^e \\mod N\\). Decryption: \\(m = c^d \\mod N\\)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain the hardness of RSA."}, {"role": "assistant", "content": "The hardness of RSA relies on: Factoring, where given \\(N\\), it is hard to factor into \\(p\\) and \\(q\\). Also, the RSA Problem states that given \\(e\\) such that \\(\\gcd(e, (p - 1)(q - 1)) = 1\\) and \\(c\\), it's hard to find \\(m\\) such that \\(m^e = c \\mod N\\)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is NP-completeness?"}, {"role": "assistant", "content": "NP-completeness covers problems like determining if \\(N\\) is composite with a factor within a range, if a graph is \\(k\\)-colorable, and given a pile of \\(n\\) items with different weights \\(w_i\\), if it is possible to put items in a knapsack such that we get a specific total weight \\(S\\). These problems are NP-complete."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain NP-completeness and Cryptography."}, {"role": "assistant", "content": "NP-completeness is about worst-case complexity, while cryptography wants a problem instance, with suitably chosen parameters that is hard on average. Most knapsack cryptosystems have failed. Determining if a graph is 3-colorable is NP-complete but easy on average because an average graph, beyond a certain size, is not 3-colorable. A standard backtracking search involves ordering vertices, traversing the graph, and on visiting a vertex, choosing the smallest possible color that works."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the Knapsack Cryptography."}, {"role": "assistant", "content": "General knapsack problem: NP-complete. Super-increasing knapsack: linear time solvable, where \\(w_j \\geq \\sum_{i=1}^{j-1} w_i\\).  Merkle Hellman Cryptosystem uses a Private transform, transforming private key (super-increasing knapsack problem) to a \"hard\" general knapsack problem, and produces a public key. Transform: two private integers \\(N, M\\) such that \\(\\gcd(N, M) = 1\\). Multiply all values in the sequence by \\(N\\) and then take mod \\(M\\). Example: \\(N = 31, M = 105\\), private key = {2, 3, 6, 14, 27, 52}, public key={62, 93, 81, 88, 102, 37}."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Give an example of Merkle Hellman Cryptosystem."}, {"role": "assistant", "content": "Merkle Hellman Example: Let \\(N = 31, M = 105\\), the private key = {2, 3, 6, 14, 27, 52} and the public key={62, 93, 81, 88, 102, 37}. \nIf Message = 011000, 110101, 101110 then\nCiphertext:011000 = 93+81 = 174\n110101 = 62+93 +88 +37 = 280\n101110 = 62+81+88 + 102 = 333\n= 174, 280, 333\nRecipient knows \\(N = 31, M = 105\\), {2, 3, 6, 14, 27, 52}. Multiplies each ciphertext block by \\(N^{-1} \\mod M\\). In this case, \\(N^{-1} = 61 \\mod 105\\).\n174*61=9 = 3 + 6 = 011000\n280*61=70 = 2 + 3 + 13 + 52 = 110101\n333*61 = 48 = 2 + 6 + 13 + 27 = 101110"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the limitations of Lattice based techniques?"}, {"role": "assistant", "content": "Density of knapsack \\(d = \\frac{n}{\\max{\\log_2 w_i:1 \\leq i \\leq n}}\\). Lattice basis reduction can solve knapsacks of low density. Unfortunately, M-H scheme always produces knapsacks of low density."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What modules does this course cover?"}, {"role": "assistant", "content": "Review: dictionaries, chaining, simple uniform, Universal hashing, Perfect hashing"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is a dictionary problem?"}, {"role": "assistant", "content": "A dictionary is an Abstract Data Type (ADT) that maintains a set of items. Each item has a key. The dictionary supports the following operations: insert(item): add item to set, delete(item): remove item from set, search(key): return item with key if it exists. We assume that items have distinct keys (or that inserting new ones clobbers old ones).\nThis problem is easier than predecessor/successor problems solved in previous lecture (by van Emde Boas trees, or by AVL/2-3 trees/skip lists)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the goal of Hashing from 6.006?"}, {"role": "assistant", "content": "O(1) time per operation and O(n) space complexity."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the definitions of n, m, and m with respect to Hashing from 6.006?"}, {"role": "assistant", "content": "n = number of keys over all possible items,  m = number of keys/items currently in the table, m = number of slots in the table"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Assuming simple uniform hashing, what is the formula and result of the algorithm?"}, {"role": "assistant", "content": "Pr {h(k\u2081) = h(k\u2082)} = 1/m. We achieve (1 + a) time per operation, where a = n/m is called load factor. The downside of the algorithm is that it requires assuming input keys are random, and it only works in average case, like basic quicksort. Today we are going to remove the unreasonable simple uniform hashing assumption."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What does the English 'hash' (1650s) mean?"}, {"role": "assistant", "content": "\"cut into small pieces\", which comes from the French \u2018hacher\u2018which means \u201cchop up\u201d, which comes from the Old French \u2018hache\u2019 which means \u201caxe\u201d (cf. English \u2018hatchet'). Alternatively, perhaps they come from Vulcan 'la'ash', which means \u201caxe\u201d. (R.I.P. Leonard Nimoy.)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the principles of universal hashing?"}, {"role": "assistant", "content": "choose a random hash function h from H, require H to be a universal hashing family such that Pr {h(k) = h(k')} \u2264 1/m for all k\u2260 k'"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "State the theorem concerning universal hashing."}, {"role": "assistant", "content": "For n arbitrary distinct keys and random h\u2208 H, where H is a universal hashing family, E[ number of keys colliding in a slot ] < 1 + \u03b1 where a = n/m"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "State the proof of the theorem."}, {"role": "assistant", "content": "Consider keys k1,k2, ..., kn. Let Ii,j =\n{\n1 if h(k) = h(kj)\n0 otherwise\n}. Then we have\nE[Ii,j] = Pr{Ii,j = 1}\n= Pr{h(ki) = h(kj)}\n< 1/m for any j\u2260 i\nE[# keys hashing to the same slot as ki] = E[\u2211j=1 Ii,j]\n= \u2211j=1E[i,j] (linearity of expectation)\n= \u2211j\u2260iE[i,j] + E[Ii,i]\n<n/m +1"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the properties of all hash functions?"}, {"role": "assistant", "content": "H = {all hash functions h : {0, 1, . . ., u \u2212 1} \u2192 {0, 1, . . ., m - 1}}. Apparently, H is universal, but it is useless. On one hand, storing a single hashing function h takes log(m\u00b2) = ulog(m) bits \u00bb n bits. On the other hand, we would need to precompute u values, which takes \u03a9(u) time."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the assumptions of a dot-product hash family?"}, {"role": "assistant", "content": "m is a prime"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the definition of ha(k)?"}, {"role": "assistant", "content": "ha(k) = \u2211i=0^(r-1) aiki mod m"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain the theorem regarding the Dot-product hash family H"}, {"role": "assistant", "content": "Dot-product hash family His universal."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain the proof of Dot-product hash family H"}, {"role": "assistant", "content": "Take any two keys k \u2260 k'. They must differ in some digits. Say ka \u2260 ka'.\nDefine not d = {0, 1, . . ., r \u2212 1} \\{d}. Now we have\nPr{ha(k) = ha(k')} = Pr[\u2211i=0^(r-1) aiki = \u2211i=0^(r-1)aiki' (mod m)]\n= Pr[\u2211i\u2260d aiki + adka = \u2211i\u2260d aiki' + adka' (mod m)]\n= Pr[\u2211i\u2260d ai(ki - ki') + ad(ka - ka') = 0 (mod m)]\n= Pr[ad = -(ka - ka')^(-1) \u2211i\u2260d ai(ki \u2013 ki') (mod m)]\n(m is prime \u21d2 Zm has multiplicative inverses)\n= E [Pr{ad = f(k, k', anot d)}]"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Define the properties of another universal hash family from CLRS"}, {"role": "assistant", "content": "Choose prime p > u (once). Define hab(k) = [(ak + b) mod p)] mod m. Let H = {hab | a, b \u2208 {0, 1, . . ., u \u2013 1}}."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the Static dictionary problem."}, {"role": "assistant", "content": "Given n keys to store in table, only need to support search(k). No insertion or deletion will happen."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the properties of perfect hashing?"}, {"role": "assistant", "content": "[Fredman, Koml\u00f3s, Szemer\u00e9di 1984], polynomial build time with high probability (w.h.p.), O(1) time for search in worst case, O(n) space in worst case. Idea: 2-level hashing"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain the perfect hashing steps in detail."}, {"role": "assistant", "content": "Step 1: Pick h\u2081 : {0, 1, . . ., u \u2212 1} \u2192 {0,1,..., m - 1} from a universal hash family for m = O(n) (e.g., nearby prime). Hash all items with chaining using h\u2081.\nStep 2: For each slot j\u2208 {0,1, . . ., m \u2212 1}, let lj be the number of items in slot j. lj = |{i | h(ki) = j}|. Pick h2,j : {0, 1, ..., u \u2212 1} \u2192 {0,1,..., m;} from a universal hash family for lj <= m; <= O(13) (e.g., nearby prime). Replace chain in slot j with hashing-with-chaining using h\u2082,j.\nThe space complexity is O(n + \u2211j=0^(m-1)13). In order to reduce it to O(n), we need to add two more steps:\nStep 1.5: If \u2211j=0^(m-1)12 > cn where c is a chose constant, then redo Step 1.\nStep 2.5: While h2,j(ki) = h2,j(k) for any i \u2260 i', j, repick h2,j and rehash those lj.\nThe above two steps guarantee that there are no collisions at second level, and the space complexity is O(n). As a result, search time is O(1). Now let's look at the build time of the algorithm. Both Step 1 and Step 2 are O(n). How about Step 1.5 and Step 2.5?\nFor Step 2.5,\nPr{h2.j(ki) = h2.j(k) for some i \u2260 i'} < \u2211i\u2260i' Pr{h2,j (ki) = h2,j (k)} (union bound)\n< (1/12) *1/2 <=1/2\nAs a result, each trial is like a coin flip. If the outcome is \u201ctail\u201d, we move to the next step. By Lecture 7, we have E[#trials] < 2 and #trials = O(log n) w.h.p. By a Chernoff bound, lj = O(log n) w.h.p., so each trial takes O(logn) time. Because we have to do this for each j, the total time complexity is O(log n) \u00b7 O(log n) \u00b7 O(n) =\nO(nlog\u00b2 n) w.h.p."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain the properties of Step 1.5."}, {"role": "assistant", "content": "For Step 1.5, we define Ii,i' = {\n1 if h(k) = h(k)\n0 otherwise\n}. Then we have\nE[\u2211j=0^(m-1)12] = E[\u2211i=1^(n)\u2211i'=1^(n)Ii,i'] = \u2211i=1^(n)\u2211i'=1^(n)E[Ii,i\u2019]\u2264n+2(n 2) *1/m = O(n) because m = O(n)\nBy Markov inequality, we have\nPr(\u2211j=0^(m-1) 12 > cn) < E[\u2211j=0^(m-1) 12] / cn <1/2\nfor a sufficiently large constant c. By Lecture 7, we have E[#trials] < 2 and #trials =\nO(log n) w.h.p. As a result, Step 1 and Step 1.5 combined takes O(n log n) time w.h.p."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the topics covered in Lecture 10?"}, {"role": "assistant", "content": "Longest palindromic sequence, Optimal binary search tree, and Alternating coin game."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the DP notions?"}, {"role": "assistant", "content": "1. Characterize the structure of an optimal solution. 2. Recursively define the value of an optimal solution based on optimal solutions of subproblems. 3. Compute the value of an optimal solution in bottom-up fashion (recursion & memoization). 4. Construct an optimal solution from the computed information."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the definition of a palindrome, and what is the Longest Palindromic Sequence problem?"}, {"role": "assistant", "content": "Definition: A palindrome is a string that is unchanged when reversed. Examples: radar, civic, t, bb, redder. Given: A string X[1\u2026n], n \u2265 1. To find: Longest palindrome that is a subsequence. Example: Given \u201ccharacter\", output \"carac\". Answer will be \u2265 1 in length."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the strategy and Analysis for Longest Palindromic Sequence?"}, {"role": "assistant", "content": "Strategy: L(i, j): length of longest palindromic subsequence of X[i\u00b7\u00b7\u00b7 j] for i < j. Code: 1 def L(i, j) : 2 if i == j: return 1 3 if X[i] == X[j]: 4 if i + 1 == j: return 2 5 else: return 2 + L(i + 1, j - 1) 6 else: 7 return max(L(i + 1, j), L(i, j - 1)). Analysis: As written, program can run in exponential time: suppose all symbols X[i] are distinct. \\(T(n)\\) = running time on input of length n. \\(T(n) = \\begin{cases} 1 & n=1 \\\\ 2T(n - 1) & n > 1 \\end{cases} = 2^{n-1}\\)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How to reduce time complexity using Subproblems?"}, {"role": "assistant", "content": "But there are only \\(\\binom{n}{2} = \\theta(n^2)\\) distinct subproblems: each is an (i, j) pair with i < j. By solving each subproblem only once. running time reduces to \\(\\theta(n^2) \\cdot \\theta(1) = \\theta(n^2)\\), where 0(n\u00b2) is the number of subproblems and 0(1) is the time to solve each subproblem, given that smaller ones are solved. Memoize L(i, j), hash inputs to get output value, and lookup hash table to see if the subproblem is already solved, else recurse."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is Memoizing Vs. Iterating?"}, {"role": "assistant", "content": "1. Memoizing uses a dictionary for L(i, j) where value of L is looked up by using i, j as a key. Could just use a 2-D array here where null entries signify that the problem has not yet been solved. 2. Can solve subproblems in order of increasing j \u2212 i so smaller ones are solved first."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the Optimal Binary Search Trees problem as defined in CLRS 15.5?"}, {"role": "assistant", "content": "Given: keys \\(K_1, K_2, \\dots, K_n, K_1 < K_2 < \\dots < K_n\\), WLOG \\(K_i = i\\), weights \\(W_1, W_2, \\dots, W_n\\). Find: BST T that minimizes: \\(\\sum_{i=1}^{n} W_i \\cdot (depth_T(K_i) + 1)\\). Example: \\(W_i = p_i = \\)probability of searching for \\(K_i\\). Then, we are minimizing expected search cost. (say we are representing an English \\(\\rightarrow\\) French dictionary and common words should have greater weight)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is Enumeration in terms of optimal binary search trees?"}, {"role": "assistant", "content": "Exponentially many trees. n = 2: 1 2,  2 1. n = 3: 3 2 1, 2 3 1, 2 1 3, 1 3 2, 1 2 3"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the strategy for the optimal binary search tree problem?"}, {"role": "assistant", "content": "\\(W(i, j) = W_i + W_{i+1} + \\cdots + W_j\\), \\(e(i, j) =\\) cost of optimal BST on \\(K_i, K_{i+1}, \\dots, K_j\\). Want \\(e(1, n)\\). Greedy solution? Pick \\(K_i\\) in some greedy fashion, e.g., \\(W_i\\) is maximum. greedy doesn't work, see example at the end of the notes."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the DP strategy for the optimal binary search tree problem?"}, {"role": "assistant", "content": "\\(e(i, j) = \\begin{cases} W_i & \\text{if } i = j \\\\ \\min_{i<r<j} (e(i, r - 1) + e(r + 1, j) + W(i, j)) & \\text{else} \\end{cases}\\) +W(i, j) accounts for \\(W_r\\) of root \\(K_r\\) as well as the increase in depth by 1 of all the other keys in the subtrees of \\(K_r\\) (DP tries all ways of making local choices and takes advantage of overlapping subproblems) Complexity: \\(O(n^2) \\cdot O(n) = O(n^3)\\) where (n\u00b2) is the number of subproblems and 0(n) is the time per subproblem."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the alternating coin game."}, {"role": "assistant", "content": "Row of n coins of values \\(V_1, \\dots, V_n\\), n is even. In each turn, a player selects either the first or last coin from the row, removes it permanently, and receives the value of the coin."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the question and strategy for the alternating coin game?"}, {"role": "assistant", "content": "Question: Can the first player always win? Try: 4 42 39 17 25 6. Strategy: \\(V_1, V_2, ..., V_{n-1}, V_n\\). 1. Compare \\(V_1 + V_3 + \\dots + V_{n-1}\\) against \\(V_2 + V_4 + \\dots + V_n\\) and pick whichever is greater. 2. During the game only pick from the chosen subset (you will always be able to!). How to maximize the amount of money won assuming you move first?"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the Optimal Strategy for the Alternating Coin Game?"}, {"role": "assistant", "content": "\\(V(i, j)\\): max value we can definitely win if it is our turn and only coins \\(V_i, ..., V_j\\) remain. \\(V(i, i)\\): just pick i. \\(V(i, i + 1)\\): pick the maximum of the two. \\(V(i, i + 2), V(i, i + 3), ...\\). \\(V(i, j) = max\\{(range becomes (i + 1, j)) + V_i, (range becomes (i, j - 1)) + V_j\\}\\) Solution: \\(V(i + 1, j)\\) subproblem with opponent picking we are guaranteed \\(min\\{V(i + 1, j - 1), V(i + 2, j)\\} \\)Where V(i+1, j\u22121) corresponds to opponent picking \\(V_j\\) and V(i+2, j) corresponds to opponent picking \\(V_{i+1}\\) We have \\(V(i, j) = max \\{\\min \\{V(i + 1, j - 1), V(i + 2, j)\\} + V_i, \\min \\{V(i, j - 2), V(i + 1, j - 1)\\} + V_j\\}\\) Complexity? \\(\\Theta(n^2) \\cdot \\Theta(1) = \\Theta(n^2)\\)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are Distributed Algorithms?"}, {"role": "assistant", "content": "Algorithms that run on networked processors, or on multiprocessors that share memory. They solve many kinds of problems such as Communication, Data management, Resource management, Synchronization and Reaching consensus. They work in difficult settings where there is Concurrent activity at many processing locations, Uncertainty of timing, order of events, inputs and Failure and recovery of processors, of channels. So they can be complicated and Hard to design, prove correct, and analyze."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are some of the key aspects of Distributed Algorithms?"}, {"role": "assistant", "content": "They have been Studied since 1967, starting with Dijkstra and Lamport. Some source materials include Lynch, Distributed Algorithms, Attiya and Welch, Distributed Computing: Fundamentals, Simulations, and Advanced Topics, Morgan Claypool series of monographs on Distributed Computing Theory. Conferences include Principles of Distributed Computing (PODC) and Distributed Computing (DISC)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How are Distributed Algorithms modeled?"}, {"role": "assistant", "content": "Distributed algorithms are modeled with: Infinite-state interacting state machines. Proofs use invariants, proved by induction. Abstraction relations. New complexity measures which include Time complexity: Rounds, or real time, and Communication complexity: Messages, or bits."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How are Distributed Networks defined?"}, {"role": "assistant", "content": "They are Based on an undirected graph G = (V, E), where n= |V|,  \u0393(u) is the set of neighbors of vertex u and deg(u) = |\u0413(u)| is the number of neighbors of vertex u. Each graph vertex is associated with a process which is an infinite-state automaton (Sometimes refer to processes, or vertices, as nodes). Associate two directed communication channels with each edge. We won't consider failures."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the Synchronous Network Model?"}, {"role": "assistant", "content": "Processes at nodes of an undirected graph, communicate using messages. Each process has output ports, input ports that connect to communication channels. Process at vertex u doesn't know who its ports' channels connect to. They Knows the ports only by local names, such as 1, 2, ..., k, where k = deg(u). Processes need not be distinguishable E.g., they needn't have Unique Identifiers (UIDs). They just know how many ports they have, and their local names."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How does an execution of a Synchronous Network Model work?"}, {"role": "assistant", "content": "An algorithm executes in synchronous rounds. In each round, each process determines, based on its state, the messages to send on all its ports, where There is at most one message per port per round. Each message gets put into its channel, and delivered to the process at the other end. Then each process computes a new state based on its old state and the arriving messages. It generally ignore costs of local computation (time and space) and focus on time (number of rounds), and communication (number of messages or total number of bits)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the Leader Election problem?"}, {"role": "assistant", "content": "Given an arbitrary connected (undirected) graph G = (V, E), the goal is for exactly one process to output a special leader signal. Motivation: Leader can take charge of Communication, Coordinating data processing, Allocating resources, Scheduling tasks and Reaching consensus."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is an impossible case for the Leader Election problem?"}, {"role": "assistant", "content": "Theorem 1: Let G = (V, E) be an n-vertex clique. Then there is no algorithm consisting of deterministic, indistinguishable processes that is guaranteed to elect a leader in G.  Proof: For example, consider n = 2. Two identical, deterministic processes. Show by induction that the processes remain in the same state forever."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is required to solve the Leader Election problem in a Clique Network?"}, {"role": "assistant", "content": "Since the basic problem for distributed algorithms is breaking symmetry, we need something more. We can use Unique Identifiers (UIDs) where each process knows it. Different UIDs can appear anywhere in the graph, but each can appear only once. We can also use Randomness"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How does an algorithm using UIDs work to solve the Leader Election problem?"}, {"role": "assistant", "content": "Theorem 2: Let G = (V, E) be an n-vertex clique. Then there is an algorithm consisting of deterministic processes with UIDs that is guaranteed to elect a leader in G.  The algorithm takes only 1 round and uses only n\u00b2 point-to-point messages. Everyone sends its UID on all its output ports, and collects UIDs received on all its input ports. The process with the maximum UID elects itself the leader."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How does an algorithm using Randomness work to solve the Leader Election problem?"}, {"role": "assistant", "content": "Processes choose IDs randomly, from a sufficiently large set so that it is likely that all are different. Then use them like UIDs. Theorem 4: Let G = (V, E) be an n-vertex clique. Then there is an algorithm consisting of randomized, indistinguishable processes that eventually elects a leader in G, with probability 1. The algorithm takes expected time \u2264 1/(1-\u0454). Processes choose random ids from a sufficiently large space. Exchange ids; if the maximum is unique, the maximum wins. Otherwise repeat, as many times as necessary."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the Maximal Independent Set (MIS) problem?"}, {"role": "assistant", "content": "Given a general undirected graph network, we Select a subset S of the nodes, so that they form a Maximal Independent Set. There can be no two neighbors that are both in the set(independent) and We can't add any more nodes without violating independence(maximal). Every node is either in S or has a neighbor in S."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How are Distributed MIS solved?"}, {"role": "assistant", "content": "We Assume No UIDs and Processes know a good upper bound on n. We Require compute an MIS S of the entire network graph where Each process in S should output in, others output out. It's Unsolvable by deterministic algorithms, in some graphs, so we consider randomized algorithms. Applications of distributed MIS include: Communication networks: Selected processes can take charge of communication, convey information to their neighbor processes and Developmental biology: Distinguish cells in fruit fly's nervous system to become \"Sensory Organ Precursor\" cells [Afek, Alon, et al., Science]."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How does Luby's MIS Algorithm work?"}, {"role": "assistant", "content": "It Executes in 2-round phases. Initially all nodes are active. At each phase, some active nodes decide to be in, others decide to be out, algorithm continues to the next phase with a smaller graph. Repeat until all nodes have decided. Round 1: Choose a random value r in {1,2, ..., n5}, send it to all neighbors. Receive values from all active neighbors. If r is strictly greater than all received values, then join the MIS, output in.  Round 2: If you joined the MIS, announce it in messages to all (active) neighbors. If you receive such an announcement, decide not to join the MIS, output out. If you decided one way or the other at this phase, become inactive."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What properties are satisfied by the final set if Luby's algorithm ever terminates?"}, {"role": "assistant", "content": "If Luby's algorithm ever terminates, then the final set S satisfies the independence and maximality property.  Theorem 5: Each node joins S only if it has the unique maximum value in its neighborhood, at some phase and When it does, all its neighbors become inactive(independence). Theorem 6: A node becomes inactive only if it joins S or a neighbor joins S. We continue until all nodes are inactive(maximality)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the nature of Termination in Luby's MIS algorithm?"}, {"role": "assistant", "content": "With probability 1, Luby's MIS algorithm eventually terminates. Theorem 7: With probability at least 1 - 1/n, all nodes decide within 4 log n phases."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is a Breadth-First Spanning Tree?"}, {"role": "assistant", "content": "Given a connected graph G = (V, E) , where V includes a distinguished vertex vo, which will be the origin (root) of the BFS tree. We assume processes have no knowledge about the graph and have UIDs. We also assume (WLOG) that processes know the UIDs of their neighbors, and know which input and output ports are connected to each neighbor. Algorithms will be deterministic (or nondeterministic), but not randomized."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is required of processes in producing a Breadth-First Spanning Tree?"}, {"role": "assistant", "content": "Processes must produce a Breadth-First Spanning Tree rooted at vertex vo. Branches are directed paths from vo that reach all vertices(Spanning) and a vertex at distance d from vo appears at depth exactly d in the tree (Breadth-first). Each process i \u2260 io should output parent(j), meaning that j's vertex is the parent of i's vertex in the BFS tree."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How does a Simple BFS Algorithm work?"}, {"role": "assistant", "content": "Processes mark themselves as they get incorporated into the tree. Initially, only io is marked. Round 1: If i = io then process i sends a search message to its neighbors. If process i receives a message, then it: Marks itself, Selects io as its parent, outputs parent(io) and Plans to send at the next round. Round r > 1: If process i planned to send, then it sends a search message to its neighbors. If process i is not marked and receives a message, then it: Marks itself, Selects one sending neighbor, j, as its parent, outputs parent(j) and Plans to send at the next round."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the qualities of the Simple BFS Algorithm?"}, {"role": "assistant", "content": "The algorithm is slightly nondeterministic, in that a process can choose arbitrarily among several possible parents.  For distributed algorithms, nondeterminism is regarded differently from the way it is for sequential algorithms. A distributed algorithm should work correctly for all ways of resolving the nondeterministic choices."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are key correctness requirements of the Simple BFS Algorithm?"}, {"role": "assistant", "content": "Key invariants include: At the end of r rounds, exactly the processes at distance \u2264 r from v0 are marked. A process \u2260 i0 has its parent defined iff it is marked. For any process at distance d from v0, if its parent is defined, then it is the UID of a process at distance d \u2013 1 from v0 ."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the complexities of the Simple BFS Algorithm?"}, {"role": "assistant", "content": "Time complexity: Number of rounds until all nodes outputs their parent information which is <= Maximum distance of any node from vo. Message complexity: Number of messages sent by all processes during the entire execution is 0(|E|)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are additional features that can be added to a Breadth-First Spanning Tree?"}, {"role": "assistant", "content": "Child pointers: So far, each process learns its parent, but not its children. To add child pointers, everyone who receives a search message sends back a parent or nonparent response, at the next round. Distances: Augment the algorithm so everyone also learns and outputs its distance from vo. Each process records its distance from vo in a new dist variable, initially 0 for process io, and \u221e for everyone else. Include the dist value in every search message; when an unmarked process receives a search(d) message, it sets its own dist to d + 1."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How can termination of a BFS be achieved?"}, {"role": "assistant", "content": "Assume each search message receives a response, parent or nonparent. After a node has received responses to all its outgoing search messages, it knows who its children are, and knows they are all marked. The leaves of the tree learn who they are (they receive only nonparent responses). Now use a convergecast strategy."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What does the termination algorithm of a BFS tree look like?"}, {"role": "assistant", "content": "A process \u2260 io can send a done message to its parent after: It has received responses to all its search messages (so it knows who its children are), and It has received done messages from all of its children. io knows that the BFS tree is completed, when: It has received responses to all its search messages (so it knows who its children are), and It has received done messages from all of its children."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is involved in the Complexity for Termination of a BFS tree?"}, {"role": "assistant", "content": "After the tree is done, it takes \u2264 diam rounds and n messages for the done information to reach io. Process io can broadcast a message to everyone along the edges of the tree. Takes an additional diam rounds and n messages."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are some applications of Breadth-First Spanning Trees?"}, {"role": "assistant", "content": "Message broadcast: Process io can use a BFS tree with child pointers to broadcast a sequence of messages to all processes in the network. Could pipeline them, so k messages take only diam + k rounds, not diam \u00d7 k. Global computation: Suppose every process starts with some initial value, and process io should determine the value of some function of the set of all processes' values.  Can use convergecast on a BFS tree. Can also apply the BFS construction to Leader election in a general graph where Every process can start its own BFS, acting as the root. Use this to determine the maximum UID; process with the max UID is the leader."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the Shortest Paths problem?"}, {"role": "assistant", "content": "It Generalize the BFS problem to allow weights on the graph edges, weight{u,v} for edge {u, v}.  Processes know their neighbors and the weights of their incident edges, but otherwise have no knowledge about the graph."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the output requirements of a process working on the Shortest Paths problem?"}, {"role": "assistant", "content": "Each process i \u2260 io should output parent(j), distance(d), meaning that: j's vertex is the parent of i's vertex on a shortest path from vo, d is the total weight of a shortest path from vo to j."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How does the Bellman-Ford Shortest Paths Algorithm work?"}, {"role": "assistant", "content": "Each process i has: dist, a nonnegative real or \u221e, representing the shortest known distance from v\u2081. Initially 0 for process 10, \u221e for the others and parent, a UID or undefined, initially undefined. At each round: Send a distance(dist) message to all neighbors. Receive messages from neighbors; let dj be the distance received from neighbor j. Perform a relaxation step: dist := min(dist, min(dj + weight{i,j}) and If dist decreases then set parent := j, where j is any neighbor that produced the new dist."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the qualities of correctness of the Bellman-Ford Shortest Paths Algorithm?"}, {"role": "assistant", "content": "Eventually, every process i has: dist = minimum weight of a path from io to i, and if i \u2260 io, parent = the previous node on some shortest path from io to i. Key invariant: For every r, at the end of r rounds, every process i \u2260 io has its dist and parent corresponding to a shortest path from io to i among those paths that consist of at most r edges; if there is no such path, then dist = \u221e and parent is undefined."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the complexities of the Bellman-Ford Shortest Paths Algorithm?"}, {"role": "assistant", "content": "Number of rounds until all the variables stabilize to their final values which is n \u2013 1 rounds. Message complexity: Number of messages sent by all processes during the entire execution which is  0(n\u00b7|E|). More expensive than BFS."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How can Child Pointers be added to the Bellman-Ford Shortest Paths Algorithm?"}, {"role": "assistant", "content": "Ignore repeated messages. When process i receives a message that it does not use to improve dist, it responds with a nonparent message. When process i receives a message that it uses to improve dist, it responds with a parent message, and also responds to any previous parent with a nonparent message. Process i records nodes from which it receives parent messages in a set children. When process i receives a nonparent message from a current child, it removes the sender from its children. When process i improves dist, it empties children."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How can termination be achieved in the Bellman-Ford Shortest Paths Algorithm?"}, {"role": "assistant", "content": "We can use convergecast.  A process \u2260 io can send a done message to its current parent after: It has received responses to all its distance messages, so it believes it knows who its children are, and It has received done messages from all of those children and The same process may be involved several times in the convergecast, based on improved estimates."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are Distributed Algorithms?"}, {"role": "assistant", "content": "Algorithms that run on networked processors, or on multiprocessors that share memory. They solve many kinds of problems, work in difficult settings, and are hard to design, prove correct, and analyze."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "When were Distributed Algorithms studied?"}, {"role": "assistant", "content": "Studied since 1967, starting with Dijkstra and Lamport."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the topics in this week's lecture?"}, {"role": "assistant", "content": "A quick introduction, synchronous distributed algorithms (Leader Election, Maximal Independent Set, Breadth-First Spanning Trees, Shortest Paths Trees), and Asynchronous distributed algorithms (Breadth-First Spanning Trees, Shortest Paths Trees)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Why are modeling, proofs, and analysis important for distributed algorithms?"}, {"role": "assistant", "content": "Because they are complicated and error-prone."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is a distributed network based on?"}, {"role": "assistant", "content": "Based on an undirected graph G = (V, E). n= |V|, \u0393(u) (set of neighbors of vertex u), deg(u) = |\u0413(u)| (number of neighbors of vertex u).  Also, associate a process with each graph vertex and two directed communication channels with each edge."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the properties of Synchronous Network Model?"}, {"role": "assistant", "content": "Processes at nodes of an undirected graph communicate using messages. Each process has output ports, input ports that connect to communication channels. Process at vertex u doesn't know who its ports' channels connect to. Processes need not be distinguishable."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How does an algorithm execute?"}, {"role": "assistant", "content": "An algorithm executes in synchronous rounds. In each round, each process determines, based on its state, the messages to send on all its ports. Each message gets put into its channel, and delivered to the process at the other end. Then each process computes a new state based on its old state and the arriving messages."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is Leader Election?"}, {"role": "assistant", "content": "Leader election's goal is for exactly one process to output a special leader signal."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Prove theorem 1, there is no algorithm consisting of deterministic, indistinguishable processes that is guaranteed to elect a leader in G."}, {"role": "assistant", "content": "By contradiction. Assume an algorithm A that solves the problem. Both processes begin in the same start state. Prove by induction on the number r of completed rounds that both processes are in identical states after r rounds. Since the algorithm solves the leader election problem, eventually one of them gets elected. Then they both get elected, contradiction."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How is symmetry breaking done?"}, {"role": "assistant", "content": "Unique Identifiers (UIDs) are assumed. Or randomness."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe algorithm using UIDs and using Randomness for leader election."}, {"role": "assistant", "content": "Algorithm using UIDs:\nTheorem 2: Let G = (V, E) be an n-vertex clique. Then there is an algorithm consisting of deterministic processes with UIDs that is guaranteed to elect a leader in G. The algorithm takes only 1 round and uses only n\u00b2 point-to-point messages. Everyone sends its UID on all its output ports, and collects UIDs received on all its input ports. The process with the maximum UID elects itself the leader.\n\nAlgorithm using Randomness:\nTheorem 4: Let G = (V, E) be an n-vertex clique. Then there is an algorithm consisting of randomized, indistinguishable processes that eventually elects a leader in G, with probability 1. The algorithm takes expected time \u2264 1/(1-\u0454).  Also, with probability \u2265 1 \u2013 \u0454, the algorithm finishes in only one round. Processes choose random ids from a sufficiently large space. Exchange ids; if the maximum is unique, the maximum wins. Otherwise repeat, as many times as necessary."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is Maximal Independent Set (MIS)?"}, {"role": "assistant", "content": "Select a subset S of the nodes, so that they form a Maximal Independent Set.\nIndependent: No two neighbors are both in the set.\nMaximal: We can't add any more nodes without violating independence.\nEvery node is either in S or has a neighbor in S."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is Luby's MIS Algorithm?"}, {"role": "assistant", "content": "Executes in 2-round phases. Initially all nodes are active. At each phase, some active nodes decide to be in, others decide to be out, algorithm continues to the next phase with a smaller graph.  Repeat until all nodes have decided.\n\nRound 1:\nChoose a random value r in {1,2, ..., n5}, send it to all neighbors. Receive values from all active neighbors. If r is strictly greater than all received values, then join the MIS, output in.\n\nRound 2:\nIf you joined the MIS, announce it in messages to all (active) neighbors. If you receive such an announcement, decide not to join the MIS, output out. If you decided one way or the other at this phase, become inactive."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Prove Theorem 5 and 6."}, {"role": "assistant", "content": "Theorem 5: If Luby's algorithm ever terminates, then the final set S satisfies the independence property.\nProof:\nEach node joins S only if it has the unique maximum value in its neighborhood, at some phase.  When it does, all its neighbors become inactive.\n\nTheorem 6: If Luby's algorithm ever terminates, then the final set S satisfies the maximality property.\nProof:\nA node becomes inactive only if it joins S or a neighbor joins S.\nWe continue until all nodes are inactive."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain Theorem 7."}, {"role": "assistant", "content": "Theorem 7: With probability at least 1 \u2013 1/n, all nodes decide within 4 log n phases."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain the simple BFS algorithm."}, {"role": "assistant", "content": "Round 1:\nIf i = io then process i sends a search message to its neighbors. If process i receives a message, then it:\nMarks itself.\nSelects io as its parent, outputs parent(io).\nPlans to send at the next round.\nRound r > 1:\nIf process i planned to send, then it sends a search message to its neighbors.\nIf process i is not marked and receives a message, then it:\nMarks itself.\nSelects one sending neighbor, j, as its parent, outputs parent(j).\nPlans to send at the next round."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the state variables and invariants of BFS?"}, {"role": "assistant", "content": "State variables, per process:\nmarked, a Boolean, initially true for io, false for others\nparent, a UID or undefined\nsend, a Boolean, initially true for io, false for others\nuid\nInvariants:\nAt the end of r rounds, exactly the processes at distance \u2264 r from vo are marked.\nA process \u2260 io has its parent defined iff it is marked.\nFor any process at distance d from vo, if its parent is defined, then it is the UID of a process at distance d \u2013 1 from vo."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the complexity of BFS?"}, {"role": "assistant", "content": "Time complexity:\nNumber of rounds until all nodes outputs their parent information.\nMaximum distance of any node from vo, which is \u2264 diam\nMessage complexity:\nNumber of messages sent by all processes during the entire execution.\nO(|E|)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the algorithm for terminating BFS?"}, {"role": "assistant", "content": "Assume each search message receives a response, parent or nonparent. After a node has received responses to all its outgoing search messages, it knows who its children are, and knows they are all marked. The leaves of the tree learn who they are (they receive only nonparent responses).\nUse a convergecast strategy:\nStarting from the leaves, the processes fan in done messages up the\nBFS tree, toward io."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is Bellman-Ford Shortest Paths Algorithm?"}, {"role": "assistant", "content": "State variables:\ndist, a nonnegative real or \u221e, representing the shortest known distance from v1. Initially 0 for process 10, \u221e for the others.\nparent, a UID or undefined, initially undefined.\nuid\nAlgorithm for process i:\nAt each round:\nSend a distance(dist) message to all neighbors.\nReceive messages from neighbors; let d; be the distance received from neighbor j.\nPerform a relaxation step:\ndist := min(dist, min(dj + weight{i,j}).\nj\nIf dist decreases then set parent := j, where j is any neighbor that produced the new dist."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the Key invariant for the Correctness of Bellman Ford?"}, {"role": "assistant", "content": "For every r, at the end of r rounds, every process i \u2260 io has its dist and parent corresponding to a shortest path from io to i among those paths that consist of at most r edges; if there is no such path, then dist = \u221e and parent is undefined."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the complexity of Bellman Ford?"}, {"role": "assistant", "content": "Time complexity:\nNumber of rounds until all the variables stabilize to their final values.\nn \u2013 1 rounds\nMessage complexity:\nNumber of messages sent by all processes during the entire execution.\nO(n\u00b7|E|)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What topics will be covered in this lecture on cryptography?"}, {"role": "assistant", "content": "Hash functions, Random oracle model, Desirable Properties, Applications to security"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is a hash function?"}, {"role": "assistant", "content": "A hash function h maps arbitrary strings of data to fixed length output. The function is deterministic and public, but the mapping should look 'random'. In other words, \\(h : {0,1}* \\rightarrow {0,1}^d\\) for a fixed d. Hash functions do not have a secret key."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How are hash functions used in practice?"}, {"role": "assistant", "content": "Hash functions are used for 'digesting' large data. For example, if you want to check the validity of a large file, you can check the hash value of that file with the expected hash."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is a desirable property for cryptographic hash functions?"}, {"role": "assistant", "content": "It is desirable that the function is collision resistant, meaning it should be 'hard' to find two inputs M1 and m2 for hash function h such that \\(h(m\u2081) = h(m2)\\)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the security levels of modern hash functions and some older ones?"}, {"role": "assistant", "content": "Most modern hash functions hope to achieve a security level of \\(2^{64}\\) or better. MD4 and MD5 aimed to provide \\(2^{64}\\) security but have been broken. SHA-1 aimed to provide \\(2^{80}\\) security but has been shown to be no more than \\(2^{61}\\) security."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the Random Oracle model?"}, {"role": "assistant", "content": "The Random Oracle model is an ideal model of the hash function that is not achievable in practice. In this model, there exists an oracle h such that on input x, if h has not seen x before, then it outputs a random value as h(x). Otherwise, it returns h(x) it previously output."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the desirable properties of a hash function?"}, {"role": "assistant", "content": "1. One-way (pre-image resistance): Given \\(y \u2208 {0,1}^d\\), it is hard to find an x such that \\(h(x) = y\\).\n2. Strong collision-resistance: It is hard to find any pair of inputs x, x' such that \\(h(x) = h(x')\\).\n3. Weak collision-resistance (target collision resistance, 2nd pre-image resistance): Given x, it is hard to find x' such that \\(h(x) = h(x')\\).\n4. Pseudo-random: The function behaves indistinguishable from a random oracle.\n5. Non-malleability: Given h(x), it is hard to generate h(f(x)) for any function f."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are some applications of hash functions?"}, {"role": "assistant", "content": "1. Password Storage: We can store hash h(p) for password p instead of p directly, and check h(p) to authenticate a user. \n2. File Authenticity: For each file F, we can store h(F) in a secure location. To check authenticity of a file, we can recompute h(F).\n3. Digital Signature: We can use hash functions to generate a signature that guarantees that the message came from a said source.\n4. Commitments: In a secure bidding, Alice wants to bid value x, but does not want to reveal the bid until the auction is over. Alice then computes h(x), and publicize it, which serves as her commitment."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the topics covered in Lecture 2?"}, {"role": "assistant", "content": "Paradigm, Convex Hull, and Median finding."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the Paradigm for divide and conquer."}, {"role": "assistant", "content": "Given a problem of size n, divide it into subproblems of size n/b, where a > 1 and b > 1. Solve each subproblem recursively and combine solutions of subproblems to get the overall solution. The time complexity is given by T(n) = aT(n/b) + [work for merge]."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Define Convex Hull."}, {"role": "assistant", "content": "Given n points in the plane S = {(xi, yi)|i = 1, 2, . . ., n}, assuming no two have the same x coordinate, no two have the same y coordinate, and no three are in a line for convenience, the Convex Hull (CH(S)) is the smallest polygon containing all points in S.  CH(S) is represented by the sequence of points on the boundary in order clockwise as a doubly linked list. The provided image illustrates a convex hull with points p, q, r, s, t, and u."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain the Brute force approach for Convex Hull."}, {"role": "assistant", "content": "Test each line segment to see if it makes up an edge of the convex hull. If the rest of the points are on one side of the segment, the segment is on the convex hull; otherwise, the segment is not. This approach has a complexity of O(n^3) because there are O(n^2) edges and O(n) tests."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the Divide and Conquer approach for Convex Hull."}, {"role": "assistant", "content": "First, sort points by x coordinate (once and for all, O(n log n)). For the input set S of points: Divide into the left half A and the right half B by x coords. Compute CH(A) and CH(B). Combine CH's of two halves (merge step)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How to merge the Convex Hull?"}, {"role": "assistant", "content": "Find the upper tangent (ai, bj). In the example, (a4, b\u2082) is U.T. Find the lower tangent (ak, bm). In the example, (a3, b3) is L.T.\nCut and paste in time \u0398(n). First link a\u017c to bj, go down b list till you see bm and link bm to ak, continue along the a list until you return to ai. In the example, this gives (a4, b2, b3, a3)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How to find Tangents?"}, {"role": "assistant", "content": "Assume a\u017c maximizes x within CH(A) (a1, a2,..., ap). b\u2081 minimizes x within CH(B) (b1, b2,..., bq). L is the vertical line separating A and B. Define y(i, j) as the y-coordinate of intersection between L and segment (ai, bj). Claim: (ai, bj) is uppertangent if and only if it maximizes y(i, j). If y(i, j) is not maximum, there will be points on both sides of (ai, bj) and it cannot be a tangent.  The provided picture has two convex hulls A and B, separated by line L. The points \\(a_1\\), \\(a_2\\), \\(a_3\\), \\(a_4\\), \\(a_5\\) belong to A and \\(b_1\\), \\(b_2\\), \\(b_3\\) belong to B. \\((a_4, b_2)\\) is the upper tangent and \\((a_3, b_3)\\) is the lower tangent."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain the algorithm for finding tangents."}, {"role": "assistant", "content": "Obvious O(n\u00b2) algorithm looks at all ai, bj pairs.  T(n) = 2T(n/2) + \u0398(n\u00b2) = \u0398(n\u00b2).\nAlgorithm:\n1. i = 1\n2. j = 1\n3. while (y(i, j + 1) > y(i, j) or y(i \u2212 1, j) > y(i, j))\n4.  if (y(i, j + 1) > y(i, j)) \u25b7 move right finger clockwise\n5.   j = j + 1 (mod q)\n6.  else\n7.   i = i - 1 (mod p) \u25b7 move left finger anti-clockwise\n8. return (ai, bj) as upper tangent\nSimilarly for lower tangent.\nT(n) = 2T(n/2) + \u0398(n) = O(n log n)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Define Median Finding."}, {"role": "assistant", "content": "Given a set of n numbers, define rank(x) as the number of numbers in the set that are \u2264 x. Find the element of rank \\[ \\frac{n+1}{2} \\] (lower median) and \\[ \\frac{n+1}{2} \\] (upper median).  Sorting works in O(n log n) time."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the SELECT Algorithm."}, {"role": "assistant", "content": "SELECT(S, i):\n1. Pick x \u2208 S \u25b7 cleverly\n2. Compute k = rank(x)\n3. B = {y \u2208 S|y < x}\n4. C = {y \u2208 S|y > x}\n5. if k = i\n6.  return x\n7. else if k > i\n8.  return Select(B, i)\n9. else if k < i\n10.  return Select(C, i \u2013 k)\n\nIn the provided image, there is a horizontal line B, and another horizontal line C. There is a x between them. The k-1 elements are to the left of x and the n-k elements are to the right of x"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How to pick x cleverly?"}, {"role": "assistant", "content": "Need to pick x so rank(x) is not extreme.\nArrange S into columns of size 5 (\\[n/5\\] cols)\nSort each column (bigger elements on top) (linear time)\nFind \"median of medians\" as x. The image displays a matrix of numbers with 5 rows, where the median of each column is identified and medians of these medians is marked as x."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How many elements are guaranteed to be > x?"}, {"role": "assistant", "content": "Half of the \\[n/5\\] groups contribute at least 3 elements > x except for 1 group with less than 5 elements and 1 group that contains x.\nAt lease 3(\\[1/2 * n/5\\] \u2013 2) elements are > x, and at least 3(\\[1/2 * n/5\\] \u2013 2) elements are < x\nRecurrence:\nT(n) = {O(1),                                  for n < 140 \nT(n/5)+T(7n/10 + 6) +\u0398(n), for n > 140 "}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Solve the Recurrence of Median Finding."}, {"role": "assistant", "content": "Master theorem does not apply. Intuition 7n/10 + n/5 < n.\nProve T(n) \u2264 cn by induction, for some large enough c. True for n < 140 by choosing large c\n\nT(n) \u2264 c * n/5 +c(7n/10 + 6) + an \n\u2264 c* n/5+ c* 7n/10 + 6c + an\n= cn + (-cn/10 + 6c + an)\nIf c \u2265 70c/n + 10a, we are done. This is true for n \u2265 140 and c \u2265 20a."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the topics covered this week?"}, {"role": "assistant", "content": "Synchronous distributed algorithms: Leader Election, Maximal Independent Set, Breadth-First Spanning Trees, Shortest Paths Trees (started/finish). Asynchronous distributed algorithms: Breadth-First Spanning Trees, Shortest Paths Trees"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the basis for Distributed Networks?"}, {"role": "assistant", "content": "Based on undirected graph G = (V,E). n = |V|, \u0413(u), set of neighbors of vertex u, deg(u) = |\u0413(u)|, number of neighbors of vertex u. Associate a process with each graph vertex and two directed communication channels with each edge."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the Synchronous Network Model?"}, {"role": "assistant", "content": "Processes at graph vertices communicate using messages. Each process has output ports, input ports that connect to communication channels. The algorithm executes in synchronous rounds. In each round, each process sends messages on its ports. Each message gets put into the channel, delivered to the process at the other end. Each process computes a new state based on the arriving messages."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the n-vertex Clique"}, {"role": "assistant", "content": "Theorem: There is no algorithm consisting of deterministic, indistinguishable processes that is guaranteed to elect a leader in G. Theorem: There is an algorithm consisting of deterministic processes with UIDs that is guaranteed to elect a leader in 1 round, n\u00b2 messages. Theorem: There is an algorithm consisting of randomized, indistinguishable processes that eventually elects a leader, with probability 1. Expected time \u2264 1/(1-e). With probability \u2265 1 \u2013 e, finishes in one round."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the characteristics of MIS"}, {"role": "assistant", "content": "Independent: No two neighbors are both in the set. Maximal: We can't add any more nodes without violating independence. Every node is either in S or has a neighbor in S. Assume: No UIDs, Processes know a good upper bound on n. Require: Compute an MIS S of the network graph, Each process in S should output in, others output out."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe Luby's Algorithm"}, {"role": "assistant", "content": "Initially all nodes are active. At each phase, some active nodes decide to be in, others decide to be out, the rest continue to the next phase. Round 1: Choose a random value r in {1,2, ..., n^5}, send it to all neighbors. Receive values from all active neighbors. If r is strictly greater than all received values, then join the MIS, output in. Round 2: If you joined the MIS, announce it in messages to all (active) neighbors. If you receive such an announcement, decide not to join the MIS, output out. If you decided one way or the other at this phase, become inactive. Theorem: If Luby's algorithm ever terminates, then the final set S is an MIS. Theorem: With probability at least 1 \u2013 1/n, all nodes decide within 4 log n phases."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the Breadth-First Spanning Trees"}, {"role": "assistant", "content": "Distinguished vertex vo. Processes must produce a Breadth-First Spanning Tree rooted at vertex vo. Assume: UIDs. Processes have no knowledge about the graph. Output: Each process i \u2260 io should output parent(j)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe Simple BFS Algorithm"}, {"role": "assistant", "content": "Processes mark themselves as they get incorporated into the tree. Initially, only i\u2080 is marked. Algorithm for process i: Round 1: If i = i\u2080 then process i sends a search message to its neighbors. If process i receives a message, then it: Marks itself, Selects i\u2080 as its parent, outputs parent(i\u2080), Plans to send at the next round. Round r > 1: If process i planned to send, then it sends a search message to its neighbors. If process i is not marked and receives a message, then it: Marks itself, Selects one sending neighbor, j, as its parent, outputs parent(j), Plans to send at the next round."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the state variables per process, and what are the invariants?"}, {"role": "assistant", "content": "State variables, per process: marked, a Boolean, initially true for io, false for others, parent, a UID or undefined, send, a Boolean, initially true for io, false for others, uid. Invariants: At the end of r rounds, exactly the processes at distance \u2264 r from vo are marked. A process \u2260 io has its parent defined iff it is marked. For any process at distance d from vo, if its parent is defined, then it is the UID of a process at distance d \u2013 1 from vo."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the complexity of Breadth-First Spanning Trees?"}, {"role": "assistant", "content": "Time complexity: Number of rounds until all nodes outputs their parent information, Maximum distance of any node from vo, which is \u2264 diam. Message complexity: Number of messages sent by all processes during the entire execution, 0(|E|)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the bells and whistles of Breadth-First Spanning Trees?"}, {"role": "assistant", "content": "Child pointers: Send parent/nonparent responses to search messages. Distances: Piggyback distances on search messages. Termination: Convergecast starting from the leaves. Applications: Message broadcast from the root, Global computation"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the Shortest Paths"}, {"role": "assistant", "content": "Generalize the BFS problem to allow weights on the graph edges, weight{u,v} for edge {u, v} Connected graph G = (V, E), root vertex vo, process io. Processes have UIDs. Processes know their neighbors and the weights of their incident edges, but otherwise have no knowledge about the graph. Processes must produce a Shortest-Paths Spanning Tree rooted at vertex vo. Branches are directed paths from vo. Spanning: Branches reach all vertices. Shortest paths: The total weight of the tree branch to each node is the minimum total weight for any path from vo in G. Output: Each process i \u2260 io should output parent(j), distance(d), meaning that: j's vertex is the parent of i's vertex on a shortest path from vo, d is the total weight of a shortest path from vo to j."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe Bellman-Ford Shortest Paths Algorithm"}, {"role": "assistant", "content": "State variables: dist, a nonnegative real or \u221e, representing the shortest known distance from vo. Initially 0 for process i0, \u221e for the others. parent, a UID or undefined, initially undefined. uid Algorithm for process i: At each round: Send a distance(dist) message to all neighbors. Receive messages from neighbors; let dj be the distance received from neighbor j. Perform a relaxation step: dist := min(dist, min(dj + weight{i,j}). If dist decreases then set parent := j, where j is any neighbor that produced the new dist."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the correctness of Bellman-Ford Shortest Paths Algorithm?"}, {"role": "assistant", "content": "Claim: Eventually, every process i has: dist = minimum weight of a path from io to i, and if i \u2260 io, parent = the previous node on some shortest path from io to i. Key invariant: For every r, at the end of r rounds, every process i \u2260 io has its dist and parent corresponding to a shortest path from io to i among those paths that consist of at most r edges; if there is no such path, then dist = \u221e and parent is undefined."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the complexity of Bellman-Ford Shortest Paths Algorithm?"}, {"role": "assistant", "content": "Time complexity: Number of rounds until all the variables stabilize to their final values, n \u2013 1 rounds. Message complexity: Number of messages sent by all processes during the entire execution, O(n\u00b7|E|). More expensive than BFS: diam rounds, O(|E|) messages."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are child pointers?"}, {"role": "assistant", "content": "Ignore repeated messages. When process i receives a message that it does not use to improve dist, it responds with a nonparent message. When process i receives a message that it uses to improve dist, it responds with a parent message, and also responds to any previous parent with a nonparent message. Process i records nodes from which it receives parent messages in a set children. When process i receives a nonparent message from a current child, it removes the sender from its children. When process i improves dist, it empties children."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the termination of Shortest-paths?"}, {"role": "assistant", "content": "Q: How can the processes learn when the shortest-paths tree is completed? Q: How can a process even know when it can output its own parent and distance? If processes knew an upper bound on n, then they could simply wait until that number of rounds have passed. But what if they don't know anything about the graph? Recall termination for BFS: Used convergecast. Q: Does that work here? Yes, but it's trickier, since the tree structure changes. A process \u2260 i\u2080 can send a done message to its current parent after: It has received responses to all its distance messages, so it believes it knows who its children are, and It has received done messages from all of those children."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the Asynchronous Network Model"}, {"role": "assistant", "content": "Complications so far: Processes act concurrently. A little nondeterminism. Now things get much worse: No rounds---process steps and message deliveries happen at arbitrary times, in arbitrary orders. Processes get out of synch. Much more nondeterminism. Understanding asynchronous distributed algorithms is hard because we can't understand exactly how they execute. Instead, we must understand abstract properties of executions."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe Asynchronous Network Model by Lynch"}, {"role": "assistant", "content": "Processes at nodes of an undirected graph G = (V, E), communicate using messages. Communication channels associated with edges (one in each direction on each edge). Cu,v, channel from vertex u to vertex v. Each process has output ports and input ports that connect it to its communication channels. Processes need not be distinguishable."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe Channel Automaton Cu,v"}, {"role": "assistant", "content": "Formally, an input/output automaton. Input actions: send(m)u,v Output actions: receive(m)u,v State variable: mqueue, a FIFO queue, initially empty. Transitions: send(m)u,v Effect: add m to mqueue. receive(m)u,v Precondition: m = head(mqueue) Effect: remove head of mqueue"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe Process Automaton Pu"}, {"role": "assistant", "content": "Associate a process automaton with each vertex of G. To simplify notation, let Pu denote the process automaton at vertex u. But the process does not \"know\u201d u. Pu has send(m)u,v outputs and receive(m)v,u inputs. May also have external inputs and outputs. Has state variables. Keeps taking steps (eventually)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe Maxu Process Automaton"}, {"role": "assistant", "content": "Input actions: receive(m)v,u Output actions: send(m)u,v State variables: max, a natural number, initially xu. For each neighbor v: send(v), a Boolean, initially true Transitions: receive(m)v,u Effect: if m > max then max:= m for every w, send(w) := true send(m)u,v Precondition: send(v) = true and m = \u0442\u0430\u0445 Effect: send(v) := false"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How to combine Processes and Channels?"}, {"role": "assistant", "content": "Undirected graph G = (V,E). Process Pu at each vertex u. Channels Cu,v and Cv,u, associated with each edge {u, v}. send(m)u,v output of process Pu gets identified with send(m)u, vinput of channel Cu,v. receive(m)v,u output of channel Cv,u gets identified with receive(m)v,u input of process Pu. Steps involving such a shared action involve simultaneous state transitions for a process and a channel."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe Execution in Asynchronous Network Model"}, {"role": "assistant", "content": "No synchronous rounds anymore. The system executes by performing enabled steps, one at a time, in any order. Formally, an execution is modeled as a sequence of individual steps. Different from the synchronous model, in which all processes take steps concurrently at each round. Assume enabled steps eventually occur: Each channel always eventually delivers the first message in its queue, each process always eventually performs some enabled step."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How to combine Max Processes and Channels?"}, {"role": "assistant", "content": "Each process Maxu starts with an initial value xu. They all send out their initial values, and propagate their max values, until everyone has the globally-maximum value. Sending and receiving steps can happen in many different orders, but in all cases the global max will eventually arrive everywhere."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the complexity in Asynchronous Network Model?"}, {"role": "assistant", "content": "Message complexity: Number of messages sent by all processes during the entire execution, 0(n\u00b7|E|) Time complexity: Q: What should we measure? Not obvious, because the various components are taking steps in arbitrary orders---no \u201crounds\u201d. A common approach: Assume real-time upper bounds on the time to perform basic steps: d for a channel to deliver the next message, and I for a process to perform its next step. Infer a real-time upper bound for solving the overall problem."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe Time complexity in Asynchronous Network Model?"}, {"role": "assistant", "content": "Assume real-time upper bounds on the time to perform basic steps: d for a channel to deliver the next message, and l for a process to perform its next step. Infer a real-time upper bound for solving the problem. For the Max system: Ignore local processing time (l = 0), consider only channel sending time. Straightforward upper bound: O(diam \u00b7 n \u00b7 d) Consider the time for the max to reach any particular vertex u, along a shortest path in the graph. At worst, it waits in each channel on the path for every other value, which is at most time n\u00b7d for that channel."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the asynchronous Breadth-First Spanning Trees?"}, {"role": "assistant", "content": "Problem: Compute a Breadth-First Spanning Tree in an asynchronous network. Connected graph G = (V, E). Distinguished root vertex vo. Processes have no knowledge about the graph. Processes have UIDs i0 is the UID of the root v0. Processes know UIDs of their neighbors, and know which ports are connected to each neighbor. Processes must produce a BFS tree rooted at vo. Each process i \u2260 i0 should output parent(j), meaning that j's vertex is the parent of i's vertex in the BFS tree."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the First Attempt for Breadth-First Spanning Trees?"}, {"role": "assistant", "content": "Just run the simple synchronous BFS algorithm asynchronously. Process i0 sends search messages, which everyone propagates the first time they receive it. Everyone picks the first node from which it receives a search message as its parent. Nondeterminism: No longer any nondeterminism in process decisions. But plenty of new nondeterminism: orders of message deliveries and process steps."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the Process Automaton Pu for Breadth-First Spanning Trees?"}, {"role": "assistant", "content": "Input actions: receive(search)v,u Output actions: send(search)u,v; parent(v)u State variables: parent: \u0393(u) U {1}, initially I reported: Boolean, initially false For every v \u2208 \u0393(\u0438): send(v) \u2208 {search, 1}, initially search if u = vo, else I Transitions: receive(search)v,u Effect: if u \u2260 vo and parent = 1 then parent := v - for every w, send(w) := search"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is running Simple BFS Asynchronously?"}, {"role": "assistant", "content": "This process can lead to paths that are longer than the shortest paths. Because in asynchronous networks, messages may propagate faster along longer paths."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the complexity of Simple BFS Asynchronously?"}, {"role": "assistant", "content": "Message complexity: Number of messages sent by all processes during the entire execution, O(|E|) Time complexity: Time until all processes have chosen their parents. Neglect local processing time. O(diam\u00b7d) Q: Why diam, when some of the paths are longer? The time until a node receives a search message is at most the time it would take on a shortest path."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are Extensions for Simple BFS Asynchronously?"}, {"role": "assistant", "content": "Child pointers: As for synchronous BFS. Everyone who receives a search message sends back a parent or nonparent response. Termination: After a node has received responses to all its search its messages, it knows who its children are, and knows they are marked. The leaves of the tree learn who they are. Use a convergecast strategy, as before. Time complexity: After the tree is done, it takes time 0(n\u00b7d) for the done information to reach io. Message complexity: 0(n)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the applications for Simple BFS Asynchronously?"}, {"role": "assistant", "content": "Message broadcast: Process i0 can use the tree (with child pointers) to broadcast a message. Takes O(n\u00b7d) time and n messages. Global computation: Suppose every process starts with some initial value, and process i0 should determine the value of some function of the set of all processes' values. Use convergecast on the tree. Takes O(n\u00b7d) time and n messages."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the Second Attempt for Breadth-First Spanning Trees?"}, {"role": "assistant", "content": "A relaxation algorithm, like synchronous Bellman-Ford. Before, we corrected for paths with many hops but low weights. Now, instead, correct for errors caused by asynchrony. Strategy: Each process keeps track of the hop distance, changes its parent when it learns of a shorter path, and propagates the improved distances. Eventually stabilizes to a breadth-first spanning tree."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the Process Automaton Pu for Breadth-First Spanning Trees?"}, {"role": "assistant", "content": "Input actions: receive(m)v,u, m a nonnegative integer Output actions: send(m)u,v, ma nonnegative integer State variables: parent: \u0393(u) U {1}, initially I dist \u2208 N U {\u221e}, initially 0 if u = vo, \u221e otherwise For every v \u2208 \u0393(\u0438): send(v), a FIFO queue of N, initially (0) if u = vo, else empty Transitions: receive(m)v,u Effect: if m + 1 dist then dist := m + 1 parent := v for every w, add dist to send(w)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the correctness of Breadth-First Spanning Trees?"}, {"role": "assistant", "content": "For synchronous BFS, we characterized precisely the situation after r rounds. We can't do that now. Instead, state abstract properties, e.g., invariants and timing properties, e.g.: Invariant: At any point, for any node u \u2260 vo, if its dist \u2260 \u221e, then it is the actual distance on some path from vo to u, and its parent is u's predecessor on such a path. Timing property: For any node u, and any r, 0 \u2264 r \u2264 diam, if there is an at-most-r-hop path from vo to u, then by time r\u00b7n\u00b7d, node u's dist is \u2264 r."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the complexity of Breadth-First Spanning Trees?"}, {"role": "assistant", "content": "Message complexity: Number of messages sent by all processes during the entire execution, O(n |E|) Time complexity: Time until all processes' dist and parent values have stabilized. Neglect local processing time. O(diam\u00b7n\u00b7d), Time until each node receives a message along a shortest path, counting time O(n\u00b7d) to traverse each link."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the termination of Breadth-First Spanning Trees?"}, {"role": "assistant", "content": "How can processes learn when the tree is completed? How can a process know when it can output its own dist and parent? Knowing a bound on n doesn't help here: can't use it to count rounds. Can use convergecast, as for synchronous Bellman-Ford: Compute and recompute child pointers, Process \u2260 v0 sends done to its current parent after: It has received responses to all its messages, so it believes it knows all its children, and It has received done messages from all of those children, The same process may be involved several times, based on improved estimates."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the uses of Breadth-First Spanning Trees?"}, {"role": "assistant", "content": "Same as in synchronous networks, e.g.: Broadcast a sequence of messages Global function computation Similar costs, but now count time d instead of one round."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the Shortest Paths?"}, {"role": "assistant", "content": "Problem: Compute a Shortest Paths Spanning Tree in an asynchronous network. Connected weighted graph, root vertex vo. weight{u,v} for edge {u, v}. Processes have no knowledge about the graph, except for weights of incident edges. UIDS Processes must produce a Shortest Paths spanning tree rooted at vo. Each process u \u2260 vo should output its distance and parent in the tree."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the algorithm for Shortest Paths?"}, {"role": "assistant", "content": "Use a relaxation algorithm, once again. Asynchronous Bellman-Ford. Now, it handles two kinds of corrections: Because of long, small-weight paths (as in synchronous Bellman-Ford), Because of asynchrony (as in asynchronous Breadth-First search). The combination leads to surprisingly high message and time complexity, much worse than either type of correction alone (exponential)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the Process Pu in Asynch Bellman-Ford"}, {"role": "assistant", "content": "Input actions: receive(m)v,u, m a nonnegative integer Output actions: send(m)u,v, ma nonnegative integer State variables: parent: \u0393(u) U {1}, initially I dist \u2208 N U {\u221e}, initially 0 if u = vo, \u221e otherwise For every v \u2208 \u0393(\u0438): send(v), a FIFO queue of N, initially (0) if u = vo, else empty Transitions: receive(m)v,u Effect: if m + weight{v,u} < dist then dist := m + weight{v,u} parent := v for every w, add dist to send(w)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the correctness of Shortest Path?"}, {"role": "assistant", "content": "Invariant: At any point, for any node u \u2260 vo, if its dist \u2260 \u221e, then it is the actual distance on some path from vo to u, and its parent is u's predecessor on such a path. Timing property: For any node u, and any r, 0 \u2264 r \u2264 diam, if p is any at-most-r-hop path from vo to u, then by time ???, node u's dist is \u2264 total weight of p. It depends on how many messages might pile up in a channel, this can be a lot!"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the complexity of Shortest Path?"}, {"role": "assistant", "content": "O(n!) simple paths from vo to any other node u, which is O(nn). So the number of messages sent on any channel is 0(n^n). Message complexity: O(n^n |E|). Time complexity: O(n^n n. d). The execution of the network in which node vk sends 2k \u2248 2n/2 messages to node vk+1. Message complexity is \u03a9(2n/2). Time complexity is \u03a9(2n/2 d)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the conclusion of Shortest Path algorithm?"}, {"role": "assistant", "content": "Moral: Unrestrained asynchrony can cause problems, but what to do? Find out in 6.852/18.437, Distributed Algorithms!"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is Linear Programming (LP)?"}, {"role": "assistant", "content": "Linear programming (LP) is a method to achieve the optimum outcome under some requirements represented by linear relationships. More precisely, LP can solve the problem of maximizing or minimizing a linear objective function subject to some linear constraints."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the standard form of LP?"}, {"role": "assistant", "content": "The standard form of LP consists of:\nVariables: $x = (x_1, x_2,...,x_d)^T$\nObjective function: c.x\nInequalities (constraints): $Ax \\le b$, where A is a n \u00d7 d matrix\nand we maximize the objective function subject to the constraints and x \u2265 0."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the approach to campaign to win an election through Linear Programming?"}, {"role": "assistant", "content": "In general, there are n demographics, each with pi people, and m issues that the voters are interested in. Given the information on how many votes can be obtained per dollar spent advertising in support of an issue, how can we guarantee victory by ensuring a majority vote in all demographics?"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How can we formulate the problem of determining the minimum amount of money to spend to guarantee majority in all demographics (with 3 demographics and 4 issues) as an LP problem (where X1,X2,X3,X4 denote the dollars spent per issue)?"}, {"role": "assistant", "content": "Minimize $x_1 + x_2 + x_3 + x_4$\nSubject to\n$2x_1 + 8x_2 + 0x_3 + 10x_4 \u2265 50,000$ (Urban Majority)\n$5x_1 + 2x_2 + 0x_3 + 0x_4 \u2265 100,000$ (Suburban Majority)\n$3x_1 - 5x_2 + 10x_3 - 2x_4 \u2265 25,000$ (Rural Majority)\n$x_1, x_2, x_3, x_4 \u2265 0$ (Can't unadvertise)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the table for the votes per dollar spent on advertising, and population."}, {"role": "assistant", "content": "The table shows the votes per dollar spent on advertising and population for different policies and demographics. The policies are Building roads, Gun Control, Farm Subsidies, and Gasoline Tax. The demographics are Urban, Suburban, and Rural. The population for each demographic is 100,000, 200,000, and 50,000 respectively. The votes per dollar spent are as follows:\nBuilding roads: -2 (Urban), 5 (Suburban), 3 (Rural)\nGun Control: 8 (Urban), 2 (Suburban), -5 (Rural)\nFarm Subsidies: 0 (Urban), 0 (Suburban), 10 (Rural)\nGasoline Tax: 10 (Urban), 0 (Suburban), 2 (Rural)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How to verify that the solution is optimal with a proper certificate?"}, {"role": "assistant", "content": "Though we have not presented an algorithm for solving this problem, given a solution, we can verify that the solution is optimal with a proper certificate. For example,\n$x_1 = \\frac{2050000}{111}$\n$x_2 = \\frac{425000}{111}$\n$x_3 = 0$\n$x_4 = \\frac{625000}{111}$\n$x_1 + x_2 + x_3 + x_4 = \\frac{3100000}{111}$\nis a solution to this problem. Now consider the following equation (certificate):\n$\\frac{25}{222} (1) + \\frac{46}{222} (2) + \\frac{14}{222} (3) = x_1 + x_2 + \\frac{140}{222} x_3 + x_4$\n$\\ge \\frac{25}{222} 50000 + \\frac{46}{222} 100000 + \\frac{14}{222} 25000 = \\frac{3100000}{111}$\n$\\Rightarrow x_1 + x_2 + \\frac{140}{222} x_3 + x_4 \\ge \\frac{3100000}{111}$\nWe also know that $x_1 + x_2 + x_3 + x_4 \\ge x_1 + x_2 + \\frac{140}{222} x_3 + x_4$. Therefore, the given solution is an optimal solution to the problem."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain Linear Programming Duality."}, {"role": "assistant", "content": "The short certificate provided in the last section is not a coincidence, but a consequence of duality of LP problems. For every primal LP problem in the form of:\nMaximize cx\nSubject to $Ax \\le b, x \\ge 0$,\nthere exists an equivalent dual LP problem:\nMinimize by\nSubject to $A^Ty \\ge c, y \\ge 0$.\nThis property of LP can be used show many important theorems. For instance, the max-flow min-cut theorem can be proven by formulating the max-flow problem as the primal LP problem."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How to convert LP to standard form?"}, {"role": "assistant", "content": "The natural LP formulation of a problem may not result in the standard LP form. In these cases, we can convert the problem to standard LP form without affecting the answers by using the following rules:\nMinimize an objective function: Negate the coefficients and maximize.\nVariable xj does not have a non-negativity constraint: Replace xj with $x_j' - x_j''$, and $x_j', x_j'' \\ge 0$.\nEquality constraints: Split into two different constraints; $x \\le b, x \\ge b$.\nGreater than or equal to constraints: Negate the coefficients, and translate to less than or equal to constraint."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How to model the max flow problem?"}, {"role": "assistant", "content": "We can model the max flow problem as maximization of sum of flows, under some constraints which will model different properties of the flow. Given G(V, E), the capacity c(e) for each e \u2208 E, the source s, and the sink t,\nMaximize $\\sum_{v \\in V} f(s, v)$\nSubject to\nf(u, v) = \u2212f(v, u) \u2200u, v \u2208 V skew symmetry\n$\\sum_{v \\in V} f(u, v) = 0 \\forall u \\in V \u2013 {s, t}$ conservation\nf(u, v) \u2264 c(u, v) \u2200u, v \u2208 V capacity."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How to model the shortest paths problem?"}, {"role": "assistant", "content": "We can model the shortest paths problem as minimization of the sum of all distances from a node. Note that this sum is minimized only when all distances are minimized. Given G(V, E), the weight w(e) for each e \u2208 E, and the source s,\nMaximize $\\sum_{v \\in V} d(v)$\nSubject to\nd(v) \u2013 d(u) \u2264 w(u, v)\u2200u, v \u2208 V triangular inequality\n$\\sum_{v \\in V} d(s) = 0$.\nNote the maximization above, so all distances don't end up being zero. There is no solution to this LP if and only if there exists a negative weight cycle reachable from s."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What algorithms are available for solving LP problems?"}, {"role": "assistant", "content": "The are many algorithms for solving LP problems:\nSimplex algorithm: In the feasible region, x moves from vertex to vertex in direction of c. The algorithm is simple, but runs in exponential time in the worst case.\nEllipsoid algorithm: It starts with an ellipsoid that includes the optimal solution, and keeps shrinking the ellipsoid until the optimal solution is found. This was the first poly-time algorithm, and was a theoretical breakthrough. However, the algorithm is impractical in practice.\nInterior Point Method: \u00e6 moves inside the polytope following c. This algorithm runs in poly-time, and is practical."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain Simplex Algorithm."}, {"role": "assistant", "content": "The simplex algorithm works well in practice, but runs in exponential time in the worst case. At a high level, the algorithm works as Gaussian elimination on the inequalities or constraints. The simplex algorithm works as follows:\nRepresent LP in \u201cslack\u201d form.\nConvert one slack form into an equivalent slack form, while likely increasing the value of the objective function, and ensuring that the value does not decrease.\nRepeat until the optimal solution becomes apparent."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain simplex example with the following data.\nMinimize $3x_1 + x_2 + x_3$\nSubject to\n$x_1 + x_2 + 3x_2 < 30$\n$2x_1 + 2x_2 + 5x_3 \u2264 24$\n$4x_1 + x_2 + 2x_3 \u2264 36$\n$x_1, x_2, x_3 \u2265 0$"}, {"role": "assistant", "content": "Change the given LP problem to slack form, consisting of the original variables called nonbasic variables, and new variables representing slack called basic variables.\n$z = 3x_1 + x_2 + 2x_3$\n$x_4 = 30 - x_1 - x_2 - 3x_3$\n$x_5 = 24 - 2x_1 - 2x_2 - 5x_3$\n$x_6 = 36 - 4x_1 - x_2 - 2x_3$\nWe start with a basic solution: we set all nonbasic variables on the right hand side to some feasible value, and compute the values of the basic variables. For instance, we can set $x_1 = x_2 = x_3 = 0$. Note that the all 0 solution satisfies all constraints in this problem, but may not do so in the general case.\nSelect a nonbasic variable xe whose coefficient in the objective function is positive.\nIncrease the value of xe as much as possible without violating any constraints.\nSet xe to be basic, while some other basic variable becomes nonbasic.\n$x_1 = 9 - \\frac{x_2}{4} - \\frac{x_3}{2} + \\frac{x_6}{4}$\n$z = 27 + \\frac{x_2}{4} - \\frac{x_3}{2} + \\frac{3x_6}{4}$\n$x_1 = 9 - \\frac{x_2}{4} - \\frac{x_3}{2} + \\frac{x_6}{4}$\n$x_4 = 21 + \\frac{3x_2}{4} - \\frac{5x_3}{2} + \\frac{x_6}{4}$\n$x_5 = 6 + \\frac{3x_2}{2} - 4x_3 + \\frac{x_6}{2}$\n$z = \\frac{111}{4} + \\frac{x_2}{16} - \\frac{x_5}{8} + \\frac{11x_6}{16}$\n$x_1 = \\frac{33}{4} + \\frac{x_2}{16} - \\frac{x_5}{8} + \\frac{5x_6}{16}$\n$x_2 = \\frac{3}{2} + \\frac{3x_2}{8} + \\frac{x_5}{4} - \\frac{x_6}{8}$\n$x_4 = \\frac{69}{4} + \\frac{3x_2}{16} + \\frac{5x_5}{8} - \\frac{x_6}{16}$\n$z = 28 - \\frac{x_3}{6} - \\frac{x_5}{3} - \\frac{2x_6}{3}$\n$x_1 = 8 + \\frac{x_3}{6} + \\frac{x_5}{6} + \\frac{x_6}{3}$\n$x_2 = 4 - \\frac{8x_3}{3} - \\frac{2x_5}{3} + \\frac{x_6}{3}$\n$x_4 = 18 - \\frac{x_3}{2} + \\frac{x_5}{2}$"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are some additional topics for LP?"}, {"role": "assistant", "content": "There are several important questions regarding LP that were not discussed in this lecture:\nHow do we determine if LP is feasible?\nWhat if LP is feasible, but the initial basic solution is infeasible?\nHow do we determine if the LP is unbounded?\nHow do we choose the pivot?"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Define the approximation ratio \u03c1(n) for an approximation algorithm, and explain what a \u03c1(n)-approximation algorithm is."}, {"role": "assistant", "content": "For a problem of size n, an approximation algorithm has an approximation ratio \u03c1(n) if, for any input, the algorithm produces a solution of cost C such that: max(C/Copt) \u2264 \u03c1(n) where Copt is the cost of the optimal algorithm. Such an algorithm is called a \u03c1(n)-approximation algorithm."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is an approximation scheme, a Polynomial Time Approximation Scheme (PTAS), and a Fully Polynomial Time Approximation Scheme (FPTAS)?"}, {"role": "assistant", "content": "An approximation scheme takes input \u03b5 > 0 and produces a solution such that C = (1 + \u03b5)Copt for any fixed \u03b5. A PTAS is an approximation algorithm that runs in time polynomial in the size of the input, n. An FPTAS runs in time polynomial in both n and \u03b5."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the Vertex Cover problem and its complexity."}, {"role": "assistant", "content": "Given an undirected graph G(V, E), the Vertex Cover problem is to find a subset V' \u2286 V such that for every edge (u, v) \u2208 E, either u \u2208 V' or v \u2208 V'. The goal is to find a V' such that |V'| is minimum. This is an NP-Complete problem."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the Approx_Vertex_Cover algorithm, and what is its running time."}, {"role": "assistant", "content": "The Approx_Vertex_Cover algorithm starts with an empty set V'. While there are edges in E, it picks an edge (u, v) arbitrarily, adds both u and v into V', and removes all edges incident on u or v. It repeats until there are no more edges left in E. It runs in polynomial time."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Illustrate the Approx_Vertex_Cover algorithm with an example."}, {"role": "assistant", "content": "Consider a graph G with nodes a,b,c,d,e,f,g and edges (b,c), (c,e), (b,e), (e,f), (c,d), (d,g). Approx_Vertex_Cover could pick edges (b,c), (e, f) and (d,g), resulting in V' = {b, c, e, f, d, g} and |V'| = 6. The optimal solution is {b, d, e}, with Copt = 3."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the approximation ratio for Approx_Vertex_Cover and prove it."}, {"role": "assistant", "content": "Approx-Vertex_Cover is a 2-approximation algorithm.\nProof: Let U \u2286 V be the set of all the edges that are picked by Approx_Vertex_Cover. The optimal vertex cover must include at least one endpoint of each edge in U (and other edges). Furthermore, no two edges in U share an endpoint. Therefore, |U| is a lower bound for Copt. i.e. Copt \u2265 |U|. The number of vertices in V' returned by Approx-Vertex_Cover is 2\u00b7|U|. Therefore, C = |V'| = 2\u00b7|U| \u2264 2Copt. Hence C\u22642.Copt"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the Set Cover problem and its complexity."}, {"role": "assistant", "content": "Given a set X and a family of subsets S1, S2, ..., Sm \u2286 X such that \u222aSi = X, the Set Cover problem is to find a set P \u2286 {1, 2, 3, ..., m} such that \u222ai\u2208PSi = X. The goal is to find a P such that |P| is minimum. Set Cover is an NP-Complete problem."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the Approx_Set_Cover algorithm and its running time."}, {"role": "assistant", "content": "The Approx_Set_Cover algorithm starts by initializing the set P to the empty set. While there are still elements in X, it picks the largest set Si, adds i to P, and removes all elements in Si from X and all other subsets Sj. It repeats until there are no more elements in X. Approx_Set_Cover runs in polynomial time."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Illustrate the Approx_Set_Cover algorithm with an example."}, {"role": "assistant", "content": "Consider a set X = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11} and subsets S1, S2, S3, S4, S5, S6 covering X. Each dot is an element in X and each Si are subsets of X. The Approx_Set_Cover selects sets S1, S4, S5, S3 in that order. Therefore it returns P = {1,4,5,3} and its cost C = |P| = 4. The optimal solution is Popt = {S3, S4, S5} and Copt = |Popt| = 3."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the approximation ratio of Approx_Set_Cover and give a brief overview of the proof."}, {"role": "assistant", "content": "Approx_Set_Cover is a (ln(n) + 1)-approximation algorithm (where n = |X|).\nProof: Let the optimal cover be Popt such that Copt = |Popt| = t. Let Xk be the set of elements remaining in iteration k of Approx_Set_Cover. Hence, Xo = X.\nThen:\n\u2022 for all k, Xk can be covered by t sets (from the optimal solution)\n\u2022 one of them covers at least |Xk|/t elements\n\u2022 Approx_Set_Cover picks a set of (current) size > |Xk|/t"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Continue the proof of the approximation ratio of Approx_Set_Cover."}, {"role": "assistant", "content": "The proof of the approximation ratio of Approx_Set_Cover continues as follows:\n\u2022 for all k, |Xk+1| \u2264 (1-(1/t))|Xk| (More careful analysis (see CLRS, Ch. 35) relates \u03c1(n) to harmonic numbers. t should shrink.)\n\u2022 for all k, |Xk+1| \u2264 (1 \u2212 (1/t))^k * n \u2264 e^(-k/t) * n (n = |Xo|)\nAlgorithm terminates when |Xk| < 1, i.e., |Xk| = 0 and will have cost C = k.\ne^(-k/t) * n < 1\ne^(k/t) > n\nHence algorithm terminates when k/t > ln(n). Therefore C = k < t * ln(n) + 1. Hence Approx_Set_Cover is a (ln(n) + 1)-approximation algorithm for Set Cover."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the Partition problem and its complexity."}, {"role": "assistant", "content": "The Partition problem takes as input a set S = {1, 2, ..., n} of n items with weights s1, s2, ..., sn. It partitions S into sets A and B to minimize max(w(A), w(B)), where w(A) = \u2211(i\u2208A) si and w(B) = \u2211(j\u2208B) sj. Partition is an NP-Complete problem."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the cost of the optimal solution Copt and what is the goal regarding PTAS or FPTAS?"}, {"role": "assistant", "content": "Define 2L = \u2211(i=1 to n) si = w(S). Then the optimal solution will have cost Copt > L by definition. The goal is to find a PTAS (1 + \u03b5)-approximation. Note that a 2-approximation in this case is trivial. An FPTAS also exists for this problem."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the Approx_Partition algorithm and its phases."}, {"role": "assistant", "content": "The Approx_Partition algorithm defines m = floor(1/\u03b5) - 1 (with \u03b5 \u2248 (m+1)/L). It proceeds in two phases:\nFirst Phase: Find an optimal partition A', B' of s1, ..., sm. This takes O(2^m) time.\nSecond Phase: Initialize sets A and B to A' and B' respectively. Then, for each i from m + 1 to n, if w(A) \u2264 w(B), add i to A; otherwise, add i to B."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "State the claim about the Approx_Partition algorithm's performance and provide the proof."}, {"role": "assistant", "content": "Approx_Partition is a PTAS for Partition.\nProof: Without loss of generality, assume w(A) \u2265 w(B). Then the approximation ratio is w(A)/Copt = w(A)/L. Let k be the last item added to A. There are two cases, either k was added in the first phase or the second phase.\nCase 1: k is added to A in the first phase. This means that A = A'. We have an optimal partition since we can't do better than w(A') when we have n \u2265 m items, and we know that w(A') is optimal for the m items.\nCase 2: k is added to A in the second phase. Here we know w(A) - sk \u2264 w(B) since this is why k was added to A and not to B. Now, because w(A) + w(B) = 2L, w(A) - sk \u2264 w(B) = 2L - w(A). Therefore w(A) \u2264 L + (sk/2). Since s1 \u2265 s2 \u2265 ... \u2265 sn, we can say that s1, s2, ..., sm \u2265 sk. Now since k > m, 2L \u2265 (m + 1)sk.\nNow w(A)/L \u2264 (L+(sk/2))/L = 1 + (sk/2L) \u2264 1 + (sk/(m+1)sk) = 1 + (1/(m+1)) = 1 + \u03b5. Hence Approx_Partition is a (1 + \u03b5)-approximation for Partition."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the Approx_Vertex_Cover_Natural algorithm."}, {"role": "assistant", "content": "The Approx_Vertex_Cover_Natural algorithm starts with an empty set V'. While there are edges left in E, it picks the vertex v \u2208 V that has the maximum degree and adds it to V'. Then remove v and all incident edges from E. Repeat until no more edges left in E. In the end, return V'."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Discuss the approximation factor of Approx_Vertex_Cover_Natural"}, {"role": "assistant", "content": "Approx_Vertex_Cover_Natural is a (log n)-approximation. Given the initial graph G0 and m the number of vertices in the optimal vertex cover for G. Let di be the degree of the maximum degree vertex of Gi\u22121. After that vertex is removed that vertex has degree di. |Gm| = |Go| - \u2211di. \n\u2211di >\u2211|Gi-1|/m. From here the approximation factor of log n is shown. However, in some instances the approximation factor may actually be loglog n."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Define a flow network. What are the key components and properties?"}, {"role": "assistant", "content": "A flow network is a directed graph G = (V, E) with two distinguished vertices: a source s and a sink t. Each edge (u, v) \u2208 E has a nonnegative capacity c(u, v). If (u, v) \u2209 E, then c(u, v) = 0."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the Maximum-flow problem?"}, {"role": "assistant", "content": "Given a flow network G, find a flow of maximum value on G."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What assumptions are made about the flow network?"}, {"role": "assistant", "content": "If edge (u, v) \u2208 E exists, then (v, u) \u2209 \u0395. No self-loop edges (u, u) exist."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Define Net Flow and what properties does it satisfy?"}, {"role": "assistant", "content": "A (net) flow on G is a function f: V \u00d7 V \u2192 R satisfying the following: Capacity constraint: For all u, v \u2208 V, \\(f(u, v) \u2264 c(u, v)\\). Flow conservation: For all u \u2208 V \u2013 {s, t}, \\(\u03a3 f (u, v) = 0\\). Skew symmetry: For all u, v \u2208 V, \\(f(u, v) = -f(v, u)\\)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How is the value of a flow defined?"}, {"role": "assistant", "content": "The value of a flow f, denoted by |f|, is given by \\(|f| = \u03a3 f(s,v) = f(s,V)\\)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "State and prove the theorem regarding the value of flow."}, {"role": "assistant", "content": "Theorem: |f|= f(V, t). Proof: |f| = f(s, V) = f(V, V)-f(V-s, V) = f (V, V-s) = f(V, t)+f(V, V-s-t) = f(V, t)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Define cut in a flow network. Explain the flow across the cut"}, {"role": "assistant", "content": "A cut (S, T) of a flow network G = (V, E) is a partition of V such that s \u2208 S and t \u2208 T. If f is a flow on G, then the flow across the cut is f(S, T)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Prove the lemma for any flow f and any cut (S, T)."}, {"role": "assistant", "content": "Lemma: For any flow fand any cut (S, T), we have | f | = f(S, T). Proof: f(S, T) = f (S, V) \u2013 f (S, S) = f(S, V) = f (s, V) + f (S-s, V) = f (s, V) = |f|."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Define the capacity of a cut."}, {"role": "assistant", "content": "The capacity of a cut (S, T) is c(S, T)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "State the theorem that gives the upper bound on maximum flow value."}, {"role": "assistant", "content": "The value of any flow is bounded above by the capacity of any cut. |f|= f(S,T) = \u03a3\u03a3 f(u,v) \u2264\u03a3\u03a3c(u, v) = c(S,T) ."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Define the residual network and its properties."}, {"role": "assistant", "content": "Let f be a flow on G = (V, E). The residual network Gf(V, Ef) is the graph with strictly positive residual capacities cf(u, v) = c(u, v) \u2212 f(u, v) > 0. Edges in Ef admit more flow. If (v, u) \u2209 E, c(v, u) = 0, but f(v, u) = \u2212 f(u, v). |Ef| \u2264 2 |E|."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Define augmenting paths."}, {"role": "assistant", "content": "Any path from s to t in Gf is an augmenting path in G with respect to f. The flow value can be increased along an augmenting path p by cf (p) = min {cf(u,v)}."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "State the max-flow, min-cut theorem."}, {"role": "assistant", "content": "The following are equivalent: 1. |f | = c(S, T) for some cut (S, T). 2. f is a maximum flow. 3. f admits no augmenting paths."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the Ford-Fulkerson max-flow algorithm."}, {"role": "assistant", "content": "f[u, v] \u2190 0 for all u, v \u2208 V. While an augmenting path p in G wrt f exists: augment f by cf(p)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the focus of this lecture?"}, {"role": "assistant", "content": "This lecture studies how to use max-flow algorithms to compute the elimination of sports teams in a league, using the standings of the AL Eastern Division of the Major League Baseball on August 30, 1996, as an example."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain the table of the Standings of AL East on August 30, 1996."}, {"role": "assistant", "content": "The table shows the standings of the AL East teams including their wins (\\(w_i\\)), losses (\\(l_i\\)), games to play (\\(r_i\\)), and games against each other.  The teams listed are NY, Baltimore, Boston, Toronto, and Detroit."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is a naive way to determine if a team is eliminated?"}, {"role": "assistant", "content": "A naive approach is to check if \\(w_i + r_i < w_j\\) for some other team j. For instance, if Detroit's record was \\(w_5 = 46\\), they would be eliminated since \\(w_5 + r_5 = 46 + 28 < 75 = w_1\\)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Is the naive condition sufficient or necessary?"}, {"role": "assistant", "content": "The naive condition is sufficient but not necessary. For example, if \\(w_5 = 47\\), even though \\(w_5 + r_5 = 75\\), either NY or Baltimore could reach 76 wins because they have 5 games remaining against each other."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How can max-flow be used to determine if Detroit is eliminated for arbitrary values of w5?"}, {"role": "assistant", "content": "A max-flow network can be constructed where the capacity between node s and node i-j is the number of games left to be played between team i and j, the capacity between node i-j and node k (representing team k) is infinity, and the capacity between node k and t is \\(w_5 + r_5 - w_k\\). Detroit is assumed to win all \\(r_5\\) games, and the network checks if the number of wins per team can be kept less than or equal to \\(w_5 + r_5\\)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "State the theorem for determining if Team 5 (Detroit) is eliminated."}, {"role": "assistant", "content": "Team 5 (Detroit) is eliminated if and only if the max-flow does not saturate all edges leaving the source, i.e., the max flow value is less than 26."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What does the saturation of edge capacity in the max-flow network correspond to?"}, {"role": "assistant", "content": "Saturation of the edge capacity corresponds to playing all the remaining games. If all the games cannot be played while keeping the number of wins of a team to be less than or equal to \\(w_5 + r_5\\), then Team 5 is eliminated."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the min-cut shown in Figure 1 and explain how it relates to Detroit's elimination."}, {"role": "assistant", "content": "The min-cut is defined by the sets \\(S = \\{s, 1-2, 1-3, 2-3, 1, 2, 3\\}\\) and \\(T = \\{1-4, 2-4, 3-4, 4, t\\}\\). The capacity of the min-cut \\(c(S, T) = 4 + 4 + 4 + 1 + 5 + 7 = 25 < 26\\). Therefore, Team 5 Detroit is eliminated."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain the alternate explanation for Team 5's elimination using a subset of teams."}, {"role": "assistant", "content": "The max-flow will find the subset of teams that eliminates Team 5.  Consider teams 1, 2, and 3.  The total wins among the 3 teams is 215, and they have 14 games left.  Thus, there will be 229 total wins, meaning at least one team will win \\(\\lceil\\frac{229}{3}\\rceil = 77\\) games. If Detroit has only 48 wins, it is eliminated because \\(48 + 28 = 76 < 77\\). This can be determined using max-flow and the max-flow min-cut theorem."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the topics covered in Lecture 14?"}, {"role": "assistant", "content": "Network Flow & Applications, Review, Max-flow min-cut theorem, Edmonds Karp algorithm, Flow Integrality, and Part II: Applications."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the key points from Lecture 13 related to network flow?"}, {"role": "assistant", "content": "Flow value: | f | = f(s, V).\nCut: Any partition (S, T) of V such that s \u2208 S and t \u2208 T.\nLemma: |f| = f(S, T) for any cut (S, T).\nCorollary: | f | \u2264 c(S, T) for any cut (S, T).\nResidual graph: The graph Gf= (V, Ef) with strictly positive residual capacities cf(u, v) = c(u, v) \u2013 f(u, v) > 0.\nAugmenting path: Any path from s to t in Gf.\nResidual capacity of an augmenting path: cf(p) = min {cf (u, v)} where (u,v) \u2208 p."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain the Ford-Fulkerson max-flow algorithm."}, {"role": "assistant", "content": "The algorithm is as follows:\nf[u, v] \u2190 0 for all u, v \u2208 V\nwhile an augmenting path p in G wrt f exists\ndo augment f by cf(p)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "State the Max-flow, min-cut theorem."}, {"role": "assistant", "content": "The following are equivalent:\n1. | f | = c(S, T) for some cut (S, T).\n2. f is a maximum flow.\n3. f admits no augmenting paths."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the proof of the Max-flow, min-cut theorem (3) \u21d2 (1)."}, {"role": "assistant", "content": "Suppose that f admits no augmenting paths.\nDefine S = {v \u2208 V: there exists a path in Gf from s to v}, and let T = V - S. Observe that s \u2208 S and t\u2208 T, and thus (S, T) is a cut. Consider any vertices u \u2208 S and v \u2208 T.\nWe must have cf (u, v) = 0, since if cf (u, v) > 0, then v \u2208 S, not v\u2208T as assumed. Thus, f(u, v) = c(u, v), since cf (u, v) = c(u, v) \u2013 f(u, v). Summing over all u \u2208 S and v\u2208T yields f(S, T) = c(S, T), and since | f | = f(S, T), the theorem follows."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Why Ford-Fulkerson max-flow algorithm can be slow?"}, {"role": "assistant", "content": "Ford-Fulkerson max-flow algorithm can be slow if the augmenting path is not chosen carefully, as demonstrated by the example given.  For a graph with 4 vertices, it may take 2 billion iterations."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What did Edmonds and Karp notice about Ford-Fulkerson implementations?"}, {"role": "assistant", "content": "Edmonds and Karp noticed that many people's implementations of Ford-Fulkerson augment along a breadth-first augmenting path: a shortest path in Gf from s to t where each edge has weight 1. These implementations would always run relatively fast."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the time complexities of the Edmonds-Karp maximum-flow algorithm and related searches?"}, {"role": "assistant", "content": "The Edmonds-Karp maximum-flow algorithm runs in O(VE^2) time. Breadth-first search takes O(E) time, and there are O(VE) augmentations in the worst case."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the time complexities of the fastest algorithm for maximum flow?"}, {"role": "assistant", "content": "The asymptotically fastest algorithm through 2011 for maximum flow, due to King, Rao, and Tarjan, runs in O(VE log_{E/(V lg V)} V) time. Recently Orlin came up with an O(VE) time algorithm!"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What does the Flow Integrality claim state?"}, {"role": "assistant", "content": "Suppose the flow network has integer capacities. Then, the maximum flow will be integer-valued."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Give the proof of the Flow Integrality claim."}, {"role": "assistant", "content": "Start with a flow of 0 on all edges. Use Ford-Fulkerson. Initially, and at each step, Ford-Fulkerson will find an augmenting path with residual capacity that is an integer. Therefore, all flow values on edges always remain integral throughout the algorithm."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are some applications of network flow?"}, {"role": "assistant", "content": "Baseball Elimination and Bipartite Matching."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What topics are covered in Lecture 6?"}, {"role": "assistant", "content": "Matrix multiplication, and Quicksort are covered."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is a randomized algorithm?"}, {"role": "assistant", "content": "An algorithm that generates a random number \\(r \\in {1, ..., R}\\) and makes decisions based on r's value. On the same input on different executions, a randomized algorithm may run a different number of steps or produce a different output."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How are randomized algorithms classified?"}, {"role": "assistant", "content": "Randomized algorithms are classified into two types: Monte Carlo and Las Vegas.\nMonte Carlo runs in polynomial time always and its output is correct with high probability. Las Vegas runs in expected polynomial time and its output is always correct."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the Matrix Product?"}, {"role": "assistant", "content": "Given \\(C = A \\times B\\), a simple algorithm uses \\(O(n^3)\\) multiplications. Strassen's algorithm multiplies two 2 \u00d7 2 matrices in 7 multiplications, with a complexity of \\(O(n^{log_2 7}) = O(n^{2.81})\\). The Coppersmith-Winograd algorithm has a complexity of \\(O(n^{2.376})\\)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the goal of the Matrix Product Checker?"}, {"role": "assistant", "content": "Given \\(n \\times n\\) matrices \\(A, B, C\\), the goal is to check if \\(A \\times B = C\\) or not. We will see an \\(O(n^2)\\) algorithm that:\n-if \\(A \\times B = C\\), then \\(Pr[output=YES] = 1\\).\n-if \\(A \\times B \\neq C\\), then \\(Pr[output=YES] \\le \\frac{1}{2}\\).\nEntries in matrices are in \\({0,1}\\) and also that the arithmetic is mod 2."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain Frievald's Algorithm"}, {"role": "assistant", "content": "Choose a random binary vector r[1...n] such that \\(Pr[r_i = 1] = 1/2\\) independently for \\(r = 1,...,n\\). The algorithm will output 'YES' if \\(A(Br) = Cr\\) and 'NO' otherwise.\nThe algorithm will take \\(O(n^2)\\) time, since there are 3 matrix multiplications Br, A(Br) and Cr of a \\(n \\times n\\) matrix by a \\(n \\times 1\\) matrix."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is Quicksort and its variants?"}, {"role": "assistant", "content": "Quicksort is a divide and conquer algorithm that works mostly in the divide step. It sorts 'in place' like insertion sort. Different variants are: Basic(good in average case), Median-based pivoting(uses median finding), Random(good for all inputs in expectation (Las Vegas algorithm))"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the steps of quicksort?"}, {"role": "assistant", "content": "Divide: pick a pivot element \\(x\\) in \\(A\\), partition the array into sub-arrays \\(L\\), consisting of all elements \\(< x\\), \\(G\\) consisting of all elements \\(> x\\) and \\(E\\) consisting of all elements \\(= x\\). Conquer: recursively sort subarrays \\(L\\) and \\(G\\). Combine: trivial"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain Basic Quicksort"}, {"role": "assistant", "content": "Pivot around \\(x = A[1]\\) or \\(A[n]\\) (first or last element). Remove, in turn, each element \\(y\\) from \\(A\\). Insert \\(y\\) into \\(L, E\\) or \\(G\\) depending on the comparison with pivot \\(x\\). Each insertion and removal takes \\(O(1)\\) time. Partition step takes \\(O(n)\\) time."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the Basic Quicksort Analysis?"}, {"role": "assistant", "content": "If input is sorted or reverse sorted, we are partitioning around the min or max element each time. This means one of L or G has n - 1 elements, and the other 0. This gives:\n\\(T(n) = T(0) + T(n \u2212 1) + \u0398(n)\\)\n\\(= \u0398(1) + T(n \u2212 1) + \u0398(n)\\)\n\\(= \u0398(n^2)\\)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain Pivot Selection Using Median Finding"}, {"role": "assistant", "content": "Can guarantee balanced \\(L\\) and \\(G\\) using rank/median selection algorithm that runs in O(n) time. The first O(n) below is for the pivot selection and the second for the partition step.\n\\(T(n) = 2T(\\frac{n}{2}) + \u0398(n) + \u0398(n)\\)\n\\(T(n) = O(nlog n)\\)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain Randomized Quicksort"}, {"role": "assistant", "content": "\\(x\\) is chosen at random from array \\(A\\) (at each recursion, a random choice is made). Expected time is \\(O(nlogn)\\) for all input arrays \\(A\\). For \"Paranoid\u201d Quicksort: repeat, choose pivot to be random element of \\(A\\), perform Partition until resulting partition is such that \\(|L| \\le \\frac{3}{4}|A|\\) and \\(|G| \\le \\frac{3}{4}|A|\\), recurse on \\(L\\) and \\(G\\)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain \"Paranoid\u201d Quicksort Analysis"}, {"role": "assistant", "content": "Let's define a 'good pivot' and a 'bad pivot'-\nGood pivot: sizes of \\(L\\) and \\(G \\le \\frac{3}{4}n\\) each\nBad pivot: one of \\(L\\) and \\(G\\) is \\(\\le \\frac{3}{4}n\\) each\nWe see that a pivot is good with probability \\(> 1/2\\).\nLet \\(T(n)\\) be an upper bound on the expected running time on any array of \\(n\\) size.\n\\(T(n)\\) comprises:\n-time needed to sort left subarray\n-time needed to sort right subarray\n-the number of iterations to get a good call. Denote as \\(c \\cdot n\\) the cost of the partition step\n\\(T(n) \\le max_{n/4<i<3n/4}(T(i) +T(n \u2212 i)) + E(\\#iterations) \\cdot cn\\)\nNow, since probability of good pivot \\(> \\frac{1}{2}\\), \\(E(\\#iterations) \\le 2\\)\n\\(T(n) \\le T(\\frac{n}{4}) + T(\\frac{3n}{4}) + 2cn\\)\nWe see in the figure that the height of the tree can be at most \\(log_{\\frac{4}{3}}(2cn)\\) no matter what branch we follow to the bottom. At each level, we do a total of \\(2cn\\) work. Thus, expected runtime is \\(T(n) = \u0398(nlogn)\\)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What topics are covered in Lecture 23: Cache-oblivious Algorithms I?"}, {"role": "assistant", "content": "Topics include: memory hierarchy, external memory vs. cache-oblivious model, cache-oblivious scanning, and cache-oblivious divide & conquer algorithms: median finding & matrix multiplication."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the modern memory hierarchy."}, {"role": "assistant", "content": "The memory hierarchy consists of CPU, L1, L2, L3, memory, and disk. Size increases from ~10KB (L1) to TB (disk). Latency also increases from ~1ns (L1) to 10ms (disk). Each hierarchy on the right is bigger, but has longer latency due to the longer distance data has to travel. Yet, bandwidth between different hierarchies is usually matched."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is blocking and why is it used?"}, {"role": "assistant", "content": "A common technique to mitigate latency is blocking: when fetching a word of data, get the entire block containing it. The idea is to amortize latency over a whole block. For this idea to work, we additional require the algorithm to use all words in a block (spatial locality) and reuse blocks in cache (temporal locality)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the external memory model."}, {"role": "assistant", "content": "In the external memory model, cache accesses are free. The algorithm explicitly reads and writes memory in blocks. We count the number of memory transfers between the cache and the memory as a metric of the algorithm's performance. The cache has a total size of M, divided into M/B blocks, with each block having B words. The memory/disk has infinite size, divided into blocks, with each block having B words."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How does the cache-oblivious model differ from the external memory model?"}, {"role": "assistant", "content": "The only change from the external memory model is that the algorithm no longer knows B and M. Accessing a word in the memory automatically fetches an entire block into the cache, and evicts the least recently used (LRU) block from the cache if the cache is full."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Why are cache-oblivious algorithms preferred?"}, {"role": "assistant", "content": "Because this way, an algorithm can auto-tune itself and run efficiently on different computers (possibly with different B and M)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the scanning example and its memory transfers."}, {"role": "assistant", "content": "The example program is 'for i in range(N): sum += A[i]'. Assuming A is stored contiguously in memory, the external memory model can align A with a block boundary, so it needs [N/B] memory transfers. Cache-oblivious algorithms cannot control alignment, so it needs [N/B] + 1 = N/B + O(1) memory transfers. O(1) parallel scans still need O(N/B + 1) memory transfers."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain the Divide & Conquer approach."}, {"role": "assistant", "content": "Divide & Conquer algorithms divide problems down to O(1) size. The base case of the recursion is either when the problem fits in cache i.e., \u2264 M, or the problem fits in O(1) blocks, i.e., O(B)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the steps in the Median Finding / Order Statistics algorithm?"}, {"role": "assistant", "content": "The steps are: 1. view array as partitioned into columns of 5 (each column is O(1) size). 2. sort each column. 3. recursively find the median of the column medians. 4. partition array by x. 5. recurse on one side"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the recurrence relation for the memory transfers in the median finding algorithm?"}, {"role": "assistant", "content": "The recurrence relation for the memory transfers is:  MT(N) = MT(N/5) + MT(7N/10) + O(N/B + 1)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the different base cases for the median finding algorithm's recursion?"}, {"role": "assistant", "content": "The base cases are MT(O(1)) = O(1) and MT(O(B)) = O(1). Using the base case, the recursion solves to MT(N) = O(N/B + 1)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain the matrix multiplication problem."}, {"role": "assistant", "content": "Compute Z = X \u00b7 Y where X, Y, Z are all N \u00d7 N matrices. X is stored in row-major order, and Y is stored in column-major order to improve locality."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the memory transfers if we use the basic algorithm."}, {"role": "assistant", "content": "Computing each element takes O(N/B + 1) memory transfers, so computing the entire Z costs O(N\u00b3/B + N\u00b2) memory transfers."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the recursion relation when using the blocked matrix multiplication algorithm?"}, {"role": "assistant", "content": "The recursion is MT(N) = 8MT(N/2) + O(N\u00b2/B + 1). The first term is recursive sub-matrix multiplication, and the second term is matrix addition which requires scanning the matrices."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the different base cases for the matrix multiplication algorithm?"}, {"role": "assistant", "content": "weak: MT(O(1)) = O(1), better: MT(O(B)) = O(1), and even better: MT(\u221a\u221aM/3) = O(M/B)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the memory transfer complexity for matrix multiplication?"}, {"role": "assistant", "content": "MT(N) = O(M/B) * 8^{0(lg N/\u221aM)} = O(M/B) * O((N/\u221aM)\u00b3) = O(N\u00b3/B\u221aM)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the topics covered in Lecture 16?"}, {"role": "assistant", "content": "The lecture covers NP-hardness and NP-completeness, 3SAT, Super Mario Brothers, 3 Dimensional Matching, Subset Sum, Partition, Rectangle Packing, and Jigsaw Puzzles."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Define P and NP."}, {"role": "assistant", "content": "P is the set of problems that are solvable in polynomial time, meaning a problem of size n should be solved in \\(n^{O(1)}\\). NP is the set of decision problems solvable in nondeterministic polynomial time, with a YES or NO answer, where a solution can be guessed out of polynomially many options in O(1) time."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Explain the concept of reduction."}, {"role": "assistant", "content": "A reduction from problem A to problem B is a polynomial-time algorithm that converts inputs to problem A into equivalent inputs to problem B, ensuring both problems output the same YES or NO answer for the input and converted input. If B\u2208 P, then A \u2208 NP. If B \u2208 NP, then A \u2208 NP. If A is NP-hard, then B is NP-hard."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the steps to show that problems are NP-complete?"}, {"role": "assistant", "content": "1. Show \\(X \\in NP\\) by finding a nondeterministic algorithm or giving a valid verifier for a certificate.\n2. Show X is NP-hard by reducing from a known NP-complete problem Y to X, ensuring a polynomial-time conversion from Y inputs to X inputs, and that if Y's answer is YES, then X's answer is YES, and vice versa."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is 3SAT and its importance?"}, {"role": "assistant", "content": "3SAT: Given a boolean formula of the form \\((x_1 \\lor x_3 \\lor x_6) \\land (x_2 \\lor x_3 \\lor x_7) \\land ...\\), is there an assignment of variables to True and False such that the entire formula evaluates to True? 3SAT is NP-complete, discovered by Cook in 1971."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How is Super Mario Brothers related to NP-hardness?"}, {"role": "assistant", "content": "Super Mario Brothers is NP-hard, shown by giving a reduction from 3SAT, using gadgets for variables and clauses to construct a level of Super Mario Brothers corresponding to a given 3SAT instance. By solving the level the 3SAT can be solved."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the gadgets for Super Mario Brothers."}, {"role": "assistant", "content": "The gadgets consist of Variable gadget where Mario jumps down from the ledge to the left or right, corresponding to assigning the variable to True or False. The Clause gadget and the Crossover gadget, ensures that Mario does not switch between variable and clause gadgets when it is not allowed."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Define 3 Dimensional Matching (3DM)."}, {"role": "assistant", "content": "3DM: Given disjoint sets X, Y, and Z, each of n elements and triples \\(T \\subseteq X \\times Y \\times Z\\), is there a subset \\(S \\subseteq T\\) such that each element \\(\\in X \\cup Y \\cup Z\\) is in exactly one \\(s \\in S\\)? 3DM is NP-complete, shown via reduction from 3SAT, and gadgets for the variables and clauses are created."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Define Subset Sum."}, {"role": "assistant", "content": "Subset Sum: Given n integers \\(A = {a_1, a_2, ..., a_n}\\) and a target sum t, is there a subset \\(S \\subseteq A\\) such that  \\(\\sum_{a_i \\in S} a_i = t\\)? Subset Sum is NP-complete, shown via reduction from 3DM."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Define Partition."}, {"role": "assistant", "content": "Partition: Given \\(A = {a_1, a_2,..., a_n}\\), is there a subset \\(S \\subseteq A\\) such that \\(\\sum S = \\sum A \\setminus S = \\frac{1}{2} \\sum A\\)? Partition is also weakly NP-complete. It is a special case of the Subset Sum problem."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Define Rectangle Packing."}, {"role": "assistant", "content": "Rectangle Packing: Given a set of rectangles \\(R_i\\) and a target rectangle T, can we pack the rectangles in T such that there is no overlap?  The sum of the area of the rectangles \\(R_i\\) is equivalent to the area of the target rectangle or \\(\\sum_i R_i = T\\). Rectangle packing is weakly NP-hard via a reduction from Partition."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Define Jigsaw Puzzles."}, {"role": "assistant", "content": "Jigsaw Puzzles: Given square tiles with no patterns, can these tiles be arranged to fit a target rectangular shape? The tiles can have a side tab, pocket, or boundary, but tabs and pockets must have matching shapes. 4-Partition is a strongly NP-complete problem. We reduce from 4-Partition to Jigsaw Puzzles to show that Jigsaw Puzzles are NP-hard."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What does this lecture cover?"}, {"role": "assistant", "content": "This lecture covers augmentation of data structures, including easy tree augmentation, order-statistics trees, finger search trees, and range trees."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the main idea of augmentation?"}, {"role": "assistant", "content": "The main idea is to modify 'off-the-shelf' common data structures to store (and update) additional information."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe Easy Tree Augmentation?"}, {"role": "assistant", "content": "The goal is to store x.f at each node x, which is a function of the node, namely f(subtree rooted at x). If x.f can be computed (updated) in O(1) time from x, children and children.f, modification a set S of nodes costs O(# of ancestors of S) to update x.f. Examples of O(lgn) updates are:\nAVL trees: after rotating two nodes, first update the new bottom node and then update the new top node. 2-3 trees: after splitting a node, update the two new nodes. In both cases, then update up the tree."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the goal of order-statistics trees?"}, {"role": "assistant", "content": "The goal of order-statistics trees is to design an Abstract Data Type (ADT) interface that supports the following operations:\ninsert(x), delete(x), successor(x), rank(x): find x's index in the sorted order, i.e., # of elements < x, select(i): find the element with rank i."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How to implement the ADT using easy tree augmentation on AVL trees to store subtree size?"}, {"role": "assistant", "content": "We can implement the above ADT using easy tree augmentation on AVL trees (or 2-3 trees) to store subtree size: f(subtree) = # of nodes in it. Then we also have x.size = 1 + \u2211c.size for c in x.children. As a comparison, we cannot store the rank for each node. In that case, insert(-\u221e) will change the ranks for all nodes."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How rank(x) can be computed?"}, {"role": "assistant", "content": "rank(x) can be computed as follows: initialize rank = x.left.size + 1, walk up from x to root, whenever taking a left move (x \u2192 x'), rank += x'.left.size + 1"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How to implement select(i)?"}, {"role": "assistant", "content": "select(i) can be implemented as follows: x = root, rank = x.left.size + 1, if i = rank: return x, if i < rank: x = x.left, if i > rank: x = x.right, i -= rank"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the goal of finger search trees?"}, {"role": "assistant", "content": "The goal of finger search trees [Brown and Tarjan, 1980] is that, if we already have node y, we want to search x from y in O (lg|rank(y) \u2013 rank(x)|) time. Intuitively, we would like the search of x to be fast if we already have a node y that is close to x. One idea is to use level-linked 2-3 trees, where each node has pointers to its next and previous node on the same level."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How level links can be maintained?"}, {"role": "assistant", "content": "The level links can be maintained during split and merge."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How to implement the original top-down search(x)?"}, {"role": "assistant", "content": "We store all keys in the leaves. Non-leaf nodes do not store keys; instead, they store the min and max key of the subtree (via easy tree augmentation). Then the original top-down search(x) (without being given y) can be implemented as follows: start from the root, look at min & max of each child ci, if c\u2081. min \u2264 x \u2264 c\u2081. max, go down to ci, if c. max \u2264 x \u2264 Ci+1. min, return ci. max (as predecessor) or Ci+1. min (as successor)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How search(x) from y can be implemented?"}, {"role": "assistant", "content": "search(x) from y can be implemented as follows. Initialize v to the leaf node containing y (given), and then in a loop do:\nif v. min \u2264 x \u2264 v. max (this means x is in the subtree rooted at v), do top-down search for x from v and return\nelif x < v. min: v = v.prev (the previous node in this level)\nelif x > v. max: v = v.next (the next node in this level)\nv = v.parent"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the analysis of finger search trees?"}, {"role": "assistant", "content": "We start at the leaf level, and go up by 1 level in each iteration. At step i, level link at height i skips roughly c\u00b2 keys (ranks), where c\u2208 [2,3]. Therefore, if |rank(y) - rank(x)| = k, we will reach the subtree containing x in O(lgk) steps, and the top-down search that follows is also O(lgk)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the Orthogonal Range Searching and Range Trees?"}, {"role": "assistant", "content": "Suppose we have n points in a d-dimension space. We would like a data structure that supports range query on these points: find all the points in a give axis-aligned box. An axis-aligned box is simply an interval in 1D, a rectangle in 2D, and a cube in 3D. To be more precise, each point xi (for i from 1 to n) is a d-dimension vector = (X1, X2, ..., Xid). Range-query(a, b) takes two points a = (a1, a2,..., ad) and b = (b1, b2, . . ., ba) as input, and should return a set of indices {i | \u2200j, aj \u2264 Xij \u2264 bj}."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the 1D case of Orthogonal Range Searching and Range Trees?"}, {"role": "assistant", "content": "We start with the simple case of 1D points, i.e., all xi's and a and b are scalars. Then, we can simply use a sorted array. To do range-query(a,b), we simply perform two binary searches for a and b, respectively, and then return all the points in between (say there are k of them). The complexity is O(lgn + k).\nSorted arrays are inefficient for insertion and deletion. For a dynamic data structure that supports range queries, we can use finger search tree from the previous section. Finger search trees support efficient insertion and deletion. To do range-query(a, b), we first search for a, and then keep doing finger search to the right by 1 until we exceed b. Each finger search by 1 takes O(1), so the total complexity is also O(lgn + k).\nHowever, neither of the above approaches generalizes to high dimensions. That's why we now introduce range trees."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the 1D range trees?"}, {"role": "assistant", "content": "A 1D range tree is a complete binary search tree (for dynamic, use an AVL tree). Range-query(a, b) can be implemented as follows:\nsearch(a), search(b), find the least common ancestor (LCA) of a and b, Usplit, return the nodes and subtrees \u201cin between'. There are O(lgn) nodes and O(lgn) subtrees \u201cin between'. Analysis. O(lgn) to implicitly represent the answer. O(lgn + k) to output all k answers. O(lgn) to report k via subtree size augmentation."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the 2D range trees?"}, {"role": "assistant", "content": "A 2D range tree consists of a primary 1D range tree and many secondary 1D range trees. The primary range stores all points, keyed on the first coordinate. Every node v in the primary range tree stores all points in v's subtree in a secondary range tree, keyed on the second coordinate.\nRange-query(a, b) can be implemented as follows:\nuse the primary range tree to find all points with the correct range on the first coordinate. Only implicitly represent the answer, so this takes O(lgn).\nfor the O(lgn) nodes, manually check whether their second coordinate lie in the correct range.\nfor the O(lgn) subtrees, use their secondary range tree to find all points with the correct range on the second coordinate.\nAnalysis. O(lg\u00b2 n) to implicitly represent the answer, because we will find O(lg\u00b2 n) nodes and subtrees in secondary range trees. O(lg2n + k) to output all k answers. O(lg2n) to report k via subtree size augmentation. Space complexity is O(nlgn). The primary subtree is O(n). Each point is duplicated up to O(lgn) times in secondary subtrees, one per ancestor."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the d-D range trees?"}, {"role": "assistant", "content": "Just recurse: primary 1D range tree \u2192 secondary 1D range trees \u2192 tertiary 1D range trees \u2192 ...\nRange-query complexity: O(lgan + k). Space complexity: O(nlgd-1n).\nSee 6.851 for Chazelle's improved results: O(lgd-1 n + k) range-query complexity and O(n()-1) space complexity."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the pre-requisites for 6.006?"}, {"role": "assistant", "content": "Data structures such as heaps, trees, graphs and Algorithms for sorting, shortest paths, graph search, dynamic programming"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the modules covered in this course?"}, {"role": "assistant", "content": "1. Divide and Conquer - FFT, Randomized algorithms\n2. Optimization - greedy and dynamic programming\n3. Network Flow\n4. Intractibility (and dealing with it)\n5. Linear programming\n6. Sublinear algorithms, approximation algorithms\n7. Advanced topics"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Define P and give an example."}, {"role": "assistant", "content": "P: class of problems solvable in polynomial time. \\(O(n^k)\\) for some constant k. Shortest paths in a graph can be found in \\(O(V^2)\\) for example."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Define NP."}, {"role": "assistant", "content": "NP: class of problems verifiable in polynomial time. Hamiltonian cycle in a directed graph G(V, E) is a simple cycle that contains each vertex in V."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Define NP-complete."}, {"role": "assistant", "content": "NP-complete: problem is in NP and is as hard as any problem in NP. If any NPC problem can be solved in polynomial time, then every problem in NP has a polynomial time solution."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Define Interval Scheduling."}, {"role": "assistant", "content": "Requests 1,2,..., n, single resource\ns(i) start time, f(i) finish time, s(i) < f(i) (start time must be less than finish time for a request). Two requests i and jare compatible if they don't overlap, i.e., f(i) \u2264 s(j) or f(j) \u2264 s(i)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Describe the image representing Interval Scheduling."}, {"role": "assistant", "content": "The image shows a timeline representing requests, where 2 and 3 are compatible, and requests 4, 5 and 6 are compatible as well, but requests 2 and 4 are not compatible."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the goal of interval scheduling?"}, {"role": "assistant", "content": "Select a compatible subset of requests of maximum size."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is a greedy algorithm?"}, {"role": "assistant", "content": "A greedy algorithm is a myopic algorithm that processes the input one piece at a time with no apparent look ahead."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are the steps for Greedy Interval Scheduling?"}, {"role": "assistant", "content": "1. Use a simple rule to select a request i.\n2. Reject all requests incompatible with i.\n3. Repeat until all requests are processed."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Give possible rules for selecting a request."}, {"role": "assistant", "content": "1. Select request that starts earliest, i.e., minimum s(i).\n2. Select request that is smallest, i.e., minimum f(i) \u2013 s(i).\n3. For each request, find number of incompatibles, and select request with mini- mum such number.\n4. Select request with earliest finish time, i.e., minimum f(i)."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What does Claim 1 state regarding a Greedy algorithm?"}, {"role": "assistant", "content": "Greedy algorithm outputs a list of intervals <s(11), f(i\u2081) >, < s(i2), f(i\u2082) >, ..., <s(ik), f(ik) > such that \\(s(i\u2081) < f(i\u2081) \u2264 s(12) < f(i2) < ... < s(ik) < f(ik)\\)"}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What does Claim 2 state regarding a Greedy algorithm?"}, {"role": "assistant", "content": "Given list of intervals L, greedy algorithm with earliest finish time produces k* intervals, where k* is optimal."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "Define Weighted Interval Scheduling."}, {"role": "assistant", "content": "Each request i has weight w(i). Schedule subset of requests that are non-overlapping with maximum weight. The greedy algorithm no longer works."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "How can you define sub-problems for Dynamic Programming?"}, {"role": "assistant", "content": "R* = {j \u2208 R\\s(j) \u2265 x}, Here, R is the set of all requests."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are non-identical machines?"}, {"role": "assistant", "content": "As before, we have n requests {1,2,..., n}. Each request i is associated with a start time s(i) and finish time f(i), m different machine types as well \u315c = {T\u2081,...,Tm}. Each request i is associated with a set Q(i) \u2286 \u03c4 that represents the set of machines that request i can be serviced on."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What is the goal for non-identical machines?"}, {"role": "assistant", "content": "Each request has a weight of 1. We want to maximize the number of jobs that can be scheduled on the m machines."}]}
{"messages": [{"role": "system", "content": "MIT OCW Assistant"}, {"role": "user", "content": "What are three ways to deal with intractability?"}, {"role": "assistant", "content": "1. Approximation algorithms: Guarantee within some factor of optimal in poly- nomial time.\n2. Pruning heuristics to reduce (possible exponential) runtime on \u201creal-world\" examples.\n3. Greedy or other sub-optimal heuristics that work well in practice but provide no guarantees."}]}
