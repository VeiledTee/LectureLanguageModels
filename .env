# ------ Core AI Configuration ------
OPENAI_API_KEY=
HF_TOKEN=                                                                                                                                          # HuggingFace authentication token for model access
PINECONE_API_KEY=                                                                                             # Pinecone API key for vector database operations
GENERATION_MODELS=qwen2.5:7b                                                                                                                                                            # Default model architecture:size for text generation
EMBEDDING_MODEL=nomic-embed-text                                                                                                                                                        # Model used for text embedding generation
EVALUATION_MODEL=llama3.3                                                                                                                                                               # Model used for automated answer evaluation
OPENAI_MODEL_NAME=gpt-4o                                                                                                                                                                # OpenAI model used for image processing
OPENAI_API_TYPE=openai  # gets client to shush

# ------ RAG Configuration ------
RAG_CHUNK_SIZE=512                         # Character length for document chunking (optimal for 512-token models)
RAG_TOP_K=5                                # Number of context chunks to retrieve per query
RAG_EMBEDDING_DIM=768                      # Dimensionality of embedding vectors
RAG_INDEX_NAME=ai-course-rag               # Pinecone index name for course materials
INCLUDE_SOURCES=0                          # [0/1] Whether to include source citations in outputs

# ------ Text Generation Settings ------
GENERATION_TEMPERATURE=0.3                 # Creativity control (0=deterministic, 1=creative)
MAX_TOKENS=2048                            # Maximum length for generated responses
TOP_P=0.9                                  # Probability mass cutoff for sampling (0.9 recommended)

# ------ Evaluation Metrics ------
BLEU_SMOOTHING=meth1                       # Smoothing method for BLEU score calculation
ROUGE_METRICS=rouge-1,rouge-l              # ROUGE variants for answer similarity assessment
JACCARD_THRESHOLD=0.25                     # Minimum similarity threshold for answer matching

# ------ Course Directory Structure ------
EXAM_DIR=AI_Course/Exams                                # Root directory for exam materials
RUBRIC_DIR=AI_Course/Rubrics                            # Location of grading rubrics
KNOWLEDGE_DIR=AI_Course/Lecture_Notes                   # Processed lecture materials storage
ANSWER_DIR=AI_Course/Exams/generated_answers            # Generated answer outputs
MODEL_OUTPUT_DIR=AI_Course/Exams/generated_answers      # Model-generated responses
RAG_OUTPUT_DIR=AI_Course/Exams/generated_rag_answers    # RAG-enhanced responses

# ------ Processing Pipeline Config ------
# Base directories
LECTURE_PDF_DIR=AI_Course/Lecture_Notes/Source_PDFs         # Raw PDF repository for processing lectures
LECTURE_OUTPUT_DIR=AI_Course/Lecture_Notes/Processed        # Central hub for processed lecture outputs
EXAM_PDF_DIR=AI_Course/Exams/Source_PDFs         # Raw PDF repository for processing exams
EXAM_OUTPUT_DIR=AI_Course/Exams/Processed        # Central hub for processed exam outputs

# Preprocessing-specific paths
LECTURE_DIR=${KNOWLEDGE_DIR}        # Reuses knowledge dir for processed lectures
PROCESS_LECTURES=1                  # [1/0] Enable PDF-to-image conversion
PROCESS_EXAMS=0                     # [1/0] Enable exam question extraction

# ------ Image Processing ------
IMAGE_QUALITY=85                           # JPEG compression quality (1-100 scale)
IMAGE_FORMAT=jpeg                          # Output format for converted images